\section{From Interpreters to Abstract Interpreters} \label{unstaged_abs}

After seeing both unstaged and staged concrete interpreters, now we trun our
focus on abstract interpreters under the same framework. We will first present a
lattice framework with binding-time annotations, but for the purpose of clearly
illustrating the idea, we just use simple abstract domains such as power set
lattice or point-wise map lattice. Then we show the abstract components such as
abstract environments and abstract stores.
The abstract interpreter we present in this section is similar to
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s, it is also
context/path/flow-insensitive by our choice.  In Section \ref{cfa}, we will
instantiate a context-sensitive analysis;
\citet{Darais:2015:GTM:2814270.2814308} shows how to achieve path- and
flow-sensitive by varying the monads, which is also applicable to our unstaged or
staged abstract interpreter. \todo{numerical/imp?}

\subsection{Stage Polymorphic Lattices} \label{stagedpoly_lat}

A complete lattice over set $S$ is a tuple of $\langle S, \sqsubseteq, \top,
\bot, \sqcup, \sqcap \rangle$, where $\sqsubseteq : S \to S \to Bool$ is the
ordering relation, $\sqcup: S \to S \to S$ is the join (least upper bound)
operator, and $\sqcap: S \to S \to S$ is the meet (greatest lower bound)
operator. The trait @SPLattice@ defines the type class of stage polymorphic
lattices. Similar to @MonadOps@ in Section \ref{generic_if}, we introduce an
additional higher-kinded type @R[_]@ to annotate the binding-times.

\begin{lstlisting}
  trait SPLattice[S, R[_]] {
    val $\top$: R[S];  val $\bot$: R[S]
    def $\sqsubseteq$(l1: R[S], l2: R[S]): R[Boolean]
    def $\sqcup$(l1: R[S], l2: R[S]): R[S]
    def $\sqcap$(l1: R[S], l2: R[S]): R[S]
  }
  trait Lattice[S] extends SPLattice[S, NoRep]
\end{lstlisting}

In this section, we simply let @R[T] = T@ (i.e., @NoRep@) to instantiate the
unstaged lattice type class. An simple instance of lattice we used is the power
set abstract domain, where the ordering is subset relation, the join is union
operation, and the meet is intersect operation. The power set lattice can be
implemented as follows:

\begin{lstlisting}
  def SetLattice[T]: Lattice[Set[T]] = new Lattice[Set[T]] {
    lazy val $\bot$: Set[T] = Set[T]()
    lazy val $\top$: Set[T] = throw new NotImplementedError("No representation for top")
    def $\sqsubseteq$(l1: Set[T], l2: Set[T]): Boolean = l1 subsetOf l2
    def $\sqcup$(l1: Set[T], l2: Set[T]): Set[T] = l1 union l2
    def $\sqcap$(l1: Set[T], l2: Set[T]): Set[T] = l1 intersect l2
  }
\end{lstlisting}

Other lattices used in the rest of the paper, such as products and maps, can be
implemented similarly, or lifted from existing lattices element-wise or point-wise.

\subsection{Abstract Semantics}

\paragraph{Abstract Components}

% \cite{DBLP:conf/icfp/HornM10, DBLP:journals/jfp/HornM12}

We follow the \textit{abstracting definitional interpreters} (ADIs) approach
\cite{DBLP:journals/pacmpl/DaraisLNH17} to refactor our concrete interpreter to
an abstract interpreter. We first widen the concrete values to @AbsValue@: numbers
are lifted to a singleton object @IntTop@ representing the set of all numbers;
closures remain the same. Then the type @Value@ is sets of @AbsValue@ (we abuse
the type names a little bit, as the generic interface defined the abstract type
@Value@).
The address space is constrained to be finited to ensure the computatbility of
analysis -- for the simplest monovariant analysis, we use variable names for
addresses. After setteling the @Value@ and @Addr@ type, the environments and
stores are automatically lifted to abstract environments and abstract stores,
i.e., @Map[Ident, Addr]@ and @Map[Addr, Set[AbsValue]]@ respectively.
It is importatnt that the abstract store now maps addresses to sets of abstract
values, meaning an address may points to an over-approximated set of values
occurred at runtime.

\begin{lstlisting}
  trait AbstractComponents extends Semantics {
    sealed trait AbsValue
    case object IntTop extends AbsValue
    case class CloV(lam: Lam, env: Env) extends AbsValue
    type Value = Set[AbsValue]; case class Addr(x: String)
    ...
  }
\end{lstlisting}

A cache is a mapping from configurations to sets of value-store pairs, where the
configuration is a triple of current expression being evaluated, environment and store.

\begin{lstlisting}
  type Config = (Expr, Env, Store); type Cache = Map[Config, Set[(Value, Store)]]
  type Result = (R[List[(Value, Store)]], R[Cache])
\end{lstlisting}

\paragraph{Monads for Abstract Interpretation} nondetT

\paragraph{Primitive Operations}

The operations @get@ and @put@ on abstract stores are slightly changed according
to the abstract semantics: @get@ uses the bottom element in the @Value@ lattice
if the queried address does not exist; @put@ performs the update by joining with
the existing values. function @alloc@ simply invokes the @Addr@ constructor.
\texttt{close} and \texttt{num} lift syntactic literals to our abstract domain,
i.e., a singleton set that contains only one \texttt{CloV} or \texttt{NumV}
object.

\begin{lstlisting}
\end{lstlisting}

For branching, @branch0@ joins the answers from two branches since we are doing
a path-insensitive analysis. For arithmetics, @prim_eval@ returns the top
abstract number element. It is worth noting that @apply_closure@ is where we
handle the non-determinism of applications. The non-determinism happens because
the abstract store maps addresses to sets of abstract values; when dereferencing
an address from the store, we need to explore all possible values to achieve a
sound analysis. In the case of @apply_closure@, the first argument @fs@ may
contain multiple target closures, so we use a @for@ comprehension over all
closures, apply them respectively and form a set result values @vs@; meanwhile,
every time when evaluating the body expression @e@ we use the latest store
$\sigma$@_*@ which is updated iteratively during the loop. Thus this is a
store-widened analysis.

\paragraph{Caching and Fixpoint Iteration}

\begin{lstlisting}
  def ask_in_cache: AnsM[Cache]
  def get_out_cache: AnsM[Cache]
  def put_out_cache(out: R[Cache]): AnsM[Unit]
  def update_out_cache(cfg: R[Config], vs: R[(Value, Store)]): AnsM[Unit]
\end{lstlisting}

We described the abstract semantics modularly in the last section, however, the
abstract interpreter may not terminate for some input program. In this section,
we use a memoization technique to ensure its termination. This technique is also
widely used under the name of co-inductive caching algorithm
\cite{DBLP:journals/pacmpl/DaraisLNH17, Wei:2018:RAA:3243631.3236800} or
truncated depth-first evaluation \cite{Rosendahl:AbsIntPL}.

The idea is to set up two caches called @in@ and @out@, which are both mapping
from the arguments of the interpreter (@Config@) to the result values of the
interpreter (@Ans@). The @in@ cache contains what we already have computed from
the last iteration, the @out@ cache is what we will have computed after this
iteration joined with the previous one. When starting a new iteration, @in@ is
set to be the result of the last iteration, i.e., @out@; @out@ is set to be
empty. In the iteration, we first check whether @out@ contains what we want, if
yes then it is returned; otherwise, we retrieve what we have from @in@, compute
the result for this iteration, and put the joined result back into @out@. Note
that we also instrument the recursive call by putting @cached_ev@ into @evev@.
After one iteration, if @in == out@, then there is no more information to be
gained, thus the iteration should end and we have reached the fixed point.

Finally, we override the definition of @eval_top@ by instantiating @CacheFix@
with @eval@ and starting the first iteration.
