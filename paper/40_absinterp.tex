\section{From Interpreters to Abstract Interpreters} \label{unstaged_abs}

After seeing both unstaged and staged concrete interpreters, now we trun our
focus on abstract interpreters under the same framework. We will first present a
lattice framework with binding-time annotations, but for the purpose of clearly
illustrating the idea, we just use simple abstract domains such as power set
lattice or point-wise map lattice. Then we show the abstract components such as
abstract environments and abstract stores.
The abstract interpreter we present in this section is similar to
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s, it is also
context/path/flow-insensitive by our choice.  In Section \ref{cfa}, we will
instantiate a context-sensitive analysis;
\citet{Darais:2015:GTM:2814270.2814308} shows how to achieve path- and
flow-sensitive by varying the monads, which is also applicable to our unstaged or
staged abstract interpreter. \todo{numerical/imp?}

\subsection{Stage Polymorphic Lattices} \label{stagedpoly_lat}

A complete lattice over set $S$ is a tuple of $\langle S, \sqsubseteq, \top,
\bot, \sqcup, \sqcap \rangle$, where $\sqsubseteq : S \to S \to Bool$ is the
ordering relation, $\sqcup: S \to S \to S$ is the join (least upper bound)
operator, and $\sqcap: S \to S \to S$ is the meet (greatest lower bound)
operator. The trait @SPLattice@ declares the type class for lattices.
Similar to @MonadOps@ in Section \ref{generic_if}, we introduce an additional
higher-kinded type @R[_]@ to annotate the binding-times.

\begin{lstlisting}
  trait SPLattice[S, R[_]] {
    val $\top$: R[S];  val $\bot$: R[S]
    def $\sqsubseteq$(l1: R[S], l2: R[S]): R[Boolean]
    def $\sqcup$(l1: R[S], l2: R[S]): R[S]
    def $\sqcap$(l1: R[S], l2: R[S]): R[S]
  }
  trait Lattice[S] extends SPLattice[S, NoRep]
\end{lstlisting}

In this section, we simply let @R[T] = T@ (i.e., @NoRep@) to instantiate the
unstaged lattice type class. An simple instance of lattice we used is the power
set abstract domain, where the ordering is subset relation, join is the union
operation, and meet is the intersect operation. The power set lattice can be
implemented as follows:

\begin{lstlisting}
  def SetLattice[T]: Lattice[Set[T]] = new Lattice[Set[T]] {
    lazy val $\bot$: Set[T] = Set[T]()
    lazy val $\top$: Set[T] = throw new NotImplementedError("No representation for top")
    def $\sqsubseteq$(l1: Set[T], l2: Set[T]): Boolean = l1 subsetOf l2
    def $\sqcup$(l1: Set[T], l2: Set[T]): Set[T] = l1 union l2
    def $\sqcap$(l1: Set[T], l2: Set[T]): Set[T] = l1 intersect l2
  }
\end{lstlisting}

Other lattices used in the rest of the paper, such as products and maps, can be
implemented similarly, or lifted from existing lattices element-wise or point-wise.

\subsection{Abstract Semantics}

\paragraph{Abstract Components}

Our instantiation roughly follows the Abstracting Abstract Machines methodology
\cite{DBLP:conf/icfp/HornM10, DBLP:journals/jfp/HornM12} that transforms the
concrete semantics to abstract semantics. The store now maps addresses to sets
of abstract values, meaning that an address points to all possible values that
may occur at runtime, where the abstract value is either a closure or a single
abstract number \texttt{NumV}, which stands for the top element of the number
lattice. The address space is also constrained to be finite, in the monovariant
setting, we simply use variable names for address.

\begin{lstlisting}
trait Abstract extends Semantics {
  case class Addr(x: Ident);  sealed trait AbsValue
  case class CloV($\lambda$: Lam, $\rho$: Env) extends AbsValue
  case class NumV() extends AbsValue
  type Value = Set[AbsValue]
  type Env = Map[Ident, Addr];  type Store = Map[Addr, Value]
}
\end{lstlisting}

\paragraph{Monads for Abstract Interpretation} nondetT

\paragraph{Primitive Operations}

The operations @get@ and @put@ on abstract stores are slightly changed according
to the abstract semantics: @get@ uses the bottom element in the @Value@ lattice
if the queried address does not exist; @put@ performs the update by joining with
the existing values. function @alloc@ simply invokes the @Addr@ constructor.
\texttt{close} and \texttt{num} lift syntactic literals to our abstract domain,
i.e., a singleton set that contains only one \texttt{CloV} or \texttt{NumV}
object.

\begin{lstlisting}
object AbsInterp extends Abstract {
  type R[+T] = T
  val $\rho$0 = Map[Ident, Addr]();  val $\sigma$0 = Map[Addr, Value]()
  def get($\rho$: Env, x: Ident): Addr = $\rho$(x)
  def put($\rho$: Env, x: Ident, a: Addr): Env = $\rho$ + (x -> a)
  def get($\sigma$: Store, a: Addr): Value = 
    $\sigma$.getOrElse(a, Lattice[Value].bot)
  def put($\sigma$: Store, a: Addr, v: Value): Store =
    $\sigma$ + (a -> (v $\sqcup$ get($\sigma$, a)))
  def alloc($\sigma$: Store, x: Ident): Addr = Addr(x)
  def close(ev: EvalFun)($\lambda$: Lam, $\rho$: Env): Value = Set(CloV($\lambda$, $\rho$))
  def num(i: Lit): Value = Set(NumV())
  def apply_closure(ev: EvalFun)
    (fs: Value, arg: Value, $\sigma$: Store): Ans = { var $\sigma$_* = $\sigma$
      val vs = for (CloV(Lam(x, e), $\rho$) <- fs) yield {
        val $\alpha$ = alloc($\sigma$_*, x)
        val (v, v$\sigma$) = ev(e, put($\rho$, x, $\alpha$), put($\sigma$_*, $\alpha$, arg))
        $\sigma$_* = v$\sigma$ $\sqcup$ $\sigma$_*; v
      }
    (vs.reduce(Lattice[Value].$\sqcup$), $\sigma$_*)
  }
  def branch0(cnd: Value, thn: =>Ans, els: =>Ans): Ans = 
    thn $\sqcup$ els
  def prim_eval(op: Symbol, v1: Value, v2: Value): Value = 
    Set(NumV())
} // to be continued
\end{lstlisting}

For branching, @branch0@ joins the answers from two branches since we are doing
a path-insensitive analysis. For arithmetics, @prim_eval@ returns the top
abstract number element. It is worth noting that @apply_closure@ is where we
handle the non-determinism of applications. The non-determinism happens because
the abstract store maps addresses to sets of abstract values; when dereferencing
an address from the store, we need to explore all possible values to achieve a
sound analysis. In the case of @apply_closure@, the first argument @fs@ may
contain multiple target closures, so we use a @for@ comprehension over all
closures, apply them respectively and form a set result values @vs@; meanwhile,
every time when evaluating the body expression @e@ we use the latest store
$\sigma$@_*@ which is updated iteratively during the loop. Thus this is a
store-widened analysis.

\paragraph{Caching and Fixpoint Iteration}

We described the abstract semantics modularly in the last section, however, the
abstract interpreter may not terminate for some input program. In this section,
we use a memoization technique to ensure its termination. This technique is also
widely used under the name of co-inductive caching algorithm
\cite{DBLP:journals/pacmpl/DaraisLNH17, Wei:2018:RAA:3243631.3236800} or
truncated depth-first evaluation \cite{Rosendahl:AbsIntPL}.

The idea is to set up two caches called @in@ and @out@, which are both mapping
from the arguments of the interpreter (@Config@) to the result values of the
interpreter (@Ans@). The @in@ cache contains what we already have computed from
the last iteration, the @out@ cache is what we will have computed after this
iteration joined with the previous one. When starting a new iteration, @in@ is
set to be the result of the last iteration, i.e., @out@; @out@ is set to be
empty. In the iteration, we first check whether @out@ contains what we want, if
yes then it is returned; otherwise, we retrieve what we have from @in@, compute
the result for this iteration, and put the joined result back into @out@. Note
that we also instrument the recursive call by putting @cached_ev@ into @evev@.
After one iteration, if @in == out@, then there is no more information to be
gained, thus the iteration should end and we have reached the fixed point.

\begin{lstlisting}
case class CacheFix(evev: EvalFun => EvalFun) {
  var in = Map[Config, Ans](); var out = Map[Config, Ans]()
  def cached_ev(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = {
    val cfg: Config = (e, $\rho$, $\sigma$)
    if (out.contains(cfg)) out(cfg)
    else {
      val ans0 = in.getOrElse(cfg, Lattice[(Value, Store)].bot)
      out = out + (cfg -> ans0)
      val ans1 = evev(cached_ev)(e, $\rho$, $\sigma$)
      out = out + (cfg -> (ans0 $\sqcup$ ans1));  ans1
    }
  }
  def iter(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = {
    in = out; out = Map[Config, Ans](); cached_ev(e, $\rho$, $\sigma$)
    if (in == out) out((e, $\rho$, $\sigma$)) else iter(e, $\rho$, $\sigma$)
  }
}
override def eval_top(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = 
  CacheFix(eval).iter(e, $\rho$, $\sigma$)
\end{lstlisting}

Finally, we override the definition of @eval_top@ by instantiating @CacheFix@
with @eval@ and starting the first iteration.
