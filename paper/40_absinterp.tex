\section{From Interpreters to Abstract Interpreters} \label{unstaged_abs}

After seeing both unstaged and staged concrete interpreters, now we trun our
focus on abstract interpreters under the same framework. We will first present a
lattice framework with binding-time annotations, but for the purpose of clearly
illustrating the idea, we just use simple abstract domains such as power set
lattice or point-wise map lattice. Then we show the abstract components such as
abstract environments and abstract stores.
The abstract interpreter we present in this section is similar to
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s, it is also
context/path/flow-insensitive by our choice.  In Section \ref{cfa}, we will
instantiate a context-sensitive analysis;
\citet{Darais:2015:GTM:2814270.2814308} shows how to achieve path- and
flow-sensitivity by varying the monads, which is also applicable to our unstaged
or staged abstract interpreter.

\subsection{Stage Polymorphic Lattices} \label{stagedpoly_lat}

A complete lattice over set $S$ is a tuple of $\langle S, \sqsubseteq, \top,
\bot, \sqcup, \sqcap \rangle$, where $\sqsubseteq : S \to S \to Bool$ is the
ordering relation, $\sqcup: S \to S \to S$ is the join (least upper bound)
operator, and $\sqcap: S \to S \to S$ is the meet (greatest lower bound)
operator. The trait @SPLattice@ defines the type class of stage polymorphic
lattices. Similar to @MonadOps@ in Section \ref{generic_if}, we introduce an
additional higher-kinded type @R[_]@ to annotate the binding-times.

\begin{lstlisting}
  trait SPLattice[S, R[_]] {
    val ⊤: R[S];  val ⊥: R[S]
    def ⊑(l1: R[S], l2: R[S]): R[Boolean]
    def ⊔(l1: R[S], l2: R[S]): R[S]
    def ⊓(l1: R[S], l2: R[S]): R[S]
  }
  trait Lattice[S] extends SPLattice[S, NoRep]
\end{lstlisting}

In this section, we simply let @R[T] = T@ (i.e., @NoRep@) to instantiate the
unstaged lattice type class. An simple instance of lattice we used is the power
set abstract domain, where the ordering is subset relation, the join is union
operation, and the meet is intersect operation. The power set lattice can be
implemented as follows:

\begin{lstlisting}
  def SetLattice[T]: Lattice[Set[T]] = new Lattice[Set[T]] {
    lazy val ⊤: Set[T] = Set[T]()
    lazy val ⊥: Set[T] = throw new NotImplementedError("No representation for top")
    def ⊑(l1: Set[T], l2: Set[T]): Boolean = l1 subsetOf  l2
    def ⊔(l1: Set[T], l2: Set[T]): Set[T]  = l1 union     l2
    def ⊓(l1: Set[T], l2: Set[T]): Set[T]  = l1 intersect l2
  }
\end{lstlisting}

Other lattices used in the rest of the paper, such as products and maps, can be
implemented similarly, or lifted from existing lattices element-wise or point-wise.

\subsection{Abstract Semantics}

\paragraph{Abstract Components}

% \cite{DBLP:conf/icfp/HornM10, DBLP:journals/jfp/HornM12}

We follow the \textit{abstracting definitional interpreters} (ADIs) approach
\cite{DBLP:journals/pacmpl/DaraisLNH17} to refactor our concrete interpreter to
an abstract interpreter. We first widen the concrete values to @AbsValue@: numbers
are lifted to a singleton object @IntTop@ representing the set of all numbers;
closures remain the same. Then the type @Value@ is sets of @AbsValue@ (we abuse
the type names a little bit, as the generic interface defined the abstract type
@Value@).
The address space is constrained to be finited to ensure the computatbility of
analysis -- for the simplest monovariant analysis, we use variable names for
addresses. After setteling the @Value@ and @Addr@ type, the environments and
stores are automatically lifted to abstract environments and abstract stores,
i.e., @Map[Ident, Addr]@ and @Map[Addr, Set[AbsValue]]@ respectively.
It is importatnt that the abstract store now maps addresses to sets of abstract
values, meaning an address may points to an over-approximated set of values
occurred at runtime.

\begin{lstlisting}
  trait AbstractComponents extends Semantics {
    sealed trait AbsValue
    case object IntTop extends AbsValue
    case class CloV(lam: Lam, env: Env) extends AbsValue
    type Value = Set[AbsValue]; case class Addr(x: String)
    ...
  }
\end{lstlisting}

To prevent the abstract interpreter from falling into nontermination, the ADI
approach uses a two-cache mechanism. Here we first provides the type
definitions, and later we will describe the algorithm in detail. A @Cache@ is a
mapping from configurations @Config@ to sets of value-store pairs, where the
configuration is a triple of current expression being evaluated, environment and
store.

\begin{lstlisting}
  type Config = (Expr, Env, Store); type Cache = Map[Config, Set[(Value, Store)]]
\end{lstlisting}

As of now, the store is a mapping from addresses to sets of abstract values.
Therefore, when applying a function, for instance @f(a)@, we may retrieve a set
of closures by dereferencing the address of @f@. We need to apply all of the
target closures, where the nondeterminism is introduced. Another nondeterminism
happens when evaluating conditionals, we have to evaluate both branches if the
condition can not be determined. In other words, we will have multiple computing
results.

\begin{lstlisting}
  type Result = (R[List[(Value, Store)]], R[Cache])
\end{lstlisting}

This oberservation leads us to the type definition of @Result@: in concrete setting,
the @Result@ is a pair of @Value@ and @Store@, now we use a list of such pairs
@List[(Value, Store)]@ to represent multiple results. The results is also linked
with the resulting cache used in this iteration.
Note that the abstract binding-time annotation is wrapped to the two objects in
the @Result@ pair, but not the whole pair. Because we statically know the result
is a tuple of two elements, but we don't know how many value-store pairs we
would have, neither the content of the cache.

\paragraph{Monads for Abstract Interpretation} Now we incorporate the
nondeterminism and caching into the monad stack. For concrete evaluation, we
already have a reader effect for environments and a state effect for stores. We
add three more effects based on it: the nondeterminism effect is represented by
the @ListT[M[_], A]@ monad transformer, inside of which, we have a @ReaderT@ for
a @in@ cache, and a @StateT@ for an @out@ cache.
\todo{highlight where changed}

\begin{lstlisting}
  trait AbstractSemantics extends AbstractComponents {
    type R[T] = T
    type AnsM[T] = ReaderT[StateT[ListT[ReaderT[StateT[IdM, Cache, ?], Cache, ?], ?], Store, ?], Env, T]
    ...
  }
\end{lstlisting}

The sketch implementation of @ListT@ is shown below. The value @run@ it encapsulates
is of type @M[List[A]]@, where @M[_]@ is the inner monad, and @A@ the element
type of the list. 

\begin{lstlisting}
  case class ListT[M[_]: Monad, A](run: M[List[A]]) { ... }
\end{lstlisting}

\paragraph{Primitive Operations} \todo{wip}

The operations @get@ and @put@ on abstract stores are slightly changed according
to the abstract semantics: @get@ uses the bottom element in the @Value@ lattice
if the queried address does not exist; @put@ performs the update by joining with
the existing values. function @alloc@ simply invokes the @Addr@ constructor.
\texttt{close} and \texttt{num} lift syntactic literals to our abstract domain,
i.e., a singleton set that contains only one \texttt{CloV} or \texttt{NumV}
object.

\begin{lstlisting}
\end{lstlisting}

For branching, @branch0@ joins the answers from two branches since we are doing
a path-insensitive analysis. For arithmetics, @prim_eval@ returns the top
abstract number element. It is worth noting that @apply_closure@ is where we
handle the non-determinism of applications. The non-determinism happens because
the abstract store maps addresses to sets of abstract values; when dereferencing
an address from the store, we need to explore all possible values to achieve a
sound analysis. In the case of @apply_closure@, the first argument @fs@ may
contain multiple target closures, so we use a @for@ comprehension over all
closures, apply them respectively and form a set result values @vs@; meanwhile,
every time when evaluating the body expression @e@ we use the latest store
$\sigma$@_*@ which is updated iteratively during the loop. Thus this is a
store-widened analysis.

\paragraph{Caching and Fixpoint Iteration} Caching

\begin{lstlisting}
  def ask_in_cache: AnsM[Cache]; def get_out_cache: AnsM[Cache]
  def put_out_cache(out: R[Cache]): AnsM[Unit]
  def set_out_cache(cfg: R[Config], vs: R[(Value, Store)]): AnsM[Unit]
\end{lstlisting}

We described the abstract semantics modularly in the last section, however, the
abstract interpreter may not terminate for some input program. In this section,
we use a memoization technique to ensure its termination. This technique is also
widely used under the name of co-inductive caching algorithm
\cite{DBLP:journals/pacmpl/DaraisLNH17, Wei:2018:RAA:3243631.3236800} or
truncated depth-first evaluation \cite{Rosendahl:AbsIntPL}.

The idea is to set up two caches called @in@ and @out@, which are both mapping
from the arguments of the interpreter (@Config@) to the result values of the
interpreter (@Ans@). The @in@ cache contains what we already have computed from
the last iteration, the @out@ cache is what we will have computed after this
iteration joined with the previous one. When starting a new iteration, @in@ is
set to be the result of the last iteration, i.e., @out@; @out@ is set to be
empty. In the iteration, we first check whether @out@ contains what we want, if
yes then it is returned; otherwise, we retrieve what we have from @in@, compute
the result for this iteration, and put the joined result back into @out@. Note
that we also instrument the recursive call by putting @cached_ev@ into @evev@.
After one iteration, if @in == out@, then there is no more information to be
gained, thus the iteration should end and we have reached the fixed point.

Finally, we override the definition of @eval_top@ by instantiating @CacheFix@
with @eval@ and starting the first iteration.
