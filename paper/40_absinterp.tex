\section{From Interpreters to Abstract Interpreters} \label{unstaged_abs}

After seeing both unstaged and staged concrete interpreters, now we turn our
focus on abstract interpreters under the same framework. We first present a
lattice framework with binding-time abstraction, as well as simple abstract
domains such as power set lattice.
Then we show the abstract components, namely abstract values, abstract
environments, and abstract stores.
The abstract interpreter we construct in this
section is similar to \citet{DBLP:journals/pacmpl/DaraisLNH17}'s. For
simplicity, it is also context/path/flow-insensitive by our choice. In Section
\ref{cfa}, we will instantiate a commonly-used context-sensitive analysis;
\citet{Darais:2015:GTM:2814270.2814308} shows how to achieve path- and
flow-sensitivity by varying the monads, which is also applicable to our unstaged
or staged abstract interpreter.

\iffalse
For example, the CEK machine \cite{DBLP:conf/popl/FelleisenF87} for
concrete execution can be readily refactored to an effective $0$-CFA
control-flow analysis \cite{Shivers:1988:CFA:53990.54007,
  Midtgaard:2012:CAF:2187671.2187672}: first, tweak the environment
dereference as a nondeterministic choice, such that the environment
may contain multiple possible values for a variable, then allocate
continuations in the environment to exploit return-flow information,
and also constrain the address space to be finite.
\fi

\subsection{Stage Polymorphic Lattices} \label{stagedpoly_lat}

Abstract interpreters run on abstract domains, such abstract domains usually can
be presented by a lattice.
A complete lattice over set $S$ is a tuple of $\langle S, \sqsubseteq, \top,
\bot, \sqcup, \sqcap \rangle$, where $\top$ is the top element, $\bot$ is the
bottom element, $\sqsubseteq : S \to S \to Bool$ is the
ordering relation, $\sqcup: S \to S \to S$ is the join (least upper bound)
operator, and $\sqcap: S \to S \to S$ is the meet (greatest lower bound)
operator. The trait @SPLattice@ (Figure \ref{fig:splattice}) defines a type
class of stage polymorphic lattices. Similar to @MonadOps@ in Section
\ref{generic_if}, we introduce an additional higher-kinded type @R[_]@ to
annotate the binding-times, where @R[_]@ wraps datatype @S@ and @Boolean@ in
these operations.

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
  \begin{lstlisting}[style=small]
trait SPLattice[S, R[_]] {
  val ⊤: R[S];  val ⊥: R[S]
  def ⊑(l1: R[S], l2: R[S]): R[Boolean]
  def ⊔(l1: R[S], l2: R[S]): R[S]
  def ⊓(l1: R[S], l2: R[S]): R[S]
}
trait Lattice[S] extends SPLattice[S, NoRep]
  \end{lstlisting}
  \caption{trait \texttt{SPLattice} and \texttt{Lattice}} \label{fig:splattice}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.6\textwidth}
\begin{lstlisting}[style=small]
def SetLattice[T]: Lattice[Set[T]] = new Lattice[Set[T]] {
  lazy val ⊤: Set[T] = error("No representation for ⊤")
  lazy val ⊥: Set[T] = Set[T]()
  def ⊑(l1: Set[T], l2: Set[T]): Boolean = l1 subsetOf  l2
  def ⊔(l1: Set[T], l2: Set[T]): Set[T]  = l1 union     l2
  def ⊓(l1: Set[T], l2: Set[T]): Set[T]  = l1 intersect l2
}
\end{lstlisting}
  \caption{The power set instance for lattice} \label{fig:powerset}
\end{subfigure}
\end{figure}

In this section, we simply let the binding-time type @R[T] = T@ (i.e., @NoRep@)
to instantiate an unstaged lattice type class. An example of lattice we used in
the rest of the paper is the power set abstract domain (shown in Figure
\ref{fig:powerset}), where the ordering is subset relation, the join is union
operation, and the meet is the intersect operation. The bottom element of a
power set is empty set, and we don't have a top representation for power set.
Other lattices used in the the paper, such as products and maps, can be
implemented similarly or lifted from existing lattices element-wise or
point-wise. Non-relational abstract domains such intervals also can be
implemented in a stage polymorphic way.

\subsection{Abstract Semantics}

We follow the \textit{abstracting definitional interpreters} (ADI) approach
\cite{DBLP:journals/pacmpl/DaraisLNH17} to refactor our concrete interpreter to
an abstract interpreter.
% \cite{DBLP:conf/icfp/HornM10, DBLP:journals/jfp/HornM12}

\paragraph{Abstract Components}

We first widen the concrete values to @AbsValue@: numbers are lifted to a
singleton object @IntTop@ representing the set of all numbers; closures remain
the same. Then the type @Value@ is a set of @AbsValue@ (we abuse the type names
a bit, as the generic interface already defined the abstract type @Value@).
The address space is constrained to be finite to ensure the computability of
analysis -- for the simplest monovariant analysis, we use variable names for
addresses. After defining the @Value@ and @Addr@ type, the environments and
stores are automatically lifted to abstract environments and abstract stores,
i.e., @Map[Ident, Addr]@ and @Map[Addr, Set[AbsValue]]@ respectively.
It is important that the abstract store now maps addresses to sets of abstract
values, indicating that an address may point to an over-approximated set of
values occurred at run-time.
\begin{lstlisting}
  trait AbstractComponents extends Semantics {
    sealed trait AbsValue
    case object IntTop extends AbsValue
    case class CloV(lam: Lam, env: Env) extends AbsValue
    type Value = Set[AbsValue]; case class Addr(x: String)
    ...
  }
\end{lstlisting}

To prevent the abstract interpreter from falling into non-termination when
computing the fixed-point, the ADI approach uses a co-inductive mechanism
consisting of two caches that remember the input and output of functions.
Here we first provide the necessary type definitions, and later we will describe
the algorithm in detail. A @Cache@ is a mapping from configurations @Config@ to
sets of value-store pairs, where the configuration is a triple of current
expression being evaluated, environment and store. Intuitively, a cache memoizes
the corresponding values and stores for a given program configuration.
\begin{lstlisting}
  type Config = (Expr, Env, Store); type Cache = Map[Config, Set[(Value, Store)]]
\end{lstlisting}

Now, the store is a mapping from addresses to sets of abstract values. This can
be justified by the approximation nature of abstract interpretation and
nondeterminism in the abstract interpreter.
First, when analyzing a conditional expression, we may not have enough
information on which branch will be taken, thus a sound treatment is to
nondeterministically explore both branches, i.e., compute the join of two path.
Second, when applying a function, for instance, @f(a)@, the possible lambda
terms of @f@ is computed approximately. As a result, we may retrieve a set of
closures when dereferencing the address of @f@ and need to apply all of them.

\paragraph{Monads for Abstract Interpretation} Compared with the concrete
interpreter that uses reader and state effects, the abstract interpreter
further introduces a nondeterminism effect and another reader and state effect
for the two caches. The nondeterminism effect is represented by the
@Set[M[_], A]@ monad transformer, where @M@ is the inner monad being
transformed, and @A@ is the type of elements in the set. We use a @ReaderT@ for
one cache that will not be changed during one fixed-point iteration, and use a
@StateT@ for another cache that will be constantly updated during analysis.
\citet{DBLP:journals/pacmpl/DaraisLNH17} discuss different permutation of the
monad stack for abstract interpretation. The following @AnsM@ type shows the
monad stack (we use \hl{light gray} to highlight what have been changed from
the monad stack of concrete interpretation):
\begin{lstlisting}[escapechar=!]
trait AbstractSemantics extends AbstractComponents {
  type R[T] = T
  type AnsM[T] = ReaderT[StateT[!\hl{SetT}![!\hl{ReaderT}![!\hl{StateT}![IdM, !\hl{Cache}!, ?], !\hl{Cache}!, ?], ?], Store, ?], Env, T]
  ...
}
\end{lstlisting}

Similar to the concrete scenario, we sketch the implementation of @flatMap@ for
@SetT@ transformer and omit the rest. The value @run@ encapsulated by the monad
is of type @M[SetT[A]]@, where @M[_]@ is the inner monad, and @A@ is the element
type of the set. The @flatMap@ method takes a function that transforms each
element of type @A@ from @M[Set[A]]@ into a @SetT[M, B]@ value, and then folds
all the transformed values into a single monadic value of type @Set[M, B]@.
\begin{lstlisting}
  case class SetT[M[_]: Monad, A](run: M[Set[A]]) {
    def flatMap[B](f: A => SetT[M, B]): SetT[M, B] =
      SetT(Monad[M].flatMap(run) { (s: Set[A]) =>
        s.foldLeft(SetT.empty[M,B])((acc, a) => acc ++ f(a)).run
      }); ... }
\end{lstlisting}

Such monad stack scheme leads to a different type of result type. In the concrete
setting, we only have a reader monad (for environment) and a state monad (for
store), and the reader effect is not persistent to the final result. Together
with the value produced by the interpreter, the final result type is a pair of
@Value@ and @Store@. In the abstract setting, we have a @SetT@ inside of the
environment monad and store monad, which becomes the container type of the pair
of values and stores, i.e., @Set[(Value, Store)]@. Also note that the reader and
state monad for caches live internally of the nondeterminism monad, therefore
the cache type of state monad becomes adjacent to the set type.
\begin{lstlisting}
  type Result = (R[Set[(Value, Store)]], R[Cache])
\end{lstlisting}

\paragraph{Primitive Operations} The primitive operations are changed to adapt
the new monad stack scheme and value domains. A notable change is that the store
update operation joins the value with the existing values, for the same address.
As what mentioned before, we may have to explore both branches for conditionals:
in @br0@ method, we combine the results using @mplus@ from @MonadPlus@, which
requires the value domains are join-semilattices (in our case @Set@s and
@Map@s).
\begin{lstlisting}
  def set_store(αv: (Addr, Value)): AnsM[Unit] = liftM(StateTMonad.mod(σ => σ ⊔ Map(αv)))
  def br0(test: Value, thn: => Ans, els: => Ans): Ans = ReaderTMonadPlus.mplus(thn, els)
\end{lstlisting}

The value representation of lambda terms is still a defunctionalized closure
@CloV@, but we lift it to a singleton set domain.
\begin{lstlisting}
  def close(ev: Expr => Ans)(λ: Lam, ρ: Env): Value = Set(CloV(λ, ρ))
\end{lstlisting}

For function applications, @ap_clo@ looks the same as the concrete interpreter.
The difference is now the first argument @rator@ is a set of closures (remember
that @Value@ is now an alias of @Set[AbsValue]@), so we can not directly
destruct it by pattern matching. Instead, we use an auxiliary function @lift_nd@
that takes a set and lifts the elements into the monad stack. Then we can still
implement @ap_clo@ in monadic style, where the closures come from the @SetT@ and
thus the nondeterminism can be naturally handled. The light gray code shows what
is added from the concrete @ap_clo@.
\begin{lstlisting}[escapechar=!]
  def lift_nd[T](vs: Set[T]): AnsM[T]
  def ap_clo(ev: Expr => Ans)(rator: Value, rand: Value): Ans = for {
    !\hl{CloV(Lam(x, e), $\rho$) <- lift\_nd[AbsValue](rator)}!
    α <- alloc(x)
    _ <- set_store(α → rator)
    rt <- local_env(ev(e))(ρ + (x → α))
  } yield rt
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Caching and Fixpoint Iteration}

As we mentioned earlier, the ADI approach uses a two-cache mechanism to
compute the least fixed-point and prevent non-termination, which is also called a
\textit{co-inductive} caching algorithm or \textit{truncated depth-first
evaluation} \cite{Rosendahl:AbsIntPL}. It has been used in other abstract
interpreter or fixed point computation
\cite{DBLP:journals/pacmpl/DaraisLNH17, Wei:2018:RAA:3243631.3236800,
  Rosendahl:AbsIntPL}. The idea is to use a @in@ cache and a @out@ cache during
the depth-first evaluation, where the @in@ cache stores the result from last
iteration, and @out@ cache is used for updates in current iteration. In the next
iteration, the last @out@ cache will be served as @in@ cache, and an empty cache
is plugged-in to the @out@ slot. Once the @out@ cache does not contain anything
new than the @in@ cache, the fixed-point is reached.

In our monad stack, the @in@ and @out@ cache modeled by a reader effect and
state effect, respectively. We first defined several methods to manipulate
the two caches through the monad stack; the implementations are elided.
\begin{lstlisting}
  def ask_in_cache: AnsM[Cache]; def get_out_cache: AnsM[Cache]
  def put_out_cache(out: R[Cache]): AnsM[Unit]
  def set_out_cache(cfg: R[Config], vs: R[(Value, Store)]): AnsM[Unit]
\end{lstlisting}

The co-inductive caching algorithm is implemented as a instrumentation over
@eval@ (Figure \ref{fig:coind_cache}), and it also closes the open recursion.
Initially, the two caches are both empty.
During the iteration, we first check whether @out@ contains the configuration
@cfg@, representing the current desired computation. If it does, then the result
is directly returned through the monads.
Otherwise, we first retrieve the results from @in@ (@⊥@ if not contained in
@in@), and join it into the @out@ cache.
Then we invoke @ev@ to compute the result for this iteration, where @ev@ takes
@fix(ev)@ as a self reference.
After the evaluation, the store @σ@ may have been changed. We update the
@out@ cache with the new result, i.e., a pair of value and store @(v, σ)@.
Similar to store update, cache update is also a point-wise join.

The iteration terminates when the resulting @out@ cache is equivalent to the
input @in@ cache, which indicates that there is no more fact can be gained, thus
the iteration should end and we have reached the least fixed point.

\begin{figure}[h!]
  \centering
\begin{lstlisting}
  def fix(ev: (Expr => Ans) => (Expr => Ans)): Expr => Ans = e => for {
    ρ <- ask_env; σ <- get_store; in <- ask_in_cache; out <- get_out_cache; val cfg = (e, ρ, σ)
    rt <- if (out.contains(cfg)) for { // ask if out already contains the desired result
            (v, σ) <- lift_nd[(Value, Store)](out(cfg))
             _ <- put_store(σ)
          } yield v
          else for {
            _ <- put_out_cache(out + (cfg → in.getOrElse(cfg, ⊥)))
            v <- ev(fix(ev))(e)
            σ <- get_store
            _ <- update_out_cache(cfg, (v, σ))
          } yield v
  } yield rt
\end{lstlisting}
\vspace{-1em}
\caption{The unstaged co-inductive caching algorithm.}
\label{fig:coind_cache}
\end{figure}

\begin{lstlisting}
  def run(e: Expr): Result = fix(eval)(e)(ρ0)(σ0)(cache0)(cache0).run
\end{lstlisting}

Finally, we override the top-level @run@ method by running the monadic value
with the empty abstract environment $\rho_0$, initial abstract store $\sigma_0$,
and initial caches @cache@$_0$.
