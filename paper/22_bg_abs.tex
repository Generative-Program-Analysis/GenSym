\section{From Interpreters to Abstract Interpreters} \label{unstaged_abs}

Based on the generic interface we presented in Section~\ref{bg_lang}, we now
describe the instantiation of an abstract interpreter. To keep the presentation
simple, we use simple abstract domains, and just establish a
context-/path-/flow-insensitive, store-widened analysis in this section ---
indeed, it is coarse but simple enough to setup a foundation for the staged
abstract interpreter we will present later. In Section~\ref{cfa}, we will see
how to regain context-/path-/flow-sensitivity \todo{path/flow} for pushdown
control-flow analysis; in Section~\ref{cases_imp}, we will see how to
instantiate an interval abstract domain for numerical analysis.

\paragraph{Abstract Instantiation}

Our instantiation roughly follows the Abstracting Abstract Machines methodology
\cite{DBLP:conf/icfp/HornM10, DBLP:journals/jfp/HornM12} that transforms the
concrete semantics to abstract semantics. The store now maps addresses to sets
of abstract values, meaning that an address points to all possible values that
may occur at runtime, where the abstract value is either a closure or a single
abstract number \texttt{NumV}, which stands for the top element of the number
lattice. The address space is also constrained to be finite, in the monovariant
setting, we simply use variable names for address.

\begin{lstlisting}
trait Abstract extends Semantics {
  case class Addr(x: Ident);  sealed trait AbsValue
  case class CloV($\lambda$: Lam, $\rho$: Env) extends AbsValue
  case class NumV() extends AbsValue
  type Value = Set[AbsValue]
  type Env = Map[Ident, Addr];  type Store = Map[Addr, Value]
}
\end{lstlisting}

\subsection{Stage Polymorphic Lattices} \label{stagedpoly_lat}

To effectively reuse the code between unstaged and staged variants, we also make
the lattice structure stage polymorphic. A lattice type class parameterizes over
an element type \texttt{E} and defines five operations for \texttt{R[E]}, such
as meet, join, and ordering relation; again, \texttt{R} is the higher-kinded
type indicating the binding-time.

\begin{lstlisting}
trait Lattice[E, R[+_]] {
  val bot: R[E];  val top: R[E]
  def $\sqsubseteq$(l1: R[E], l2: R[E]): R[Boolean]
  def $\sqcup$(l1: R[E], l2: R[E]): R[E]
  def $\sqcap$(l1: R[E], l2: R[E]): R[E]
}
\end{lstlisting}

For example, here we use powersets as the abstract domain, and the unstaged
lattice of powersets can be easily implemented as follows:

\begin{lstlisting}
implicit def SetLattice[T]: Lattice[Set[T], NoRep] = 
  new Lattice[Set[T], NoRep] {
    lazy val bot: Set[T] = Set[T]()
    lazy val top: Set[T] = throw new NotImplementedError()
    def $\sqsubseteq$(l1: Set[T], l2: Set[T]): Boolean = l1 subsetOf l2
    def $\sqcup$(l1: Set[T], l2: Set[T]): Set[T] = l1 union l2
    def $\sqcap$(l1: Set[T], l2: Set[T]): Set[T] = l1 intersect l2
  }
\end{lstlisting}

The ordering relation is to ask whether one set is a subset of the other, 
join is to union the two sets, and meet is to intersect the two sets.
Accordingly, other structures used in the rest of the paper such as tuples 
(products) and maps can be lifted to lattices element-wise or point-wise.
The code for them are elided.

\subsection{Abstract Semantics}

The operations @get@ and @put@ on abstract stores are slightly changed according
to the abstract semantics: @get@ uses the bottom element in the @Value@ lattice
if the queried address does not exist; @put@ performs the update by joining with
the existing values. function @alloc@ simply invokes the @Addr@ constructor.
\texttt{close} and \texttt{num} lift syntactic literals to our abstract domain,
i.e., a singleton set that contains only one \texttt{CloV} or \texttt{NumV}
object.

\begin{lstlisting}
object AbsInterp extends Abstract {
  type R[+T] = T
  val $\rho$0 = Map[Ident, Addr]();  val $\sigma$0 = Map[Addr, Value]()
  def get($\rho$: Env, x: Ident): Addr = $\rho$(x)
  def put($\rho$: Env, x: Ident, a: Addr): Env = $\rho$ + (x -> a)
  def get($\sigma$: Store, a: Addr): Value = 
    $\sigma$.getOrElse(a, Lattice[Value].bot)
  def put($\sigma$: Store, a: Addr, v: Value): Store =
    $\sigma$ + (a -> (v $\sqcup$ get($\sigma$, a)))
  def alloc($\sigma$: Store, x: Ident): Addr = Addr(x)
  def close(ev: EvalFun)($\lambda$: Lam, $\rho$: Env): Value = Set(CloV($\lambda$, $\rho$))
  def num(i: Lit): Value = Set(NumV())
  def apply_closure(ev: EvalFun)
    (fs: Value, arg: Value, $\sigma$: Store): Ans = { var $\sigma$_* = $\sigma$
      val vs = for (CloV(Lam(x, e), $\rho$) <- fs) yield {
        val $\alpha$ = alloc($\sigma$_*, x)
        val (v, v$\sigma$) = ev(e, put($\rho$, x, $\alpha$), put($\sigma$_*, $\alpha$, arg))
        $\sigma$_* = v$\sigma$ $\sqcup$ $\sigma$_*; v
      }
    (vs.reduce(Lattice[Value].$\sqcup$), $\sigma$_*)
  }
  def branch0(cnd: Value, thn: =>Ans, els: =>Ans): Ans = 
    thn $\sqcup$ els
  def prim_eval(op: Symbol, v1: Value, v2: Value): Value = 
    Set(NumV())
} // to be continued
\end{lstlisting}

For branching, @branch0@ joins the answers from two branches since we are doing
a path-insensitive analysis. For arithmetics, @prim_eval@ returns the top
abstract number element. It is worth noting that @apply_closure@ is where we
handle the non-determinism of applications. The non-determinism happens because
the abstract store maps addresses to sets of abstract values; when dereferencing
an address from the store, we need to explore all possible values to achieve a
sound analysis. In the case of @apply_closure@, the first argument @fs@ may
contain multiple target closures, so we use a @for@ comprehension over all
closures, apply them respectively and form a set result values @vs@; meanwhile,
every time when evaluating the body expression @e@ we use the latest store
$\sigma$@_*@ which is updated iteratively during the loop. Thus this is a
store-widened analysis.

\subsection{Fixpoint Iteration}

We described the abstract semantics modularly in the last section, however, the
abstract interpreter may not terminate for some input program. In this section,
we use a memoization technique to ensure its termination. This technique is also
widely used under the name of co-inductive caching algorithm
\cite{DBLP:journals/pacmpl/DaraisLNH17, Wei:2018:RAA:3243631.3236800} or
truncated depth-first evaluation \cite{Rosendahl:AbsIntPL}.

The idea is to set up two caches called @in@ and @out@, which are both mapping
from the arguments of the interpreter (@Config@) to the result values of the
interpreter (@Ans@). The @in@ cache contains what we already have computed from
the last iteration, the @out@ cache is what we will have computed after this
iteration joined with the previous one. When starting a new iteration, @in@ is
set to be the result of the last iteration, i.e., @out@; @out@ is set to be
empty. In the iteration, we first check whether @out@ contains what we want, if
yes then it is returned; otherwise, we retrieve what we have from @in@, compute
the result for this iteration, and put the joined result back into @out@. Note
that we also instrument the recursive call by putting @cached_ev@ into @evev@.
After one iteration, if @in == out@, then there is no more information to be
gained, thus the iteration should end and we have reached the fixed point.

\begin{lstlisting}
case class CacheFix(evev: EvalFun => EvalFun) {
  var in = Map[Config, Ans](); var out = Map[Config, Ans]()
  def cached_ev(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = {
    val cfg: Config = (e, $\rho$, $\sigma$)
    if (out.contains(cfg)) out(cfg)
    else {
      val ans0 = in.getOrElse(cfg, Lattice[(Value, Store)].bot)
      out = out + (cfg -> ans0)
      val ans1 = evev(cached_ev)(e, $\rho$, $\sigma$)
      out = out + (cfg -> (ans0 $\sqcup$ ans1));  ans1
    }
  }
  def iter(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = {
    in = out; out = Map[Config, Ans](); cached_ev(e, $\rho$, $\sigma$)
    if (in == out) out((e, $\rho$, $\sigma$)) else iter(e, $\rho$, $\sigma$)
  }
}
override def eval_top(e: Expr, $\rho$: Env, $\sigma$: Store): Ans = 
  CacheFix(eval).iter(e, $\rho$, $\sigma$)
\end{lstlisting}

Finally, we override the definition of @eval_top@ by instantiating @CacheFix@
with @eval@ and starting the first iteration.
