\section{From Interpreters to Staged Interpreters} \label{stagedinterp}

In this section, based on the generic interpreter and concrete components we
presented in Section \ref{prelim}, we show how to stage the concrete interpreter
by changing the monad type and refactoring several primitive operations. We
begin by briefly introducing the Lightweight Modular Staging framework in Scala,
and then replay the same steps from the unstaged counterpart. At last, we briefly
describe code generation.

\subsection{Multi-Stage Programming with LMS}

Lightweight modular staging (LMS) \cite{DBLP:conf/gpce/RompfO10} is a
multi-stage programming framework implemented as a Scala library that enables
dynamic code generation in a type-safe manner. Different from the approach of
MetaML/MetaOCaml \cite{DBLP:conf/flops/Kiselyov14, DBLP:conf/gpce/CalcagnoTHL03} that
uses syntactic quotations and quasiquotations, LMS distinguishes binding-time
based on types. LMS provides a type constructor @Rep[T]@ where @T@ can be
an arbitrary type, indicating a value of @T@ will be known at the next stage.
All operations acting on @Rep[T]@ expressions will be residualized as generated
code.

A classic example for introducing multi-stage programming is the power function
that computes $b^x$, which is usually implemented as a recursive function:
\begin{lstlisting}
  def power(b: Int, x: Int): Int = if (x == 0) 1 else b * power(b, x - 1)
\end{lstlisting}

If @x@ is a value know at current stage, we may specialize the power function to
some value @x@ -- by unrolling the recursive calls. In LMS, this is fulfilled by
first adding the @Rep@ type to the variable known at next stage. In this case,
@b : Rep[Int]@ is know later, and @x : Int@ is know currently, as shown in the
below code recipe.
The way we use this @power@ function is to create a @DslDriver@ and override the
@snippet@ method give the currently know value @x@ (5 in this example).
\begin{lstlisting}
  new DslDriver[Int, Int] {
    def power(b: Rep[Int], x: Int): Rep[Int] = if (x == 0) 1 else b * power(b, x-1)
    def snippet(b: Rep[Int]): Rep[Int] = power(b, 5) // specialize the power to b^5
  }
\end{lstlisting}

The LMS framework provides staging support for primitive data types such as
@Int@ and @Double@, and commonly-used data structures such as lists and maps.
The idea behind the framework is to construct a sea-of-node intermediate
representations (IR) for the next stage program at the current stage
\cite{DBLP:conf/birthday/Rompf16}. For convinence, the conversion from
expressions of type @Rep[_]@ to their IR is done by using the implicit design
pattern. As we will see later, implementing staging and code generation
support for user-defined classes is also straightforward.

\subsection{Staged Concrete Semantics}

To implement the staged concrete interpreter, we replay the steps from
instantiating unstaged concrete interpreter in Section \ref{unstaged_conc}.
But now we use the @Rep@ type to annotate value domains, environments and
stores, and redefine the staged version of monads and primitive operations.

\paragraph{Staged Monads}
We use the same structure of monad stack in the unstaged interpreter: a reader
monad with a state monad. But now the monads operate on staged values, for
brivity, we call them \textit{staged monads}. In the code, we also use a @Rep@
prefix on the constructors and types to differentiate them. But it is important
to note that objects of a case class @ReaderT@/@StateT@ are not staged, the
monadic computation like @R => M[A]@ are also not staged. Instead, the internal
data that these monads operate on are staged, i.e., @R@ and @A@ in the
reader monad, @S@ and @A@ in the state monad. The following code
snippet shows the idea. We use \hl{light gray} to highlight where @Rep@ type is added:
\begin{lstlisting}[escapechar=!]
  case class RepReaderT[M[_]: RepMonad, R, A](run: !\hl{Rep[R]}! => M[A]) {
    def flatMap[B](f: !\hl{Rep[A]}! => ReaderT[M, R, B]): RepReaderT[M, R, B] =
      RepReaderT(r => RepMonad[M].flatMap(run(r))(a => f(a).run(r))); ... }
  case class RepStateT[M[_]: RepMonad, S, A](run: !\hl{Rep[S]}! => M[(A, S)]) {
    def flatMap[B](f: !\hl{Rep[A]}! => StateT[M, S, B]): RepStateT[M, S, B] =
      RepStateT(s => RepMonad[M].flatMap(run(s))(as => f(as._1).run(as._2))); ... }
\end{lstlisting}

The function @f@ passed to @flatMap@ is also a current-stage-known value, so
that all the invocation of @flatMap@s can be completed before generating code.
The fact that we only stage data but not monadic computation or monadic
values, is the reason that we can peel of the monad stack in the generated code.
Now the @AnsM[_]@ is instantiated as the same structure as before, but using the
@Rep@ versions:
\begin{lstlisting}
  type R[T] = Rep[T]
  type AnsM[T] = RepReaderT[RepStateT[RepIdM, Store, ?], Env, T]
\end{lstlisting}

Readers may notice that the conversion between unstaged monads and staged monads
is merely changing the type of unstaged data to staged data, which in fact can be
achieved without modifying the implementation of monads. This is true so far, but
as we will see, it is not straightfoward when for nondeterminism monad
(@SetT@) in abstract interpreters. Because not only the elements in the set are staged,
but the whole set is also staged, and we have no knowledge about how many elements
in the set. In this section, we explicitly distinguish the two versions of monadic interfaces,
later we will instantiated staged set monad using a different strategy.

\paragraph{Primitive Operations} Most of the primitive operations can be easily
translated to their staged versions -- we just need to change the types.
As we mentioned before, we will take more care on how functions and
applications are handled. The problem here is what should we do for
lambda terms when staging? We cannot create a next-stage
defunctionalized closure for it, because it means we still need to
access the interpreter at the next stage. The desired goal is to eliminate the
interpretation overhead staging, so the right thing is compiling the lambda term
and its environment to a next-stage Scala function. To do this, we need to
recursively call the interpreter function, i.e., the @ev@ argument passed to @close@.
The following code implements the idea:

\begin{lstlisting}
  def emit_compiled_clo(f: (Rep[Value], Rep[Store]) => Rep[(Value, Store)]): Rep[Value]
  def close(ev: Expr => Ans)(λ: Lam, ρ: Rep[Env]): Rep[Value] = {
    val Lam(x, e) = λ
    val f: (Rep[Value], Rep[Store]) => Rep[(Value, Store)] = {
      case (v: Rep[Value], σ: Rep[Store]) =>
        val α = alloc(σ, x); val ρ_* = ρ + (unit(x) → α); val σ_* = σ + (α → v)
        ev(e)(ρ_*)(σ_*)
    }; emit_compiled_clo(f)
  }
\end{lstlisting}

We have created a current function @f@ that takes a next-stage value
and store, and returns staged value. Then we use @emit_complied_clo@
to delay @f@ to a next Scala function, represented by the type
@Rep[Value]@. Inside of @f@, we

To make this happen, when
closing a lambda term, we need to specialize the body expression by
\textit{collpasing} the @AnsM@ monads to normal values. The
following function @close@ illustrates the idea: @f@ is a current stage function
but takes two next-stage values @v@ and $\sigma$, inside of which, we eagerly
collapse the monads to values by @ev(e)(ρ_*)(σ_*)@, which has type
@Rep[(Value, Store)]@. Then we generate the next-stage value of the compiled
closure using @emit_compiled_clo@, containing the compiled closure.


When applying a function in @ap_clo@, we also generate the next-stage value
for closure application through @emit_ap_clo@, assuming that the @rator@ is already an
IR of compiled closure, @rand@ is an arbitrary stage value, and $\sigma$ is the
latest store. @emit_ap_clo@ represents the result value of the application, which has type
@Rep[(Value, Store)]@. Note that @emit_ap_clo@ is an ordinary value from the
future, and there are no monads in the future, so we need to reify the value and
store back into the monad stack through @put_store@ and @yield@.

\begin{lstlisting}
  def emit_ap_clo(rator: Rep[Value], rand: Rep[Value], σ: Rep[Store]): Rep[(Value, Store)]
  def ap_clo(ev: Expr => Ans)(rator: Rep[Value], rand: Rep[Value]): Ans = for {
    σ <- get_store
    val res: Rep[(Value, Store)] = emit_ap_clo(rator, rand, σ)
    _ <- put_store(res._2)
  } yield res._1
\end{lstlisting}

\subsection{A Little Bit Code Generation}

The method @emit_compiled_clo@ and @emit_ap_clo@ mentioned above produces
intermediate representations for the denoted operations in LMS. These IRs are
wrappers of the underlying staged data. We define these IR nodes using
@case class@ extending from @Def[T]@, meaning that they are next-staged definitions of type @T@.

\begin{lstlisting}
  type ValSt = (Value, Store)
  case class IRCompiledClo(f: Rep[(ValSt) => ValSt], λ: Lam, ρ: Rep[Env]) extends Def[Value]
  case class IRApClo(rator: Rep[Value], rand: Rep[Value], σ: Rep[Store]) extends Def[ValSt]
\end{lstlisting}

After constructing the IR graph, LMS provides an @emitNode@ to generate code for
each kind of IR node. To generate code for @IRApClo@, we know that @rator@ is a
compiled closure @IRCompiledClo@, which contains a next-stage function @f@, so
we just need to generate code that invokes @f@ with @rand@ and @σ@ as arguments
provided. Similarly, we directly generate a next-stage value @CompiledClo(f)@
for @IRCompiledClo@.

\begin{lstlisting}
  override def emitNode(sym: Sym[Any], rhs: Def[Any]) = rhs match {
    case IRApClo(rator, rand, σ) => emitValDef(sym, s"$\textdollar$rator.f($\textdollar$rand, $\textdollar$σ)")
    case IRCompiledClo(f, λ, ρ) => emitValDef(sym, s"CompiledClo($\textdollar$f, $\textdollar$λ, $\textdollar$ρ)")
    ...
  }
\end{lstlisting}
