\section{From Interpreters to Staged Interpreters} \label{stagedinterp}

In this section, based on the generic interpreter and concrete components we
presented in Section \ref{prelim}, we show how to obtain a staged concrete
interpreters by changing the monads and refactoring several primitive
operations. We begin by briefly introducing the Lightweight Modular Staging
framework in Scala.

\subsection{Multi-Stage Programming with LMS}

Lightweight modular staging (LMS) \cite{DBLP:conf/gpce/RompfO10} is a
multi-stage programming framework implemented as a Scala library that enables
dynamic code generation in a type-safe manner. Different from the approach of
MetaOCaml \cite{DBLP:conf/flops/Kiselyov14, DBLP:conf/gpce/CalcagnoTHL03} that
uses syntactic quotation and escape, LMS distinguishes binding-time solely based
on types. LMS provides a type constructor @Rep[T]@ where @T@ can be an arbitrary
type, indicating a value of @T@ will be known at next stage. All operations
acting a @Rep[T]@ expression will be residualized as generated code.

The LMS framework provides staging support for primitive data types such as
@Int@ and @Double@, and commonly-used data structures such as arrays and maps.
The idea is to construct intermediate representations (IR) for the next-stage
program at current stage. Such conversion from expressions of type @Rep[_]@ to
their IR is done by using implicit design pattern. As we will see later,
implementing the staging support for custom classes is also straightforward.

For example, let us go back and see how LMS can be used to specialize the
@power@ function from Section ~\ref{intro}.

\begin{lstlisting}
new DslDriver[Int, Int] {
  def power(b: Rep[Int], x: Int): Rep[Int] = if (x == 0) 1 else b * power(b, x-1)
  def snippet(x: Rep[Int]): Rep[Int] = power(x, 5)
}
\end{lstlisting}

\todo{Show some IR}

\subsection{Staged Concrete Semantics}

To implement the staged concrete interpreter, we reuse the exactly same concrete
components from Section \ref{unstaged_conc}, but we instantiate the binding-time
type @R[T]@ as @Rep[T]@.

\paragraph{Staged Monads} We also need to use monads that operate on staged
values. Note that the monadic objects such as @StateT@ or the internal value
@R[S] => M[(A,S)]@ are not staged, only the data @S@ or @A@ are staged.
This is why we can completely eliminate the overhead caused by the monadic layers.
Here we use the prefix name @Rep@ to differentitate unstaged monads and staged
monads, such as @RepReaderT@. So the @AnsM[_]@ is instantiated as the same monad
stack before, but with @Rep@ versions.

\begin{lstlisting}
  type R[T] = Rep[T]
  type AnsM[T] = RepReaderT[RepStateT[RepIdM, Store, ?], Env, T]
\end{lstlisting}

We use @RepStateT@ as an example to give a sketch of how the @Rep@ versions of monad
transformers look like. The generic type @M[_]@ is a @RepMonad@ and used as the
inner monad, which means the pair @(A,S)@ is also staged when appears inside of monad
@M[_]@. The @flatMap@ is similar to the unstaged one, but the function @f@ takes
a @Rep[A]@ value. Again, @f@ is not a next-stage function, but a current-stage
function that transforms a next-stage value of @Rep[A]@ to @StateT[M,S,B]@.
\todo{highlight the changes in the code}

\begin{lstlisting}
  case class RepStateT[M[_]: RepMonad, S, A](run: Rep[S] => M[(A, S)]) {
    def flatMap[B](f: Rep[A] => StateT[M, S, B]): StateT[M, S, B] = ...
  }
\end{lstlisting}

Readers may notice that the conversion between unstaged monads and monads is 
simply changing the unstaged data to staged data, which in fact can be achieved without
changing the implementation of monads. This is true so far, but as we will see
when introducing the nondeterminism monad (@ListT@) for abstract interpreters, as
the whole list will be a next-stage value instead of merely the elements in the list.
For this reason, we explicitly distinguish and present the two version of
monads, as a more consistent approach.

\paragraph{Primitive Operations} Most of the primitive operations can be easily
translated to staged version -- we just need to let them works on staged data.

\begin{lstlisting}
  def emit_ap_clo(fun: Rep[Value], arg: Rep[Value], σ: Rep[Store]): Rep[(Value, Store)]
  def emit_compiled_clo(fun: (Rep[Value], Rep[Store]) => Rep[(Value, Store)],
                        λ: Lam, ρ: Rep[Env]): Rep[Value]

  def close(ev: EvalFun)(λ: Lam, ρ: Rep[Env]): Rep[Value] = {
    val Lam(x, e) = λ
    val f: (Rep[Value], Rep[Store]) => Rep[(Value, Store)] = {
      case (v: Rep[Value], σ: Rep[Store]) =>
        val α = alloc(σ, x)
        ev(e)(ρ + (unit(x) → α))(σ + (α → v))
    }; emit_compiled_clo(f, λ, ρ)
  }
  def ap_clo(ev: EvalFun)(fun: Rep[Value], arg: Rep[Value]): Ans = for {
    σ <- get_store
    val res: Rep[(Value, Store)] = emit_ap_clo(fun, arg, σ)
    _ <- put_store(res._2)
  } yield res._1
\end{lstlisting}

\paragraph{Code Generation}

\begin{lstlisting}
  case class IRApClo(f: Exp[Value], arg: Exp[Value], σ: Exp[Store]) extends Def[(Value, Store)]
  override def emit_ap_clo(fun: Exp[Value], arg: Exp[Value], σ: Exp[Store]): Exp[(Value, Store)] =
    IRApClo(fun, arg, σ)
\end{lstlisting}

\begin{lstlisting}
  override def emitNode(sym: Sym[Any], rhs: Def[Any]) = rhs match {
    case IRApClo(f, arg, σ) =>
      emitValDef(sym, s"$\textdollar${quote(f)}.asInstanceOf[CompiledClo].f($\textdollar${quote(arg)}, $\textdollar${quote(σ)})")
    ...
  }
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the staging part, we share the same concrete type instantiation, i.e., trait
\texttt{Concrete}, but we reimplement the staged version for the concrete
operations in trait @RepConcInterpOps@. Meanwhile, it is also extended from
@LMSOps@ which provides necessary support for the staged version of primitive
types and data structures. To stage the interpreter, we first identify the
syntactic input that is known statically, and the interpreter returns a pair of
values and store, which both becomes dynamic values. Thus the staged stores
propagate the binding-time to environments, because they share the same address
component.


The first notable change is that the abstract type member @R@ is assigned to be
@Rep@, and accordingly the affected types such as @Env@ and @Store@ become
@Rep[Env]@ and @Rep[Store]@. For @num@, we use the @lift@ function which is a
built-in in LMS that lifts a current-stage value to next stage. The interesting
point is how we handle closures and function applications when staging is
involved. In the unstaged version, function @close@ is used to lift a literal
lambda term to a closure, which is a pair of the syntactic lambda term and the
enclosing environment. However, what we desire is a \textit{compiled} closure,
instead of a lifted @CloV@ value like what we did for @NumV@ --- in other words,
the syntactic term of the lambda expression should be eliminated and specialized
away. The specialization of the interpreter with respect to the body of the
lambda term proceeds under the assumptions that the argument and latest store
will be provided later.

We will see this is an important observation that enables us to specialize an
abstract interpreter in a modular way. At the end of function @close@, we create
a @CompiledClo@ object that contains a staged function, which all will be
emitted in the generated code.

\begin{lstlisting}
def close(ev: EvalFun)($\lambda$: Lam, $\rho$: Rep[Env]): Rep[Value] = {
  val Lam(x, e) = $\lambda$
  val f: Rep[(Value,Store)]=>Rep[(Value,Store)] = { 
    case (arg: Rep[Value],$\sigma$: Rep[Store]) =>
      val $\alpha$ = alloc($\sigma$, x)
      ev(e, put($\rho$, x, $\alpha$), put($\sigma$, $\alpha$, arg)) 
  }
  CompiledClo(fun(f))
}
\end{lstlisting}

Next, @apply_closure@ takes three arguments: the function value, argument value
and the latest store, which are all of @Rep@ type. This means basically there
is nothing we can do at the current stage --- so we create a new node
@ApplyClosure@ that contains these arguments in the intermediate representation
graph, and in the code generation phase we can emit the code that performs the
application. The additional @reflectEffect@ is a function in LMS that handles
side effects.

\begin{lstlisting}
case class ApplyClosure(f: Rep[Value], arg: Rep[Value], $\sigma$: Rep[Store]) extends Def[(Value, Store)]
def apply_closure(ev: EvalFun)
  (f: Rep[Value], arg: Rep[Value], $\sigma$: Rep[Store]): Ans = {
    reflectEffect(ApplyClosure(f, arg, $\sigma$))
  }
\end{lstlisting}


When generating code for the next stage, values like @CompiledClo@ and @NumV@
are kept as they are because they are intended exist in the next stage; however,
we need to treat @ApplyClosure@ a little differently.

Concretely, as shown in the code above, when emitting code for @ApplyClosure@,
we just emit a function application where the function value is extracted from
the @CompiledClo@ object (we assume the input program is well-typed so that we
can safely cast it to @CompiledClo@). Argument and a store are the remaining rest
fields in @ApplyClosure@.