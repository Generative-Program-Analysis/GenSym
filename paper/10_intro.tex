\section{Introduction}

\subsection{Motivation}

Futamura projection \cite{Futamura1999, futamura1971partial} reveals the close relation between 
compilers and interpreters, 
and the first Futamura projection specifically shows that specializing an interpreter yields a compiler. 
Multi-stage programming (MSP) \cite{taha1999multi, DBLP:conf/pepm/TahaS97} is a popular way to write 
generic programs that and generates specialized and efficient programs; 
the generated program then can be executed at next stage. 
As an approach to partial evaluation, MSP requires explicit staging annotations from the implementers.
The staging annotations controls which part of the program should be specialized, and are considered 
as manual binding-time analysis. On the other hand, partial evaluation \cite{DBLP:books/daglib/0072559} 
can be considered as a two-stage (static or dynamic) instance of MSP but analyzing binding-time automatically.

Recent research uncovers a systematic approach to construct sound abstract interpreters 
from concrete interpreters \cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10, DBLP:journals/pacmpl/DaraisLNH17}.
Given the structural similarity between concrete and abstract interpreters, intellectually 
it is natural to raise the question whether it is possible to stage an abstract interpreter, and how 
to effectively specialize an abstract interpreter having considered their functional dissimilarity. 
This paper studies the application of the first Futamura projection on abstract interpreters, 
and the approach to construct efficient abstract interpreters by multi-stage programming.

Multi-stage programming has been widely used to improve the performance in many domains, 
such as optimizing compilers and domain-specific languages \cite{DBLP:conf/pldi/RompfSBLCO14, DBLP:conf/snapl/RompfBLSJAOSKDK15,
DBLP:journals/tecs/SujeethBLRCOO14, DBLP:conf/gpce/SujeethGBLROO13, DBLP:journals/jfp/CaretteKS09},
numerical computation \cite{PGL-038, DBLP:conf/pepm/AktemurKKS13}, 
generic programming \cite{DBLP:journals/pacmpl/Yallop17}, 
data processing \cite{DBLP:conf/oopsla/JonnalageddaCSRO14, DBLP:conf/popl/KiselyovBPS17}, 
query compilation in databases \cite{DBLP:conf/osdi/EssertelTDBOR18, DBLP:conf/sigmod/TahboubER18},
and etc.
Likewise, specializing static analyses by partial evaluation had been emerged in 1990s 
\cite{damian1999partial, amtoft1999partial, Boucher:1996:ACN:647473.727587, ashley:practical}, 
and indeed it is able to effectively remove the interpretive overhead of 
repeatedly traversing the abstract syntax tree. However, it is still worth 
to investigate the idea deeper from a modern perspective based on meta-programming 
for general abstract interpreters.
Practically, precise whole-program analyses formulated as abstract interpretation 
can be very slow due to the inherent complexity of the algorithm and the large scale 
of the analyzed programs \cite{toman_et_al:LIPIcs:2017:7121} \todo{other cite?};
particularly, we would like a systematic approach to optimize program 
analyzers and meanwhile minimally modifying the analyzer programs.
In the present work, we show how to achieve this goal by bring existing 
high-performance computing facilities, in the style of multi-stage generative
programming, to abstract interpretation semantic artifacts, i.e., 
abstract interpreters. 

The slogan of multi-stage programming is "abstraction without regret". 
Of course, all interpreters are metalinguistic abstractions, but some interpreters are more "abstract"
than others \todo{maybe rephrase}. 
One technical challenge is to deal with the non-determinisism, fixed-point iterations and abstract 
domains in abstract interpreters when staging is introduced. The abstract interpreter, as a semantic artifact, 
should be written in a style that is easy for people to communicate the formulation, but also be friendly
to specialization and generating efficient code. \todo{We discuss the form of abstract interpreters for staging}
We show the use LMS framework, that enables multi-stage programming by just changing the types 
of the analyzer program, and we thus bridge the gap between designing sound program analyses 
and implementing efficient program analyzers.

When staging a concrete interpreter, the programmers need to distinguish 
static and dynamic values --- the given program to be executed by the 
interpreter is classified as static because it is known at compile-time, 
and the inputs to that program are dynamic.  However, when staging an 
abstract interpreter, this distinction not exists anymore. Because the 
abstract interpreter instantiates all the inputs as some form of abstract 
values, which are usually top elements in their abstract domains and are 
also statically known. Then what is the point of staging if no such distinction?
A surprising by-product of thinking about this question is to realize that 
we can apply the staged abstract interpreter on \textit{open} programs, and
the free variables representing other parts of the program (e.g., libraries) 
are dynamic input, therefore we obtain a modular analysis through staging, 
mechanically. 

The use of staged abstract interpreters on open programs improves the scalability.
One challenge in static analysis of modern software is that the programs are usually 
shipped with large library code, for example, it has been shown that analyzing a simple
"Hello World" program in Java depends on additional 3,000 classes in the library \cite{DBLP:conf/oopsla/KulkarniMZN16}.
Soundly and precisely analyzing these libraries sometimes are expensive and unnecessary repeatedly.
When applying the staged abstract interpreter on libraries, we leave the unknown 
calling context as dynamic value and generate partial analyzing result which is 
repsented as a residul program. The partial analyzing result can be resued and composed
with the analyzing result of application code when available later. 
It has been observed that partially applying context-sensitivity on selected portion of the program could
improve the precision and efficiency \cite{zipper2018, Kastrinis:2013:HCP:2491956.2462191}. 
We show that staging abstract interpreters as an approach to effectively implement hybird context-sensitivity\todo{}.

staged polymorphism, decide when to compile an analysis.  
% Many optimization of static analysis are ad-hoc.

\subsection{Contributions}

\begin{itemize}
\item Starting from a definitional abstract interpreter for a higher-order functional language,
  which the syntax and semantics are described in section \ref{bg_lang},
  we show how to turn it into a staged abstract interpreter by adding stage annotations within
  Lightweight Modular Staging (LMS) framework, a library-based approach to code generation. 
  We later extend the staged abstract interpreter to support imperative language features 
  (section \ref{cases_imp}), such as states, loops and exceptions.
\item We elaborate the idea that the staged abstract interpreter not only improves the \textit{efficiency}
  but also the \textit{scalability}, which are two major issues in static analysis, if we apply it on open
  programs. \todo{more on this point.}
\item To demonstrate the feasibility and applicability of the proposed approach, we conduct three case studies in section \ref{cases_study}. 
  First we revisited Abstract Compilation \cite{Boucher:1996:ACN:647473.727587}, which is a closure generation 
  technique applied on 0-CFA. We show that it can be understood and easily implemented as an instance of 
  staged abstract interpreter. 
  Second, we demonstrate sophisticated control-flow analysis techniques, such as adaptive context/flow/path-sensitive 
  analysis and store-widening can be integrated with staged abstract interpreters without losing any precision.
  Finally, we show that in an imperative language, the idea can be applied onto an abstract interpreter with
  an abstract domain that performs numerical analysis.
  (Optional: taint/information flow analysis?)
\item We also empirically evaluate the speed improved by staging an big-step abstract interpreter 
  for control-flow analysis. We compare against with the unstaged version, a small-step version (unstaged), 
  and an optimizing small-step version.
\end{itemize}
