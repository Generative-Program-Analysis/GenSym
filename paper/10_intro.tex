\section{Introduction}

\subsection{Motivation}

1. Futamura projection \cite{Futamura1999} shows that staging an interpreter yields a compiler.
literature on this approach, creating DSL.

Recent research uncovers a systematic approach to construct abstract interpreters from concrete interpreters.
Given the structural similarity between abstract and concrete interpreters, intellectually it is natural to 
wonder what would be a staged abstract interpreter, and how to stage an abstract interpreter 
having considered their functional dissimilarity.

2. Multi-stage programming is widely used in high performance computation.
Precise whole-program analysis can be very slow, how to optimize it systematically/mechanically?
bring existing high-performance computation facilities, in the form of meta-programming, into
semantic artifacts of abstract interpretation, i.e., abstract interpreters.
and bridging the gap between designing sound analyses and implementing efficient analyses.
without changing the abstract interpreter, just type

partial evaluation on program analyzers is not a new idea, remove the interpretive overhead of repetively 
traversing the abstract syntax tree.
we revisit this approach from a more recent perspective by combining general abstract interpreters
and multi-stage programming.

When staging a concrete interpreter, the programmers need to distinguish static and dynamic values
--- the given program is classified as static because it is known at compile-time, and the inputs to that program 
are dynamic. However, when staging an abstract interpreter, this distinction not exists anymore. 
Because an abstract interpreter treats all the inputs as some form of abstract values, which usually are 
top elements in their abstract domains and are statically known. Then what is the point of staging?
A surprising by-product of thinking about this question is to realize that we can apply the staged
abstract interpreter on \textit{open} programs, and the free variables representing other parts of 
the program (e.g., libraries) are dynamic input, then we obtain a modular analysis, mechanically.

3. analyzing modern programs with large libraries are expensive. 
why? 1. precise analysis usually required whole-program analysis; 2. to do wp analysis, need to 
repetitively analyze the parts of library.
As modularity in compilers, we need to a way to separately analyze programs, and create summaries of analyzed 
part so that we can reuse them, remove redundant analyzing of libraries.

\subsection{Contributions}

\begin{itemize}
\item Starting from a definitional abstract interpreter for a higher-order functional language,
  we show how to turn it into a staged abstract interpreter by adding stage annotations with 
  Lightweight Modular Staging (LMS) framework, a library-based approach to code generation. 
  We later extend the abstract interpreter to support
  imperative language features, such as states, loops and exceptions.
\item We elaborate the idea that the staged abstract interpreter not only improves the performance 
  but also the scalability, which are two major issues in static analysis, if we apply it on open
  programs. TODO: more on this point.
\item To evaluate the generality of the idea, we conduct several case studies. 
  First we revisited Abstract Compilation (TODO: cite), which is a closure generation technique applied 
  on 0-CFA and can be understood as an instance of staged abstract interpreter. 
  Second, we demonstrate existing control-flow analysis techniques, such as context/flow/path-sensitive 
  analysis and store-widening can be integrated with staged abstract interpreters.
  Finally, we show it also can be applied to numerical analysis in an imperative language.
  (Optional: taint/information flow analysis?)
\item We also emprically evaluate the performance improved of staged abstract interpreter with the
  unstaged version and other existing optimizations on benchmarks.
\end{itemize}
