\section{Introduction} \label{intro}

Abstract interpretation as a lattice-based approach to sound static analyses was
proposed by \citet{DBLP:conf/popl/CousotC77}. Based on the notion of Galois
connections \cite{CousotCousot79-1}, the analyzer can soundly approximate the
concrete program runtime behavior by computing fixed points on an abstract
domain. Despite the tremendous theoretical development of abstract
interpretation over the years, constructing artifacts and analyzers that perform
sound abstract interpretation for modern and expressive languages was considered
complicated for a long time.

Recent progress on methodologies such as Abstracting Abstract
Machine (AAM) \cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10}
uncovers an approach to constructing abstract interpreters from
systematic principles, rather than ad-hoc engineering.  By deriving
semantics artifacts for abstract interpretation from their concrete
counterparts (for example, abstract machines), soundness can be
easily established by examining the transformation of semantic
artifacts.
This systematic abstraction approach can be tailored to different
language features (such as state, first-class control, exception, and
concurrency) and sensitivity analyses \cite{DBLP:conf/icfp/Gilray0M16,
  DBLP:conf/popl/GilrayL0MH16, Darais:2015:GTM:2814270.2814308}. It
has also been applied to various small-step abstract machines
\cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10,
  Sergey:2013:MAI:2491956.2491979} and big-step definitional
interpreters \cite{Wei:2018:RAA:3243631.3236800,
  DBLP:journals/pacmpl/DaraisLNH17, Keidel:2018:CSP:3243631.3236767}.

Based on the idea of abstracting abstract machines, more
pragmatically, several implementation strategies utilizing purely
functional programming techniques to build abstract interpreters have
emerged. Such techniques include monads, monad transformers
\cite{DBLP:journals/pacmpl/DaraisLNH17,
  Sergey:2013:MAI:2491956.2491979}, arrows
\cite{Keidel:2018:CSP:3243631.3236767}, extensible effects
\cite{Kiselyov:2015:FMM:2804302.2804319}, etc. The pure approaches provide certain
benefits, including that the abstract interpretation artifacts can be
built compositionally and modularly, e.g., by using monad
transformers. Therefore, the soundness of analysis can be proven with
less effort, whether by mechanized proofs
\cite{Darais:2016:CGC:2951913.2951934} or paper-based proofs
\cite{Keidel:2018:CSP:3243631.3236767}.  Also, referential
transparency and equational reasoning allow programmers to
confidently reason about the correctness of their implementations.

However, besides the intrinsic complexity of static analysis, there
are additional abstraction penalties from these high-level
implementation approaches. First, similar to concrete interpreters,
an abstract interpreter analyzes the program by traversing the
abstract syntax tree (AST), which incurs interpretive overhead, such
as the pattern matching on the ASTs and recursive calls on the
subexpressions.
Such overhead can be negligible if the abstract interpreter only runs
on the program a single time, but can accumulate significantly if
run repeatedly (for example, on libraries).  Second, it is common that
abstract interpreters written in pure languages extensively use effect
systems to implement the semantics of abstract interpretation. For
example, the collecting interpreter that returns all possible runtime
values is a form of nondeterminism, where nondeterminism monads can
help.  Although such pure approaches have their own merits, compared
with imperative stateful implementations, they are significantly
slower.

Roughly at the same when abstract interpretation was proposed in
1970s, \citet{futamura1971partial, Futamura1999} revealed a close
connection between interpreters and compilers through a hierarchy of
specializations, namely, Futamura Projections. The first Futamura
projection shows that specializing an interpreter to the input program
removes interpretation overhead and yields an equivalent executable
that runs faster.  The challenge here: can we apply the same idea to
general abstract interpreters to make hem run faster?
To achieve this, we need to handle a nonstandard semantics that
extensively uses nondeterminism, operates on abstract domains, and
computes fixed-point iteratively with a cache.

In this paper, we show that the first Futamura projection can be naturally
extended to abstract interpreters. We present an abstraction-without-regret
framework to eliminate performance penalties for abstract interpreters, while
keeping the benefits inherent in purely functional programming. In short, our
approach borrows ideas and techniques from multi-stage programming and embedded
DSLs to abstract interpreters:  1) To remove the overhead from interpretation
and effect layers, we specialize the abstract interpreter with respect to an
input program and then generate efficient low-level code that does the actual
analysis.  2) Inspired by the tagless-final interpreters
\cite{DBLP:journals/jfp/CaretteKS09}, we construct a generic interpreter that
abstracts over binding-time and different semantics, which allows user to
implement different semantics modularly, including the staged abstract
interpretation semantics. As a result, we can derive the staged abstract
interpreters without intrusive changes to its corresponding unstaged
counterpart, and also preserve the soundness of analysis. In this sense, our
approach allows for no regret for both performance and engineering effort. We
elaborate these two main ideas in detail, as follows.

%The result of specialization is reusable, and the effect layers have
%been eliminated in the generated code.

\paragraph{Futamura Projection of Abstract Interpreters}

The first Futamura projection specifically shows that specializing an
interpreter w.r.t. the input program yields an equivalent
executable. For instance,
\lstinline[keywordstyle=,flexiblecolumns=false,mathescape=false,basicstyle=\tt]{eval}
is an interpreter for some language:
\begin{lstlisting}
  def eval(e: Expr)(arg: Input): Value
\end{lstlisting}
Given a program $e_0$ of type
\lstinline[keywordstyle=,flexiblecolumns=false,mathescape=false,basicstyle=\tt]{Expr},
by applying the specialization, we can obtain a specialized
interpreter $\texttt{eval}_{\texttt{e0}}$ :
\lstinline[keywordstyle=,flexiblecolumns=false,mathescape=false,basicstyle=\tt]{Input}
$\to$
\lstinline[keywordstyle=,flexiblecolumns=false,mathescape=false,basicstyle=\tt]{Value},
which is the so-called \textit{equivalent executable}.

% By definition of the interpreter, they produce the same result when applied with the argument $\texttt{eval}_{\texttt{e0}}(arg) = [\![ e_0 ]\!] arg $.

Partial evaluation \cite{DBLP:books/daglib/0072559} was the first proposed
approach to realize Futamura projections: it first discovers the binding-times
(\textit{static} or \textit{dynamic}) of variables, then evaluates the static
part of the program, and generates a residualized program that solely relies on
the dynamic part. However, it is hard to precisely analyze binding-times given
an arbitrary program. As an alternative approach, multi-stage programming (MSP)
\cite{taha1999multi, DBLP:conf/pepm/TahaS97} lets users explicitly program over
a two-level semantics \cite{NIELSON198859}, by manually annotating the
binding-times of variables in the program. Then, the MSP system will check
whether these annotations are consistent, and specialize the program using that
information. The staging annotations can be either syntactic (e.g., quote and
quasi-quote in MetaML/MetaOCaml) or type-based (e.g., the Lightweight Modular
Staging framework \cite{DBLP:conf/gpce/RompfO10} in Scala).

Similar to two-level semantics \cite{NIELSON1989117}, we found
monads provide a good abstraction to hide the detail of abstract
interpretation semantics, and allows us to fit code generation into
the semantics. We use \citet{DBLP:journals/pacmpl/DaraisLNH17}'s
abstract definitional interpreter that uses monad transformers as the
unstaged baseline.  Our proposed framework adopts the type-based
multi-stage programming from the Lightweight Modular Staging framework,
and implements the Futamura projection of a big-step abstract
interpreter for a small, stateful, higher-order language. By deriving
staged monads that can be used to do code generation, we obtain a
staged abstract interpreter that fulfills the specialization. After
staging, the generated code is specialized to the input program, and
all monadic operations are inlined and compiled down to low-level
Scala code.

\input{fig_confluence.tex}

\paragraph{Generic Interpreter and Reinterpretation}

Program specialization and abstract interpretation are two orthogonal
concepts.  To implement the confluence of them, we first construct a
generic interpreter that is agnostic to both binding-times and value
domains used in the semantics.  Later, the generic interpreter can be
instantiated from these two dimensions (Figure~\ref{confluence}):
\begin{itemize}
\item With a flat binding-time and concrete domains, it is an ordinary
  definitional interpreter based on big-step operational semantics;
\item With two-level binding-times and concrete domains, it is a
  compiler that translates a program into another language;
\item With a flat binding-time and abstract domains, it is a
  definitional abstract interpreter \cite{DBLP:journals/pacmpl/DaraisLNH17}
  that statically computes runtime properties;
\item With two-level binding-times and abstract domains, it is an optimizing
  program analyzer, but works in the fashion of compilation.
\end{itemize}

Although the four artifacts may look like dissimilar at first
glance, they in fact are all firmly rooted in the concrete semantics of
the language.  This observation provides a way to abstract over the
interpreter and achieve the flexibility of reinterpreting the shared
interpreter. Generic interpreters using monads have already been
applied to abstract interpreters; we further introduce the
binding-time abstraction into the generic interpreter.  The generic
interpreter returns a value of monadic type, which can be varied by
different semantics. The domain of the interpreter and the effects
such as read, state, and nondeterminism can all be wrapped into this
monadic type.  The binding-time abstraction is represented by a
higher-kinded type, and controls whether the interpreter produces
values directly or generates code. It is worth mentioning that the
binding-time type is also injected into the monadic type, so that we
will distinguish normal monads and staged monads.

\paragraph{Applications and Evaluations}
We evaluate the idea of staging an abstract interpreter through
case studies and an empirical evaluation on performance.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, an implementation technique for
control-flow analyses, and show that by utilizing type-based stage
annotations we can achieve the same optimizations. Meanwhile,
the analyzer does not need to change, thereby requiring significantly less
engineering effort.
2) We extend the basic staged abstract interpreter to different flow
analyses, including a store-widened analysis, a context-sensitive
analysis, and abstract garbage collection.
3) We show that staging an abstract interpreter enables modular
compilation of an analysis to programs. Here we borrow the concept of
modular analysis, and show that the compiled analysis is reusable.
Therefore, the approach provides a modular way to create optimized
analysis code by mechanized reuse of a whole-program analyzer.
4) We also empirically evaluate the performance improvements gained by staging,
showing an order of magnitude speedup on flow-analysis.

\paragraph{Contributions} Briefly, the contributions of the paper are as follows:
\begin{itemize}[leftmargin=2em]
  \item To our best knowledge, we present the first
    multi-stage programming system to specialize a general abstract interpreter,
    without our approach affecting the soundness of analyses.
  \item Intellectually, our framework naturally extends the first
    Futamura projection to abstract interpreters, showing a
    well-grounded approach to optimizing static analyses via
    meta-programming.
  \item Practically, we show that staging an abstract interpreter is
    useful to improve performance and scalability of analyses by case
    studies and an empirical evaluation.
\end{itemize}

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our target language and reviewing
    monads in Scala, and then presenting the generic interpreter
    (Section~\ref{prelim}), after which we review instantiations
    of concrete interpretation (Section~\ref{unstaged_conc}) and
    staged concrete interpretation (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same
    framework by replacing the environment, store, and values to their
    abstract counterparts (Section~\ref{unstaged_abs}). We then
    show that the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived
    (Section~\ref{sai}). We also summarize the approach and discuss
    soundness properties after showing the four artifacts.
  \item We conduct three case studies (Section~\ref{cases_study}) and
    an empirical evaluation on performance improvements (Section~\ref{evaluation}).
    Finally we discuss related work and conclude.
\end{itemize}

\iffalse
On the other side, static analysis is a trade-off between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
