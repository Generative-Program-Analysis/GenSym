\section{Introduction}

\subsection{Motivation}

Futamura projection \cite{Futamura1999, futamura1971partial} reveals the close relation between 
compilers and interpreters, 
and the first Futamura projection specifically shows that specializing an interpreter yields a compiler. 
Multi-stage programming (MSP) \cite{taha1999multi, DBLP:conf/pepm/TahaS97} is a popular way to write 
multi-stage programs that specializes and generates programs; the generated program then can be executed 
at next stage. 
As an approach to partial evaluation, MSP requires explicit staging annotations from the implementers.
The staging annotations controls which part should be specialized, and are considered as manual 
binding-time analysis. On the other hand, partial evaluation \cite{DBLP:books/daglib/0072559} can be 
considered as a two-stage (static or dynamic) instance of MSP but analyzing binding-time automatically.

Recent research uncovers a systematic approach to construct sound abstract interpreters 
from concrete interpreters \cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10, DBLP:journals/pacmpl/DaraisLNH17}.
Given the structural similarity between concrete and abstract interpreters, intellectually 
it is natural to wonder what would be a staged abstract interpreter, and how to effectively 
specializing an abstract interpreter having considered their functional dissimilarity. 
In this paper, we study the application of the first Futamura projection on abstract interpreters, 
and the approach to construct efficient abstract interpreters by applying multi-stage programming.

Multi-stage programming has been widely used to improve the performance in many domains, 
such as optimizing compilers and domain-specific languages \cite{DBLP:conf/pldi/RompfSBLCO14, DBLP:conf/snapl/RompfBLSJAOSKDK15,
DBLP:journals/tecs/SujeethBLRCOO14, DBLP:conf/gpce/SujeethGBLROO13, DBLP:journals/jfp/CaretteKS09},
numerical computation \cite{PGL-038, DBLP:conf/pepm/AktemurKKS13}, 
generic programming \cite{DBLP:journals/pacmpl/Yallop17}, 
data processing \cite{DBLP:conf/oopsla/JonnalageddaCSRO14, DBLP:conf/popl/KiselyovBPS17}, 
query compilation in databases \cite{DBLP:conf/osdi/EssertelTDBOR18, DBLP:conf/sigmod/TahboubER18},
and etc.
Likewise, specializing static analyses by partial evaluation had been emerged in 90s 
\cite{damian1999partial, amtoft1999partial, Boucher:1996:ACN:647473.727587, ashley:practical}, 
and indeed it is able to effectively remove the interpretive overhead of 
repeatedly traversing the abstract syntax tree. However, it is still worth 
to investigate the idea deeper from a modern perspective based on meta-programming 
for general abstract interpreters.
Practically, precise whole-program analyses formulated as abstract interpretation 
can be very slow due to the inherent complexity of the algorithm and the large scale 
of the analyzed programs \cite{toman_et_al:LIPIcs:2017:7121} \todo{other cite?};
particularly, we would like a systematic approach to optimize program 
analyzers and meanwhile minimally modifying the analyzer programs.
In the present paper, we show how to achieve this goal by bring existing 
high-performance computing facilities, in the style of multi-stage generative
programming, to abstract interpretation semantic artifacts, i.e., 
abstract interpreters. We show the use LMS framework, that enables 
multi-stage programming by just changing the types of the analyzer 
program, and we thus bridge the gap between designing sound program 
analyses and implementing efficient program analyzers.

When staging a concrete interpreter, the programmers need to distinguish 
static and dynamic values --- the given program to be executed by the 
interpreter is classified as static because it is known at compile-time, 
and the inputs to that program are dynamic.  However, when staging an 
abstract interpreter, this distinction not exists anymore. Because the 
abstract interpreter instantiates all the inputs as some form of abstract 
values, which are usually top elements in their abstract domains and are 
also statically known. Then what is the point of staging if no such distinction?
A surprising by-product of thinking about this question is to realize that 
we can apply the staged abstract interpreter on \textit{open} programs, and
the free variables representing other parts of the program (e.g., libraries) 
are dynamic input, therefore we obtain a modular analysis through staging, 
mechanically. \todo{unknown context}

The use of staged abstract interpreters on open programs 
This addresses 
3. analyzing modern programs with large libraries are expensive. 
why? 1. precise analysis usually required whole-program analysis; 2. to do whole-program analysis, need to 
repetitively analyze the parts of library.
As modularity in compilers, we need to a way to separately analyze programs, and create summaries of analyzed 
part so that we can reuse them, remove redundant analyzing of libraries.

Many optimization of static analysis are ad-hoc.

\subsection{Contributions}

\begin{itemize}
\item Starting from a definitional abstract interpreter for a higher-order functional language,
  which the syntax and semantics are described in section \ref{bg_lang},
  we show how to turn it into a staged abstract interpreter by adding stage annotations within
  Lightweight Modular Staging (LMS) framework, a library-based approach to code generation. 
  We later extend the staged abstract interpreter to support imperative language features 
  (section \ref{cases_imp}), such as states, loops and exceptions.
\item We elaborate the idea that the staged abstract interpreter not only improves the \textit{performance}
  but also the \textit{scalability}, which are two major issues in static analysis, if we apply it on open
  programs. \todo{more on this point.}
\item To evaluate the generality and applicability of the idea, we conduct three case studies in section \ref{cases_study}. 
  First we revisited Abstract Compilation \cite{Boucher:1996:ACN:647473.727587}, which is a closure generation 
  technique applied on 0-CFA. We show that it can be understood and easily implemented as an instance of 
  staged abstract interpreter. 
  Second, we demonstrate sophisticated control-flow analysis techniques, such as adaptive context/flow/path-sensitive 
  analysis and store-widening can be integrated with staged abstract interpreters without losing any precision.
  Finally, we show that in an imperative language, the idea can be applied onto an abstract interpreter with
  an abstract domain that performs numerical analysis.
  (Optional: taint/information flow analysis?)
\item We also empirically evaluate the performance improved by staging an big-step abstract interpreter 
  for control-flow analysis. We compare against with the unstaged version, a small-step version (unstaged), 
  and an optimizing small-step version.
\end{itemize}
