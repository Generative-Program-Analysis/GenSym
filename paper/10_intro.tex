\section{Introduction} \label{intro}

Abstract interpretation as a lattice-based approach to sound static analyses was
proposed by \citet{DBLP:conf/popl/CousotC77, CousotCousot79-1}. Based on the
notion of Galois connections, an analyzer can soundly approximate concrete
program behavior at runtime by computing fixed points on an abstract domain.
Despite the tremendous theoretical development of abstract interpretation over
the years, constructing artifacts and analyzers that perform sound abstract
interpretation for modern and expressive languages is considered complicated
for a long time.

Recent progress on methodologies such as Abstracting Abstract Machines (AAM)
\cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10} uncovers an operational
approach to constructing abstract interpreters.  By deriving semantics artifacts
for abstract interpretation from their concrete counterparts (for example,
abstract machines), soundness can be easily established by examining the
transformation of semantic artifacts. This systematic approach to abstraction
can be tailored to different language features (such as state, first-class
control, exceptions, etc.) and sensitivity analyses
\cite{DBLP:conf/icfp/Gilray0M16, DBLP:conf/popl/GilrayL0MH16,
Darais:2015:GTM:2814270.2814308}. It has also been applied to various small-step
abstract machines \cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10,
Sergey:2013:MAI:2491956.2491979} and big-step definitional interpreters
\cite{Wei:2018:RAA:3243631.3236800, DBLP:journals/pacmpl/DaraisLNH17,
Keidel:2018:CSP:3243631.3236767}.
Based on the idea of AAM, more pragmatically, several implementation strategies
in high-level functional programming languages have emerged.  Such techniques
include monads and monad transformers \cite{DBLP:journals/pacmpl/DaraisLNH17,
Sergey:2013:MAI:2491956.2491979}, arrows \cite{Keidel:2018:CSP:3243631.3236767},
and extensible effects \cite{Githubsemantic}.
These pure approaches provide certain benefits, including the fact that the
abstract interpretation artifacts can be built in a compositional and modular
fashion. Furthermore, referential transparency allows programmers to confidently
reason about the correctness. The soundness of an
analysis can also be proven with less effort, whether by mechanized proofs
\cite{Darais:2016:CGC:2951913.2951934} or paper-based proofs
\cite{Keidel:2018:CSP:3243631.3236767}.

However, besides the intrinsic complexity of static analysis, there are
additional abstraction penalties from these high-level implementation
approaches. First, similar to concrete interpreters, an abstract interpreter
analyzes a program by traversing its AST. This traversal incurs interpretive
overhead, such as pattern matching on the AST nodes and recursive calls on
subexpressions. If this requires only a single traversal, such overhead can be
negligible. Usually, however, abstract interpreters iteratively analyze and
traverse an AST multiple times to reach fixed-points; the accumulated overhead
is therefore magnified.
%Repeatedly analyzing library programs also poses significant overhead.
%Such overhead can be negligible if the abstract
%interpreter only runs on the program a single time, but can accumulate
%significantly if it runs repeatedly (for example, on libraries).
Second, it is common that abstract interpreters written in pure languages make
extensive use of functional encodings of side-effects to implement the semantics
of interpreted languages. For example, the list monad can be used to model
nondeterminism of collecting interpreters. Although such pure approaches have
their merits, they are significantly slower when compared with imperative,
stateful implementations. The goal of this paper is to develop an approach for
implementing abstract interpreters, which allows high-level abstractions during
implementation for clarity, but bypasses the incurred overhead at runtime for
efficiency.
%In order to reconcile these approaches, one need to
%use a programming technique which allows for high-level abstractions during
%implementation, but bypasses the incurred overhead at runtime.

Roughly at the same time abstract interpretation was proposed,
\citet{futamura1971partial} observed a close connection between interpreters and
compilers through a hierarchy of specializations, known since then as the
Futamura projections. 
The first Futamura projection states that specializing an interpreter to an
input program removes interpretative overhead and yields an equivalent
executable that runs faster. Moreover, a procedure that can specialize an
interpreter to any input program is equivalent to a compiler.
In recent years, the idea of Futamura projections has attracted more attention,
and has been successfully applied to many real-world scenarios, such as
building JIT compilers for dynamic languages
\cite{Bolz:2009:TMP:1565824.1565827, Marr:2015:TVP:2814270.2814275} and building query
compilers for databases \cite{DBLP:conf/sigmod/TahboubER18, DBLP:conf/osdi/EssertelTDBOR18}.
The question here is can we apply Futamura projections to an abstract
interpreter and obtain a compiler for abstract interpretation?
%apply Futamura projections to a general abstract interpreter to make it run faster? 
The solution is not obvious, as we need to specialize a nonstandard
semantics that extensively uses nondeterminism, operates on abstract domains,
and computes fixed-points iteratively. 

In this paper, we show that the first Futamura projection can be naturally
extended to abstract interpreters. We present an abstraction-without-regret
framework that eliminates performance penalties for monadic abstract
interpreters, while keeping the implementation as close to their conceptual
model as possible. In short, we borrow ideas and techniques from multi-stage
programming and embedded DSLs, and apply them to abstract interpreters:  1) To
remove the overhead from interpretation and effect layers, we specialize the
abstract interpreter via staging, and then generate efficient low-level code
that performs the actual analysis. 2) Inspired by tagless-final interpreters
\cite{DBLP:journals/jfp/CaretteKS09}, we construct a generic interpreter that
abstracts over binding-times \cite{Ofenbeck:2017:SGP:3136040.3136060,
Amin:2017:CTI:3177123.3158140} and different semantics, which allows the staged
abstract interpreter to be derived from its unstaged counterpart.  As a result,
the derived staged abstract interpreter has no intrusive changes to the
underlying abstract semantics, thereby preserving soundness.  In this sense, our
approach allows for a complete absence of regret in terms of both performance
and engineering effort. We elaborate these two main ideas in detail, as follows.

%The result of specialization is reusable, and the effect layers have
%been eliminated in the generated code.

\input{fig_confluence.tex}

\paragraph{Futamura Projections Meet Abstract Interpreters}

The first Futamura projection shows that specializing an interpreter w.r.t. an
input program yields an equivalent program. For instance, assume that 
@eval : Expr --> Input --> Value@ is an interpreter for some language.
Given a program $e$@ : Expr@, by applying the specialization we
obtain a specialized program $\texttt{eval}_{\texttt{e}}$ : @Input --> Value@.
%which is the so-called \textit{equivalent executable}.
% By definition of the interpreter, they produce the same result when applied
% with the argument $\texttt{eval}_{\texttt{e0}}(arg) = [\![ e ]\!] arg $.
The earlier approach to realizing Futamura projections is partial
evaluation (PE) \cite{DBLP:books/daglib/0072559}.
Offline PE relies on a separate binding-time analysis (\textit{static} or
\textit{dynamic}), and online PE identifies the binding-times during the
specialization.
The underlying representation of binding-times can be viewed as a
two-level semantics \cite{NIELSON1989117, NIELSON198859,
Nielson:1992:TFL:130665} that distinguishes between compile-time computation
and run-time computation.  However, it is hard to precisely analyze
binding-times given an arbitrary program. As an alternative approach,
multi-stage programming (MSP) \cite{taha1999multi, DBLP:conf/pepm/TahaS97}
allows programmers to annotate the binding-times of variables and control which
part of the program should be specialized.
At the syntactic level, traditional MSP languages (e.g., MetaML/MetaOCaml) use
quasi-quotations and escapes as annotations. However, the syntactic
quasi-quotation is a weak two-level semantics, and does not always preserve the
evaluation order of staged expressions.
%The MSP system will then check whether these
%annotations are consistent, and specialize the program using that information.
Besides the syntactic approach, staging annotations can also be purely
type-based.  One of the examples is the Lightweight Modular Staging framework
\cite{DBLP:conf/gpce/RompfO10} in Scala, which as well provides a stronger
guarantee of preserving the evaluation order by generating code in
administrative normal form.

To apply the Futamura projections to abstract interpreters, we consider
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s big-step monadic abstract interpreter
as the unstaged baseline.  Similar to two-level semantics \cite{NIELSON1989117},
monads provide a good abstraction to hide the detail of abstract interpretation
semantics. However, monads do not have a clear stage distinction. We further
introduce binding-times and make the monads binding-time polymorphic. Our
proposed framework adopts type-based multi-stage programming from the
Lightweight Modular Staging framework, and implements the first Futamura projection of
an abstract interpreter for a stateful higher-order language. By deriving staged
monads that can be used to perform code generation, we obtain a staged abstract
interpreter that can be used for specialization. Through staging, the generated
code is specialized to the input program, and all the monadic operations are
inlined and compiled down to low-level Scala code.

\paragraph{Generic Interpreter and Reinterpretation}

Program specialization and abstract interpretation are two orthogonal
concepts.  To implement the confluence of them, we first construct a
generic interpreter that is agnostic to both binding times and value
domains used in the semantics.  Later, the generic interpreter can be
instantiated from these two dimensions (Figure~\ref{confluence}):
\begin{itemize}
\item With a flat binding-time and concrete domains, it is an ordinary
  definitional interpreter based on big-step operational semantics;
\item With two-level binding-times and concrete domains, it is a
  compiler that translates a program into another language;
\item With a flat binding-time and abstract domains, it is a
  definitional abstract interpreter \cite{DBLP:journals/pacmpl/DaraisLNH17}
  that statically computes runtime properties;
\item With two-level binding-times and abstract domains, it is an optimized
  program analyzer, but works in the fashion of compilation.
\end{itemize}

Although the four artifacts may look dissimilar at first glance, they are in
fact all firmly rooted in the concrete semantics.  This observation provides a
way to abstract over the semantics and achieve the flexibility of
reinterpreting the shared interpreter.  The generic interpreter returns a value
of monadic types, which vary based on semantics. The value domains
of the interpreter and the effects such as state and nondeterminism can all be
wrapped into this monadic type.  The binding-time abstraction is represented by
a higher-kinded type and injected into the monadic type.  The binding-times
control whether the interpreter produces values directly or generates code.

%It is worth mentioning
%that the binding-time type is also injected into the monadic type, so that we
%will distinguish normal monads and staged monads.

\paragraph{Applications and Evaluation}
We evaluate the idea of staging an abstract interpreter through
case studies and an empirical performance evaluation.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, an implementation technique for
control-flow analyses. We show that by utilizing type-based stage
annotations, we can achieve the same optimizations. Meanwhile,
the analyzer does not need to change (modulo the addition of stage annotations),
thereby requiring significantly less engineering effort.
2) We extend the basic staged abstract interpreter to cover different flow
analyses, including a store-widened analysis, a context-sensitive
analysis, and abstract garbage collection.
3) We show that staging an abstract interpreter enables modular
compilation of an analysis to programs. Here we borrow the concept of
modular analysis, and show that the compiled analysis is reusable.
Therefore, the approach provides a modular way to create optimized
analysis code by mechanized reuse of a whole-program analyzer.
4) We empirically evaluate the performance improvements gained by staging,
showing an order of magnitude speedup.

\paragraph{Contributions} 
1) Intellectually, we present a framework that naturally extends the first
Futamura projection to abstract interpreters, showing a well-grounded approach
to optimizing static analyses via meta-programming.  2) Practically, we show
that staging an abstract interpreter is useful to improve performance and
scalability of analyses by case studies and an empirical evaluation.

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our target language and reviewing
    monads in Scala, and then presenting the generic interpreter
    (Section~\ref{prelim}), after which we review instantiations
    of concrete interpretation (Section~\ref{unstaged_conc}) and
    staged concrete interpretation (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same
    framework by replacing the environment, store, and values with their
    abstract counterparts (Section~\ref{unstaged_abs}). We then
    show that the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived
    (Section~\ref{sai}). We also summarize the approach and discuss
    soundness properties after showing the four artifacts.
  \item We summarize our approach and discuss correctness (Section~\ref{discussion}).
    We conduct three case studies (Section~\ref{cases_study}) and
    an empirical evaluation on performance improvements (Section~\ref{evaluation}).
    Finally we discuss related work and conclude.
\end{itemize}

\iffalse
On the other side, static analysis is a trade-off between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
