\section{Introduction} \label{intro}

Statically analyzing semantic properties of a program is a
widely-known undecidable problem. Abstract interpretation as a
lattice-based approach to sound static analyses was proposed
by \citet{DBLP:conf/popl/CousotC77}. Equipped with Galois connections,
the analyzer can obtain the program runtime behaviors approximately
by computing the fixed points on the abstract domain. Despite the tremendous
theoretical development of abstract interpretation over the years,
constructing artifacts and analyzers that perform sound abstract
interpretation for modern and expressive languages was considered
abstruse and complicated for a long time.

In recent years, we observe a rich progress on the methodologies for
constructing abstract interpreters from systematic principles, instead
of ad-hoc engineering. A notable one is the Abstracting Abstract
Machine (AAM) methodology \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10}. It uncovers an approach to derive sound
abstract interpreters from their concrete counterparts, for example,
abstract machines, where the soundness can be easily established by examining
the transformation of semantic artifacts. For example, the CEK machine
\cite{DBLP:conf/popl/FelleisenF87} for concrete execution can be
readily refactored to an effective $0$-CFA control-flow analysis
\cite{Shivers:1988:CFA:53990.54007, Midtgaard:2012:CAF:2187671.2187672}:
first we tweak the environment dereference as a nondeterministic choice,
such that the environment may contain mutiple possible values for a varaiable,
then allocating continuations in the environment to exploit return-flow information,
and also constrain the addresses space to be finite.
This systematic abstraction approach can be tailored to
different language features (such as states, first-class controls,
exceptions and concurrency) and sensitivity analyses
\cite{DBLP:conf/icfp/Gilray0M16, DBLP:conf/popl/GilrayL0MH16,
  Darais:2015:GTM:2814270.2814308}. It also has been applied to various
small-step abstract machines \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10, Sergey:2013:MAI:2491956.2491979} and
big-step definitional interpreters \cite{Wei:2018:RAA:3243631.3236800,
  DBLP:journals/pacmpl/DaraisLNH17, Keidel:2018:CSP:3243631.3236767}.

Based on the idea of abstracting abstract machines, more pragmatically,
several implementation strategies utilizing purely functional programming
to build abstract interpreters were emerged. Such techniques include monads,
monad transformers \cite{DBLP:journals/pacmpl/DaraisLNH17, Sergey:2013:MAI:2491956.2491979},
arrows \cite{Keidel:2018:CSP:3243631.3236767}, extensible effects \cite{Githubsemantic} and etc.
The pure approaches provide certain benefits. The abstract interpretation
artifacts can be built compositionally and modularly, e.g., by using monad
transformers. Therefore, the soundness of analysis can be proved with less efforts,
either by mechanized \cite{Darais:2016:CGC:2951913.2951934} or paper-based proof
\cite{Keidel:2018:CSP:3243631.3236767}. Also, referential transparent and
equational reasoning allow programmers to reason the correctness of their
implementations more confidently.

However, besides the intrinsic complexity of static analysis, there are
additional abstraction penalties with these high-level implementation approaches.
First, similar to concrete interpreters, the abstract interpreter analyzes the
program by traversing the abstract syntax tree, which poses an interpretive
overhead, such as the pattern matching on the ASTs and recursive calls on the sub
expressions. Those kind of overhead can be negligible if the abstract
interpreter only runs on the program for one time, but also can be accumulated
significantly if it runs repeatedly, for example, on libraries.
Second, the abstract interpreter written in pure languages usually extensively
uses effect systems to implement the semantics of abstract interpretation.
For example, the abstract interpreter that returns all possible runtime values
is a form of nondeterminism, where nondeterminism monads can help.
Although such pure approaches have its own merits and elegance,
compared with imperative stateful implementations, they are significantly slower.

In this paper, we propose an abstraction-without-regret approach to
eliminate those performance penalties for abstract interpreters, meanwhile
still keeping the benefits come from purely functional programming.
In short, our approach applies ideas and techniques from program specialization
and embedded DSLs to abstract interpreters. 1) Using multi-stage
programming , we can specialize the abstract interpreter with respect to an
input program and then generate efficient low-level code that does the actual analysis.
The result of specialization is reusable, and the effect layers have been
eliminated in the generated code. 2) Inspired by the tagless-final interpreters,
we define a generic interpreter that abstracts over binding-time and
different semantics, which allows user to implement different semantics
modularly, including the staged abstract interpretation semantics.
Together with the multi-stage programming and type-level annotations of binding-times,
we can derive the staged abstract interpreters without intrusive changes to
the corresponding unstaged one, thus the soundness is untouched.
In this sense, our approach is no regret of both performance and engineering
effort. We elaborate these two main ideas in detail as follow.

\paragraph{Futamura Projection of Abstract Interpreters}

The idea of specializing interpreters can be traced to Futamura
projections \cite{Futamura1999, futamura1971partial}.
The first Futamura projection specifically shows that
specializing an interpreter w.r.t. the input program yields an
equivalent executable. For instance, @eval@ is an interpreter for
some language:
\begin{lstlisting}
  def eval(e: Expr)(arg: Input): Value
\end{lstlisting}
Given a program $e_0$ of type @Expr@, by applying the specialization,
we can obtain a specialized interpreter $\texttt{eval}_{\texttt{e0}}$ :
@Input@ $\to$ @Value@, which is the so-called \textit{equivalent executable}.
By definition of the interpreter, they produce the same result when applied
with the argument $\texttt{eval}_{\texttt{e0}}(arg) = [\![ e_0 ]\!] arg $.

Partial evaluation \cite{DBLP:books/daglib/0072559} was the first
proposed approach to realize Futamura projections: it first discovers
the binding-times (\textit{static} or \textit{dynamic}) of variables,
then evaluates the static part of the program, and generates a residualized
program that solely relies on the dynamic part. However, it is hard to
precisely analyze binding-times given an arbitrary program.
As an alternative approach to specialization, multi-stage programming (MSP)
\cite{taha1999multi, DBLP:conf/pepm/TahaS97}
lets the programmer to explicitly control and annotate the
binding-times in the program, then the MSP system will check whether these annotations
are consistent and specialize the program using that information.
The staging annotations can be either syntactic (e.g., quote and quasiquote
in MetaML/MetaOCaml) or type-based (e.g., the Lightweight Modular Staging
framework \cite{DBLP:conf/gpce/RompfO10} in Scala).

Our proposed framework adopts the type-based multi-stage programming from
the Lightweight Modular Staging framework and implements the Futamura
projection of a big-step abstract interpreter for a small stateful,
higher-order language.
We use \citet{DBLP:journals/pacmpl/DaraisLNH17}'s abstract definitional
interpreter that uses monad transformers as the unstaged baseline. By
deriving staged monads that can be used to do code generation, we may
obtain a staged abstract interpreter that fulfills the specialization.
After staging, the generated code is specialized to the input program,
and all monadic operations are all inlined and compiled down to low-level
Scala code.

\input{fig_confluence.tex}

\paragraph{Generic Interpreter and Reinterpretation}

Program specialization and abstract interpretation are two orthogonal concepts.
To implement the confluence of them, we first construct a generic interpreter that
is agnostic to both binding-times and value domains used in the semantics.
Later, the generic interpreter can be instantiated from these two dimensions (Figure~\ref{confluence}):
\begin{itemize}
\item With a flat binding-time and concrete domains, it is a ordinary definitional interpreter based
  on big-step operational semantics;
\item With two-level binding-times and concrete domain, it is a compiler that translate to program
  intro antoher language;
\item With a flat binding-time and abstract domains, it is an definitional abstract interpreter
  \cite{DBLP:journals/pacmpl/DaraisLNH17} that statically computes runtime properties;
\item With two-level binding-times and abstract domains, it is an optimizing program analyzer but
  works in the fashion of compilation.
\end{itemize}

Although the four artifacts may look like very differently at first glance,
but in fact are all firmly rooted in the concrete semantics of the language.
This observation provides a way to abstract over the interpreter and achieve
the flexibility of reinterpreting the shared interpreter. We adapt the monadic
interpreter schema, which already have been applied to abstract interpreters,
and introduce the binding-time abstraction into the generic interpreter.
The generic interpreter returns a value of monadic type, which can be varied
by different semantics. The domain of the interpreter and the effects such as read,
state and nondeterminism can be both wrapped into this monadic type.
The binding-time abstraction is represented by a higher-kinded type,
and controls whether the interpreter produces values directly or generates code.
It is worth to mention that the binding-time type is also instrumented into
the monadic type, so that we will distinguish normal monads and staged monads.

\paragraph{Applications and Evaluations}
We evaluate the idea of staging an abstract interpreter through
case studies and an empirical evaluation on performance.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, a implementation technique for
control-flow analyses, and show that by utilizing type-based stage
annotations we can achieve the same optimization, and meanwhile,
the analyzer does not need to change, thereby requires much less
engineering efforts.
2) We extend the basic staged abstract interpreter to different flow
analyses, including a store-widened analysis, a context-sensitive
analysis and abstract garbage collection.
3) We notice that staging an abstract interpreter enables modularly
compiling an analysis to programs. Here we borrow the concept of modular
analysis, and show that the compiled analysis is reusable.
Therefore the approach provides a modular way to create optimized analysis
code by mechanized reusing a whole-program analyzer.
4) We also empirically evaluate the performance improved by staging,
showing an order of magnitude speed-up on flow-analysis \todo{explicit note the number}.

\paragraph{Contributions} Briefly, the contribution of the paper is as follows:
\begin{itemize}[leftmargin=2em]
  \item To our best knowledge, we present the first one to use
    multi-stage programming to specialize a general abstract interpreter,
    and our approach does not touch the soundness of analyses.
  \item Intellectually, our framework naturally extends the first
    Futamura projection to abstract interpreters, showing a
    well-grounded approach to optimize static analyses via
    metaprogramming.
  \item Pragmatically, we show that staging abstract interpreters is
    useful to improve performance and scalability of analyses by case
    studies and empirical evaluation.
\end{itemize}

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our core target language and reviewing
    monads in Scala, and then presenting the generic interpreter (Section~\ref{prelim}).
    After which, we review its instantiations of concrete interpretation
    (Section~\ref{unstaged_conc}) and staged concrete interpretation
    (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same framework by
    replacing the environment, store and values (Section~\ref{unstaged_abs}).
    After, we show the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived (Section~\ref{sai}).
  \item We conduct three case studies (Section~\ref{cases_study}), which demonstrate that
    our approach requires less engineering efforts, is applicable to various analysis,
    and enables modular analysis.
  \item We empirically evaluate the performance improvement by staging on
    control-flow analysis (Section~\ref{evaluation}). We compare the both
    context-insensitive and store-widening analysis.
\end{itemize}

\iffalse
On the other side, static analysis is a tradeoff between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
