\section{Introduction} \label{intro}

Statically analyzing semantic properties of a program is a
widely-known undecidable problem. Abstract interpretation as a
lattice-based approach to sound static analyses was proposed
by \citet{DBLP:conf/popl/CousotC77}. With the Galois connections, one
can approximate to the program runtime behaviors by computing the
fixed points on the abstract domain. Despite the tremendous
theoretical development of abstract interpretation over the years, on
the side of pragmatics, constructing artifacts and analyzers that
perform sound abstract interpretation for modern, high-level and
expressive languages was considered abstruse and complicated for a
long time.

In recent years, we observe a rich progress on the methodologies for
constructing abstract interpreters from systematic principles, instead
of ad-hoc engineerings. A notable one is the Abstracting Abstract
Machine (AAM) methodology \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10}, which uncovers an approach to derive sound
abstract interpreters from their concrete counterparts, i.e., abstract
machines, where the soundness can be easily established by examining
the transformation of semantic artifacts. For example, a CEK machine
\cite{DBLP:conf/popl/FelleisenF87} for concrete execution can be
readily refactored to an effective $0$-CFA control-flow analysis
\cite{Shivers:1988:CFA:53990.54007,
  Midtgaard:2012:CAF:2187671.2187672} by first tweaking the
environment dereference as a nondeterministic choice, then allocating
continuations in the environment, and constraining the addresses space
to be finite. This systematic abstraction approach can be tailored to
various language features (such as states, first-class controls,
exceptions and concurrency) and different sensitivity analyses
\cite{DBLP:conf/icfp/Gilray0M16, DBLP:conf/popl/GilrayL0MH16,
  Darais:2015:GTM:2814270.2814308}, and has been applied to multiple
small-step abstract machines \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10, Sergey:2013:MAI:2491956.2491979} and
big-step definitional interpreters \cite{Wei:2018:RAA:3243631.3236800,
  DBLP:journals/pacmpl/DaraisLNH17, Keidel:2018:CSP:3243631.3236767}.

Based on the idea of AAM, and more pragmatically, as an implementation
strategy, several purely functional programming approaches to build
abstract interpreters were emerged, for examples, using monads or
arrows. The pure approach provides much benefits: 1) the abstract
interpretation artifacts are compositional and can be constructed
modularly, e.g., by using monad transformers. 2) The soundness of
analysis can be proved more easily, by mechnization
\cite{Darais:2016:CGC:2951913.2951934} or paper-based proof
\cite{Keidel:2018:CSP:3243631.3236767}.  3) The correctness of
implementations can be reasoned by the programmers more condidently,
e.g., by leveraging equational reasoning.

However, besides the intrinsic complexity of static analysis, there are
additional abstraction penalties with these high-level programming approaches.
First, similar to concrete interpreters, the abstract interpreter analyzes the
program by traversing the abstract syntax tree, which poses the interpretive
overhead, e.g., pattern matching on the AST and recursive calls on the sub
expressions. Those kind of overhead can be negligible if the abstract
interpreter only runs on the program once, but also can be accumulated
significantly if it runs repeatedly, for example, on libraries. Second, the
abstract interpreter written in pure languages usually extensively uses effect
systems to model the behaviors of abstract interpretatation, such as
nondeterminism. For example, \citet{DBLP:journals/pacmpl/DaraisLNH17} and
\citet{Sergey:2013:MAI:2491956.2491979}'s monadic abstract interpreters use
monad transformers; the very recent \citet{Githubsemantic}'s \textsc{Semantic} framework
uses extensible effects. With certain merits and elegance of the implementation,
the effect systems may also introduce additional performance overhead.

In this paper, we propose an abstraction-without-regret approach to
eliminate those performance penalties for abstract interpreters, while
still keeping these benefits from purely functional programming.  In
short, our approach borrows ideas from program specialization and
embedded DSLs, and applies them to this particular kind of
meta-programs, abstract interpreters.  1) Using multi-stage
programming , we can specialize the
abstract interpreter with respect to an input program and then
generate efficient low-level code that does the actual analysis. The
result of specialization is reusable, and the effect layers have been
eleiminated in the generated code. 2) We use a tagless-final approach
to embed the target language interpreter in a high-level host language,
which defines a generic interpreter and allows user to
implement different semantics modularly, including the abstract
semantics and staging, without changing the generic one.
Together with the multi-stage programming and type-level
annotations, this design allows user to derive staged abstract
interpreters without intrusive changes to the unstaged one, thus the soundness is preserved. 
Therefore, our approach is no regret in the sense of both performance and least
engineering efforts to achieve such performance. We elaborate these
two main ideas in detail as follow.

\paragraph{Futamura Projection of Abstract Interpreters}

The idea of specializing interpreters can be traced to Futamura
projections \cite{Futamura1999, futamura1971partial}.
The first Futamura projection specifically shows that
specializing an interpreter w.r.t. the input program yields an
equivalent executable.  For instance, we have an interpreter @eval@ of
some language:
\begin{lstlisting}
  def eval(e: Expr)(arg: Input): Value
\end{lstlisting}
Given a program $e_0$ of type @Expr@, by applying the first Futamura
projection, we can obtain a specialized interpreter
$\texttt{eval}_{\texttt{e0}}$ : @Input@ $\to$ @Value@, which is the so-called
\textit{equivalent executable}. By definition of the interpreter,
$\texttt{eval}_{\texttt{e0}}(arg) = [\![ e_0 ]\!] arg $.

Partial evaluation \cite{DBLP:books/daglib/0072559} was the first
proposed approach to realize Futamura projections: it discovers the
binding-time (static or dynamic) of variables, evaluates the static
part, and residualizes a program that solely relies on the dynamic
part. However, it is hard to precisely analyze binding-times given an
arbitrary program. As an alternative approach to specialization and
partial evaluation, multi-stage programming (MSP) \cite{taha1999multi, DBLP:conf/pepm/TahaS97}
lets the programmer to explicitly control and annotate the
binding-times in the program, and the MSP system will specialize the
program. The staging annotations can be either syntactic (e.g.,
MetaML/MetaOCaml) or type-based (e.g., the Lightweight Modular Staging framework
\cite{DBLP:conf/gpce/RompfO10} in Scala).

Our proposed framework adopts the type-based multi-stage programming
and implements the first Futamura projection of a big-step abstract
interpreter for a stateful, higher-order core language.  We use
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s abstract definitional
interpreter that uses monad transformers as the unstaged baseline. By
deriving staged monads that can be used to do code generation, we may
obtain a staged abstract interpreter that fulfills the specializtion.
After staging, the generated code is specialized to the input program,
and monadic operations are all inlined.

\input{fig_confluence.tex}

\paragraph{Generic Interpreter and Reinterpretation}

The central basis of our approach is a semantic-agnostic interpreter, which can be
instantiated by different interpretations or compilations (Figure~\ref{confluence}).
The different semantics in Figure~\ref{confluence} correspond to four different
artifacts involved in software language engineering: definitional interpreters
which are defined by the denotational or operational semantics, compilers that
translate the program into another language, analyzers that statically compute the
runtime properties of programs, and optimizing analyzers that achieve the same goal
of analyzers but in the way of compilers. We observe that these four
tasks may look like very differently at first glance, but in fact are
all firmly rooted in the concrete semantics of the language.

To achieve the flexibility of reinterpreting the shared interpreter by
different semantics, our framework abstracts the primitive operations
from these semantics, and extensively uses abstract type members over
the binding-times, the components of the interpreter, and the returned
monadic type of the interpreter. The binding-time abstraction is
represented by a higher-kinded type, and controls whether the
interpreter produces values or generates code. The components of the
interpreter, such as the environment and values, determines the domain
that the interpreter will be running with. Following the AAM approach,
by applying a series of abstractions to these components, we can
derive computable and sound abstract interpreters. Finally, the
monadic abstraction encapsulates both the binding-times and
components, which appears as the returned type and defines the
behaviors and datatype the interpreter operatres on.

\paragraph{Applications and Evaluations}
We evaluate the idea of staging an abstract interpreter through
multiple case studies and emipical evaluation on performance.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, and show that we can achieve
the same optimization by utilizing type-based stage annotations;
meanwhile, the analyzer program does not need any changes, thereby
requres little engineering efforts.
2) We extend the basic staged abstract interpreter to diverse flow
analysis, including a store-widened analysis, a context-sensitive
analysis and abstract garbage collection.
3) We notice that staging an abstract interpreter enables modularly
compiling an analysis to programs. The compiled analysis is reusable,
therefore it provides a mechnized way to create library summaries by
reusing a whole-program analyzer.
4) We also emipically evaluate the performance improved by staging,
showing an average 11x speed-up on flow-analysis.

\paragraph{Contributions} Briefly, the contribution of the paper is as follows:
\begin{itemize}[leftmargin=2em]
  \item To our best knowledge, we present the first one to use
    multi-stage programming to specialize a general abstract interpreter,
    and our approach does not touch the soundness of analyses.
  \item Intellectually, our framework naturally extends the first
    Futamura projection to abstract interpreters, showing a
    well-grounded approach to optimize static analyses via
    metaprogramming.
  \item Pragmatically, we show that staging abstract interpreters is
    useful to improve performance and scalability of analyses by case
    studies and emiprical evaluation.
\end{itemize}

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our core target language and reviewing
    monads in Scala, and then presenting the generic interpreter (Section~\ref{prelim}).
    After which, we review its instantiations of concrete interpretation
    (Section~\ref{unstaged_conc}) and staged concrete interpretation
    (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same framework by
    replacing the environment, store and values (Section~\ref{unstaged_abs}).
    After, we show the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived (Section~\ref{sai}).
  \item We conduct three case studies (Section~\ref{cases_study}), which demonstrate that
    our approach requires less engineering efforts, is applicable to various analysis,
    and enables modular analysis.
  \item We empirically evaluate the performance improvement by staging on
    control-flow analysis (Section~\ref{evaluation}). We compare the both
    context-insensitive and store-widening analysis.
\end{itemize}

\iffalse
On the other side, static analysis is a tradeoff between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
