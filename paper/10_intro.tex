\section{Introduction} \label{intro}

Abstract interpretation as a lattice-based approach to sound static analyses was
proposed by \citet{DBLP:conf/popl/CousotC77, CousotCousot79-1}. Based on the notion of Galois
connections, the analyzer can soundly approximate the
concrete program behavior at runtime by computing fixed points on an abstract
domain. Despite the tremendous theoretical development of abstract
interpretation over the years, constructing artifacts and analyzers that perform
sound abstract interpretation for modern and expressive languages was considered
complicated for a long time.

Recent progress on methodologies such as Abstracting Abstract Machine (AAM)
\cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10} uncovers an
operational approach to constructing abstract interpreters.  By deriving
semantics artifacts for abstract interpretation from their concrete
counterparts (for example, abstract machines), soundness can be easily
established by examining the transformation of semantic artifacts.
This systematic abstraction approach can be tailored to different
language features (such as state, first-class control, exceptions, and
concurrency) and sensitivity analyses \cite{DBLP:conf/icfp/Gilray0M16,
  DBLP:conf/popl/GilrayL0MH16, Darais:2015:GTM:2814270.2814308}. It
has also been applied to various small-step abstract machines
\cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10,
  Sergey:2013:MAI:2491956.2491979} and big-step definitional
interpreters \cite{Wei:2018:RAA:3243631.3236800,
  DBLP:journals/pacmpl/DaraisLNH17, Keidel:2018:CSP:3243631.3236767}.

%Based on the idea of abstracting abstract machines, more
%pragmatically, several implementation strategies utilizing purely
%functional programming techniques to build abstract interpreters have
%emerged. 

Based on the idea of AAM, more pragmatically, several implementation strategies
in high-level functional programming languages have emerged.  Such techniques
include monads and monad transformers \cite{DBLP:journals/pacmpl/DaraisLNH17,
Sergey:2013:MAI:2491956.2491979}, arrows
\cite{Keidel:2018:CSP:3243631.3236767}, extensible effects
\cite{Kiselyov:2015:FMM:2804302.2804319, Githubsemantic}, etc. These pure
approaches provide certain benefits, for example, the abstract interpretation
artifacts can be built in a compositional and modular fashion, and referential
transparency allows programmers to confidently reason about the correctness of
their implementations.  The soundness of an analysis can also be proven with less
effort, whether by mechanized proofs \cite{Darais:2016:CGC:2951913.2951934} or
paper-based proofs \cite{Keidel:2018:CSP:3243631.3236767}.  

However, besides the intrinsic complexity of static analysis, there are
additional abstraction penalties from these high-level implementation
approaches. First, similar to concrete interpreters, an abstract interpreter
analyzes a program by traversing its AST. This traversal incurs
interpretive overhead, such as pattern matching on the AST nodes and recursive
calls on subexpressions. If it is a single-time traversal, such overhead can be
negligible. But usually, abstract interpreters iteratively analyze and traverse
the AST multiple times to reach fixed-points, therefore the accumulated
overhead is even magnified. 
%Repeatedly analyzing library programs also poses significant overhead.
%Such overhead can be negligible if the abstract
%interpreter only runs on the program a single time, but can accumulate
%significantly if it runs repeatedly (for example, on libraries).  
Second, it is common that abstract interpreters written in pure languages
extensively use functional encodings of side-effects to implement the semantics
of abstract interpretation.  For example, the list monad can be used to model
nondeterminism from collecting interpreters.
Although such pure approaches have their own merits, compared with imperative,
stateful implementations, they are significantly slower.  In order to
reconcile these approaches, one must use a programming technique which allows
for high-level abstractions during implementation, but bypasses the
incurred overhead at runtime.

Roughly at the same time when abstract interpretation was proposed in the
1970s, \citet{futamura1971partial} observed a close
connection between interpreters and compilers through a hierarchy of
specializations, since then known as Futamura Projections. The first Futamura
projection describes that specializing an interpreter to the input program
removes interpretative overhead and yields an equivalent executable
that runs faster. 
In recent years, the idea of Futamura projections has regained more attentions
and successfully applied to many real-world problems, examples including
query compilers \cite{DBLP:conf/sigmod/TahboubER18}, PyPy \cite{Bolz:2009:TMP:1565824.1565827},
Truffle \cite{Marr:2015:TVP:2814270.2814275}, etc.
The challenge here: can we apply the same idea to a general abstract interpreter
to make it run faster? The solution is not obvious, as we need to specialize
a nonstandard semantics that extensively uses nondeterminism, operates on
abstract domains, and computes fixed-points iteratively over a cache. 

In this paper, we show that the first Futamura projection can be naturally
extended to abstract interpreters. We present an abstraction-without-regret
framework that eliminates performance penalties for monadic abstract
interpreters, while keeping the implementation as close to their conceptual
model as possible.
In short, our approach borrows ideas and techniques from multi-stage
programming and embedded DSLs, and apply them to abstract interpreters:  1) To
remove the overhead from interpretation and effect layers, we specialize the
abstract interpreter via staging and then generate efficient low-level code
that does the actual analysis. 2) Inspired by the tagless-final interpreters
\cite{DBLP:journals/jfp/CaretteKS09}, we construct a generic interpreter that
abstracts over binding-times and different semantics, which allows the staged
abstract interpreter to be derived from its unstaged counterpart.  As a result,
the derived staged abstract interpreters has no intrusive changes to the
underlying abstract semantics, thereby preserving soundness.  In this
sense, our approach allows for no regret for both performance and engineering
effort. We elaborate these two main ideas in detail, as follows.

%The result of specialization is reusable, and the effect layers have
%been eliminated in the generated code.

\input{fig_confluence.tex}

\paragraph{Futamura Projection of Abstract Interpreters}

The first Futamura projection specifically shows that specializing an
interpreter w.r.t. the input program yields an equivalent executable. For
instance, assume that @eval : Expr --> Input --> Value@ is an interpreter for some language.
Given a program $e_0$@ : Expr@, by applying the specialization, we can
obtain a specialized program $\texttt{eval}_{\texttt{e0}}$ : @Input --> Value@.
%which is the so-called \textit{equivalent executable}.
% By definition of the interpreter, they produce the same result when applied with the argument $\texttt{eval}_{\texttt{e0}}(arg) = [\![ e_0 ]\!] arg $.
The first proposed approach to realize Futamura projections is partial
evaluation \cite{DBLP:books/daglib/0072559}, which relies on an automatic
binding-time analysis (\textit{static} or \textit{dynamic}).  The underlying
representation can be viewed as a \textit{two-level semantics}
\cite{NIELSON1989117, NIELSON198859} that distinguishes compile-time
computation and run-time computation.
However, it is hard to precisely analyze binding-times given an arbitrary
program. As an alternative approach, multi-stage programming (MSP)
\cite{taha1999multi, DBLP:conf/pepm/TahaS97} allows users to explicitly program over
a two-level syntax \cite{Nielson:1992:TFL:130665}, by manually
annotating the binding-times of variables. Then, the MSP system
will check whether these annotations are consistent, and specialize the program
using that information. The staging annotations can be either syntactic (e.g.,
quote and quasi-quote in MetaML/MetaOCaml) or type-based (e.g., the Lightweight
Modular Staging framework \cite{DBLP:conf/gpce/RompfO10} in Scala).

To apply Futamura projections on abstract interpreters, we consider
\citet{DBLP:journals/pacmpl/DaraisLNH17}'s big-step monadic abstract
interpreter as the unstaged baseline.  Similar to the two-level semantics
\cite{NIELSON1989117}, monads provide a good abstraction to hide the detail of
abstract interpretation semantics. However, monads do not have a clear
stage distinction.
We further introduce binding-times and make the monads binding-time polymorphic.
Our proposed framework adopts the type-based multi-stage programming from the
Lightweight Modular Staging framework, and implements the Futamura projection
of an abstract interpreter for a stateful higher-order
language. By deriving staged monads that can be used to perform code generation, we
obtain a staged abstract interpreter that can be used for specialization. Through
staging, the generated code is specialized to the input program, and all the
monadic operations are inlined and compiled down to low-level Scala code.

\paragraph{Generic Interpreter and Reinterpretation}

Program specialization and abstract interpretation are two orthogonal
concepts.  To implement the confluence of them, we first construct a
generic interpreter that is agnostic to both binding times and value
domains used in the semantics.  Later, the generic interpreter can be
instantiated from these two dimensions (Figure~\ref{confluence}):
\begin{itemize}
\item With a flat binding-time and concrete domains, it is an ordinary
  definitional interpreter based on big-step operational semantics;
\item With two-level binding-times and concrete domains, it is a
  compiler that translates a program into another language;
\item With a flat binding-time and abstract domains, it is a
  definitional abstract interpreter \cite{DBLP:journals/pacmpl/DaraisLNH17}
  that statically computes runtime properties;
\item With two-level binding-times and abstract domains, it is an optimizing
  program analyzer, but works in the fashion of compilation.
\end{itemize}

Although the four artifacts may look dissimilar at first glance, they in
fact are all firmly rooted in the concrete semantics of the language.  This
observation provides a way to abstract over the interpreter and achieve the
flexibility of reinterpreting the shared interpreter.  The generic interpreter
returns a value of monadic type, which can be varied by different semantics.
The value domains of the interpreter and the effects such as state and nondeterminism
can all be wrapped into this monadic type.  The binding-time abstraction is
represented by a higher-kinded type, and injected into the monadic type.  The
binding-times control whether the interpreter produces values directly or
generates code. 

%It is worth mentioning
%that the binding-time type is also injected into the monadic type, so that we
%will distinguish normal monads and staged monads.

\paragraph{Applications and Evaluation}
We evaluate the idea of staging an abstract interpreter through
case studies and an empirical performance evaluation.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, an implementation technique for
control-flow analyses. We show that by utilizing type-based stage
annotations, we can achieve the same optimizations. Meanwhile,
the analyzer does not need to change, except the addition of stage annotations,
thereby requiring significantly less engineering effort.
2) We extend the basic staged abstract interpreter to different flow
analyses, including a store-widened analysis, a context-sensitive
analysis, and abstract garbage collection.
3) We show that staging an abstract interpreter enables modular
compilation of an analysis to programs. Here we borrow the concept of
modular analysis, and show that the compiled analysis is reusable.
Therefore, the approach provides a modular way to create optimized
analysis code by mechanized reuse of a whole-program analyzer.
4) We empirically evaluate the performance improvements gained by staging,
showing an order of magnitude speedup.

\paragraph{Contributions} Briefly, the contributions of the paper are as follows:
\begin{itemize}[leftmargin=2em]
  \item Intellectually, we present a framework that naturally extends the first
    Futamura projection to definitional abstract interpreters, showing a
    well-grounded approach to optimizing static analyses via meta-programming.
  \item Practically, we show that staging an abstract interpreter is useful to
    improve performance and scalability of analyses by case studies and an
    empirical evaluation.
\end{itemize}

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our target language and reviewing
    monads in Scala, and then presenting the generic interpreter
    (Section~\ref{prelim}), after which we review instantiations
    of concrete interpretation (Section~\ref{unstaged_conc}) and
    staged concrete interpretation (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same
    framework by replacing the environment, store, and values to their
    abstract counterparts (Section~\ref{unstaged_abs}). We then
    show that the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived
    (Section~\ref{sai}). We also summarize the approach and discuss
    soundness properties after showing the four artifacts.
  \item We summarize our approach and discuss correctness (Section~\ref{discussion}).
    We conduct three case studies (Section~\ref{cases_study}) and
    an empirical evaluation on performance improvements (Section~\ref{evaluation}).
    Finally we discuss related work and conclude.
\end{itemize}

\iffalse
On the other side, static analysis is a trade-off between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
