\section{Introduction} \label{intro}

Statically analyzing semantic properties of a program is a
widely-known undecidable problem. Abstract interpretation as a
lattice-based approach to sound static analyses was proposed
by \citet{DBLP:conf/popl/CousotC77}. Equipped with Galois connections,
the analyzer can obtain the program runtime behaviors approximately
by computing the fixed points on the abstract domain. Despite the tremendous
theoretical development of abstract interpretation over the years,
constructing artifacts and analyzers that perform sound abstract
interpretation for modern and expressive languages was considered
abstruse and complicated for a long time.

In recent years, we observe a rich progress on the methodologies for
constructing abstract interpreters from systematic principles, instead
of ad-hoc engineering. A notable one is the Abstracting Abstract
Machine (AAM) methodology \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10}. It uncovers an approach to derive sound
abstract interpreters from their concrete counterparts, for example,
abstract machines, where the soundness can be easily established by examining
the transformation of semantic artifacts. For example, the CEK machine
\cite{DBLP:conf/popl/FelleisenF87} for concrete execution can be
readily refactored to an effective $0$-CFA control-flow analysis
\cite{Shivers:1988:CFA:53990.54007, Midtgaard:2012:CAF:2187671.2187672}:
first we tweak the environment dereference as a nondeterministic choice,
such that the environment may contain mutiple possible values for a varaiable,
then allocating continuations in the environment to exploit return-flow information,
and also constrain the addresses space to be finite.
This systematic abstraction approach can be tailored to
different language features (such as states, first-class controls,
exceptions and concurrency) and sensitivity analyses
\cite{DBLP:conf/icfp/Gilray0M16, DBLP:conf/popl/GilrayL0MH16,
  Darais:2015:GTM:2814270.2814308}. It also has been applied to various
small-step abstract machines \cite{DBLP:journals/jfp/HornM12,
  DBLP:conf/icfp/HornM10, Sergey:2013:MAI:2491956.2491979} and
big-step definitional interpreters \cite{Wei:2018:RAA:3243631.3236800,
  DBLP:journals/pacmpl/DaraisLNH17, Keidel:2018:CSP:3243631.3236767}.

Based on the idea of abstracting abstract machines, more pragmatically,
several implementation strategies utilizing purely functional programming
to build abstract interpreters were emerged. Such techniques include monads,
monad transformers \cite{DBLP:journals/pacmpl/DaraisLNH17, Sergey:2013:MAI:2491956.2491979},
arrows \cite{Keidel:2018:CSP:3243631.3236767}, extensible effects \cite{Githubsemantic} and etc.
The pure approaches provide certain benefits. The abstract interpretation
artifacts can be built compositionally and modularly, e.g., by using monad
transformers. Therefore, the soundness of analysis can be proved with less efforts,
either by mechanized \cite{Darais:2016:CGC:2951913.2951934} or paper-based proof
\cite{Keidel:2018:CSP:3243631.3236767}. Also, referential transparent and
equational reasoning allow programmers to reason the correctness of their
implementations more confidently.

However, besides the intrinsic complexity of static analysis, there are
additional abstraction penalties with these high-level implementation approaches.
First, similar to concrete interpreters, the abstract interpreter analyzes the
program by traversing the abstract syntax tree, which poses an interpretive
overhead, such as the pattern matching on the ASTs and recursive calls on the sub
expressions. Those kind of overhead can be negligible if the abstract
interpreter only runs on the program for one time, but also can be accumulated
significantly if it runs repeatedly, for example, on libraries.
Second, the abstract interpreter written in pure languages usually extensively
uses effect systems to implement the semantics of abstract interpretation.
For example, the abstract interpreter that returns all possible runtime values
is a form of nondeterminism, where nondeterminism monads can help.
Although such pure approaches have its own merits and elegance,
compared with imperative stateful implementations, they are significantly slower.

In this paper, we propose an abstraction-without-regret approach to
eliminate those performance penalties for abstract interpreters, meanwhile
still keeping the benefits come from purely functional programming.
In short, our approach applies ideas and techniques from program specialization
and embedded DSLs to abstract interpreters. 1) Using multi-stage
programming , we can specialize the abstract interpreter with respect to an
input program and then generate efficient low-level code that does the actual analysis.
The result of specialization is reusable, and the effect layers have been
eliminated in the generated code. 2) Inspired by the tagless-final interpreters,
we define a generic interpreter that abstracts over binding-time and
different semantics, which allows user to implement different semantics
modularly, including the staged abstract interpretation semantics.
Together with the multi-stage programming and type-level annotations of binding-times,
we can derive the staged abstract interpreters without intrusive changes to
the corresponding unstaged one, thus the soundness is untouched.
In this sense, our approach is no regret of both performance and engineering
effort. We elaborate these two main ideas in detail as follow.

\paragraph{Futamura Projection of Abstract Interpreters}

The idea of specializing interpreters can be traced to Futamura
projections \cite{Futamura1999, futamura1971partial}.
The first Futamura projection specifically shows that
specializing an interpreter w.r.t. the input program yields an
equivalent executable. For instance, @eval@ is an interpreter for
some language:
\begin{lstlisting}
  def eval(e: Expr)(arg: Input): Value
\end{lstlisting}
Given a program $e_0$ of type @Expr@, by applying the specialization,
we can obtain a specialized interpreter $\texttt{eval}_{\texttt{e0}}$ :
@Input@ $\to$ @Value@, which is the so-called \textit{equivalent executable}.
By definition of the interpreter, they produce the same result when applied
with the argument $\texttt{eval}_{\texttt{e0}}(arg) = [\![ e_0 ]\!] arg $.

Partial evaluation \cite{DBLP:books/daglib/0072559} was the first
proposed approach to realize Futamura projections: it first discovers
the binding-times (\textit{static} or \textit{dynamic}) of variables,
then evaluates the static part of the program, and generates a residualized
program that solely relies on the dynamic part. However, it is hard to
precisely analyze binding-times given an arbitrary program.
As an alternative approach to specialization, multi-stage programming (MSP)
\cite{taha1999multi, DBLP:conf/pepm/TahaS97}
lets the programmer to explicitly control and annotate the
binding-times in the program, then the MSP system will check whether these annotations
are consistent and specialize the program using that information.
The staging annotations can be either syntactic (e.g., quote and quasiquote
in MetaML/MetaOCaml) or type-based (e.g., the Lightweight Modular Staging
framework \cite{DBLP:conf/gpce/RompfO10} in Scala).

Our proposed framework adopts the type-based multi-stage programming from
the Lightweight Modular Staging framework and implements the Futamura
projection of a big-step abstract interpreter for a small stateful,
higher-order language.
We use \citet{DBLP:journals/pacmpl/DaraisLNH17}'s abstract definitional
interpreter that uses monad transformers as the unstaged baseline. By
deriving staged monads that can be used to do code generation, we may
obtain a staged abstract interpreter that fulfills the specialization.
After staging, the generated code is specialized to the input program,
and all monadic operations are all inlined and compiled down to low-level
Scala code.

\input{fig_confluence.tex}

\paragraph{Generic Interpreter and Reinterpretation}

The central basis of our approach is a semantic-agnostic interpreter, which can be
instantiated by different interpretations or compilations (Figure~\ref{confluence}).
The different semantics in Figure~\ref{confluence} correspond to four different
artifacts involved in software language engineering: definitional interpreters
which are defined by the denotational or operational semantics, compilers that
translate the program into another language, analyzers that statically compute the
runtime properties of programs, and optimizing analyzers that achieve the same goal
of analyzers but in the way of compilers. We observe that these four
tasks may look like very differently at first glance, but in fact are
all firmly rooted in the concrete semantics of the language.

To achieve the flexibility of reinterpreting the shared interpreter by
different semantics, our framework abstracts the primitive operations
from these semantics, and extensively uses abstract type members over
the binding-times, the components of the interpreter, and the returned
monadic type of the interpreter. The binding-time abstraction is
represented by a higher-kinded type, and controls whether the
interpreter produces values or generates code. The components of the
interpreter, such as the environment and values, determines the domain
that the interpreter will be running with. Following the AAM approach,
by applying a series of abstractions to these components, we can
derive computable and sound abstract interpreters. Finally, the
monadic abstraction encapsulates both the binding-times and
components, which appears as the returned type and defines the
behaviors and datatype the interpreter operates on.

\paragraph{Applications and Evaluations}
We evaluate the idea of staging an abstract interpreter through
multiple case studies and empirical evaluation on performance.
1) We compare our approach with abstract compilation
\cite{Boucher:1996:ACN:647473.727587}, and show that we can achieve
the same optimization by utilizing type-based stage annotations;
meanwhile, the analyzer program does not need any changes, thereby
requires little engineering efforts.
2) We extend the basic staged abstract interpreter to diverse flow
analysis, including a store-widened analysis, a context-sensitive
analysis and abstract garbage collection.
3) We notice that staging an abstract interpreter enables modularly
compiling an analysis to programs. The compiled analysis is reusable,
therefore it provides a mechanized way to create library summaries by
reusing a whole-program analyzer.
4) We also empirically evaluate the performance improved by staging,
showing an order of magnitude speed-up on flow-analysis.

\paragraph{Contributions} Briefly, the contribution of the paper is as follows:
\begin{itemize}[leftmargin=2em]
  \item To our best knowledge, we present the first one to use
    multi-stage programming to specialize a general abstract interpreter,
    and our approach does not touch the soundness of analyses.
  \item Intellectually, our framework naturally extends the first
    Futamura projection to abstract interpreters, showing a
    well-grounded approach to optimize static analyses via
    metaprogramming.
  \item Pragmatically, we show that staging abstract interpreters is
    useful to improve performance and scalability of analyses by case
    studies and empirical evaluation.
\end{itemize}

\paragraph{Organization} The paper is organized as follows:
\begin{itemize}[leftmargin=2em]
  \item We begin by introducing our core target language and reviewing
    monads in Scala, and then presenting the generic interpreter (Section~\ref{prelim}).
    After which, we review its instantiations of concrete interpretation
    (Section~\ref{unstaged_conc}) and staged concrete interpretation
    (Section~\ref{stagedinterp}).
  \item We present the unstaged abstract interpreter under the same framework by
    replacing the environment, store and values (Section~\ref{unstaged_abs}).
    After, we show the combination of approximation and specialization, dubbed
    \textit{staged abstract interpreters}, can be readily derived (Section~\ref{sai}).
  \item We conduct three case studies (Section~\ref{cases_study}), which demonstrate that
    our approach requires less engineering efforts, is applicable to various analysis,
    and enables modular analysis.
  \item We empirically evaluate the performance improvement by staging on
    control-flow analysis (Section~\ref{evaluation}). We compare the both
    context-insensitive and store-widening analysis.
\end{itemize}

\iffalse
On the other side, static analysis is a tradeoff between performance and
precision: higher precision usually leads to longer running time.

4. Existing method to improve the performance is adhoc, engineering heavy, require to rewrite the optimized version, therefore harder to reason about the correctness
6. program analyzers are also meta-programs, they manipulate other programs as data objects
\fi
