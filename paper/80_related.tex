\section{Related Work}

\paragraph{Optimizing Static Analysis Through Specialization} The underlying
idea in this paper is closely related to abstract compilation (AC)
\cite{Boucher:1996:ACN:647473.727587}: removing the interpretative overhead of
traversing the syntax tree by specialization. The residual programs of AC can
be either textual (using quasi-quotations) or closures (using higher-order
functions).  Our approach is more flexible between representations and requires
less engineering efforts to refactor the analyzer (Section \ref{cs_ac}).
\citet{Johnson:2013:OAA:2500365.2500604} adapted closure generation to optimize a
small-step abstract interpreter in state-transition style. The program
is firstly compiled to an ``abstract bytecode'' IR. The IR consists of higher-order
functions, which will be executed later on an abstract abstract machine for
that IR.  \citet{damian1999partial} provided a formal treatment for abstract
compilation and control-flow analysis, as well as proofs to establish the
correctness of a certified specialized analyzer.  \citet{amtoft1999partial}
applied partial evaluation for constraint-based control-flow analysis.

Splitting an analysis into multiple stages has also been studied for other
forms of static analyses.
\citet{DBLP:conf/cgo/HardekopfL11} applied staging to a
flow-sensitive pointer analysis. The first stage is to analyze the
programs and obtain a sparse representation, and then the second
stage conducts a flow-sensitive analysis by refining the first
one. Another large body of static analyses is implemented by
first generating constraints and then using a solver to discharge the
proof obligations or find the fixed-point. Notable examples include
SAT- and SMT-based program analysis
\cite{Gulwani:2008:PAC:1375581.1375616} and Datalog-based points-to
analysis \cite{Smaragdakis:2015:PA:2802194.2802195}.
Such analyses can be considered having stage distinctions.  One piece of future
work is to explore whether they can be implemented and optimized using
meta-programming.
Souffl{\'e}, one of the state-of-the-art Datalog engines commonly used in
points-to analysis \cite{Antoniadis:2017:PDS:3088515.3088522}, uses Futamura
projections for efficient implementation \cite{10.1007/978-3-319-41540-6_23}.
However, it only specializes the solving engine to Datalog rules, instead of a
full pipeline from a program AST to a specialized solver.

Recent work shows that numerical abstract domains can be
specialized to the static program structure, although not by
ways of staging. For example, decomposing polyhedrons
\cite{DBLP:conf/popl/SinghPV17, Singh:2017:PCD:3177123.3158143} to
smaller ones depending on the variables involved in a statement can
significantly improve the running time and space consumption of abstract
transformers.

\paragraph{Construction of Abstract Interpreters} Abstract interpretation is a
semantics-based approach to build sound static analysis by approximation
\cite{DBLP:conf/popl/CousotC77, Cousot98-5}.
As for building semantic artifacts, the Abstracting Abstract Machines (AAM)
\cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10} approach shows that
abstract interpreters can be derived systematically from concrete semantic
artifacts based on operational semantics.
The AAM approach is closely related to control-flow analysis for higher-order languages
\cite{Midtgaard:2012:CAF:2187671.2187672, Shivers:1991:SSC:115865.115884}.
Using monads to construct abstract interpreters was explored by
\citet{Sergey:2013:MAI:2491956.2491979, DBLP:journals/pacmpl/DaraisLNH17,
Darais:2015:GTM:2814270.2814308}.
The unstaged abstract interpreter in this paper follows the abstracting
definitional interpreters (ADI) approach \cite{DBLP:journals/pacmpl/DaraisLNH17}.  
Similar to ADI, reconstructing
big-step abstract interpreters with delimited continuations was shown by
\citet{Wei:2018:RAA:3243631.3236800}; \citet{Keidel:2018:CSP:3243631.3236767}
presented a modular, arrow-based abstract interpreter that allows soundness
proof to be constructed compositionally.
\citet{DBLP:conf/cc/CousotC02} proposed an abstract interpretation framework for
modular analysis, from where we borrow the notation of modular analysis.
However, the staged abstract interpreter does not generate complete summaries for
modules; instead, it specializes the analysis modularly. Similarly, AC
is considered as an example of this kind of modular analyses \cite{DBLP:conf/cc/CousotC02}.

\paragraph{Control-flow Analysis} Our case studies and evaluation focus on
control-flow analysis for functional languages
\cite{Shivers:1991:SSC:115865.115884, Midtgaard:2012:CAF:2187671.2187672}. In
general, $k$-CFA (where $k > 0$) is considered impractical to be used as a
compiler pass, due to its EXPTIME lower bound
\cite{VanHorn:2008:DKC:1411204.1411243}.  However, several variants of 0CFA
were developed and shown to be useful in practice
\cite{Adams:2011:FTR:2048066.2048105, Bergstrom:2014:PEH:2628136.2628153,
ashley:practical, Reppy:2006:TCA:1159876.1159888}.

\paragraph{Two-level Semantics} The idea of reinterpreting the semantics as
abstract interpretation can be traced to Nielson's two-level semantics
\cite{NIELSON1989117}; using two-level semantics for code generation
was also explored by \citet{NIELSON198859}.
\citet{Sergey:2013:MAI:2491956.2491979}'s monadic abstract
interpreters is closely related to the two-level semantics: the
use of a generic interface with monads and then reinterpreting it with
different semantics is already two-level. Instead of focusing on
semantics, this paper shows how a staged analyzer can be built and
used to increase efficiency of static analyses. We augment the monadic
abstract interpreter with binding-time polymorphism, using code generation to
produce efficient low-level code. The presented work can be considered as
a two-dimensional application of the two-level semantics.

\paragraph{Partial Evaluation and Multi-stage Programming}
Partial evaluation is an automatic technique for program
specialization and was studied comprehensively by
\citet{10.1007/3-540-61580-6_11, DBLP:books/daglib/0072559}.
In this paper, we use mutli-stage programming to specialize programs.
The Lightweight Modular Staging (LMS) framework
\cite{DBLP:conf/gpce/RompfO10} we used in the paper relies on
type-level stage annotations.  Other notable MSP systems using syntactic
quotations exist in the ML family, e.g., MetaML \cite{DBLP:conf/pepm/TahaS97}
and MetaOCaml \cite{DBLP:conf/gpce/CalcagnoTHL03, DBLP:conf/flops/Kiselyov14}. 
Compared with other approaches using syntactic quotations, LMS provides
guarantees for preserving evaluation orders within a stage.
\citet{Ofenbeck:2017:SGP:3136040.3136060} and
\citet{Amin:2017:CTI:3177123.3158140} discussed staging for generic programming
as well as stage polymorphism in LMS.
%The idea of staging an abstract interpreter we presented here
%is also applicable to other MSP systems.
Multi-stage programming has been widely used to improve the
performance in many other domains, such as optimizing compilers or
domain-specific languages \cite{DBLP:conf/pldi/RompfSBLCO14,
  DBLP:conf/snapl/RompfBLSJAOSKDK15,
  DBLP:journals/tecs/SujeethBLRCOO14, DBLP:conf/gpce/SujeethGBLROO13,
  DBLP:journals/jfp/CaretteKS09}, numerical computation \cite{PGL-038,
  DBLP:conf/pepm/AktemurKKS13}, generic programming
\cite{DBLP:journals/pacmpl/Yallop17,
  Ofenbeck:2017:SGP:3136040.3136060}, data processing
\cite{DBLP:conf/oopsla/JonnalageddaCSRO14,
  DBLP:conf/popl/KiselyovBPS17}, query compilation in databases
\cite{DBLP:conf/osdi/EssertelTDBOR18, DBLP:conf/sigmod/TahboubER18},
etc.

As a source of inspiration of this paper, the Futamura projections reveal a
close relation between interpreters and compilers, which was
originally proposed by \citet{futamura1971partial}, and later reprinted \cite{Futamura1999}.
\citeauthor{Amin:2017:CTI:3177123.3158140} considered a tower of concrete
interpreters and showed how to collapse them by using MSP -- it would be interesting
to explore this idea for multiple abstract interpreters
\cite{Cousot:2019:AAI:3302515.3290355, Giacobazzi:2015:APA:2676726.2676987}.
\citet{10.1007/11561347_18} discussed a monad with let-insertion and
memoization for code generation, using Gaussian Elimination in MetaOCaml as an
example. In this work, let-insertion is handled by the ANF transformation in
LMS, and the memoizing monad is just a combination of a reader monad and a state monad
operating on staged data.  Similar to the idea in this paper, specializing
monadic interpreters was explored by \citet{danvy1991compiling,
DBLP:conf/dsl/SheardBP99}. However, they are different from the performance motivation
here: the generated code is in monadic form.
