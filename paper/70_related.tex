\section{Related Work}

\paragraph{Optimizing Static Analysis Through Specialization}
The idea in this paper is closely inspired by abstract compilation
\cite{Boucher:1996:ACN:647473.727587}.
\citeauthor{Boucher:1996:ACN:647473.727587} presented abstract compilation
techniques as an efficient implementation of the monovariant flow analysis
(\textit{0}-CFA) for programs written in continuation-passing style. The key
idea is to remove the interpretation overhead on traversing the syntax tree by
partial evaluation. Specifically, they proposed two similar kinds of abstract
compilation techniques. The first one is to generate specialized analysis as a
textual program, which then can be loaded and executed by \texttt{eval} or other
similar mechanisms. The second one is to use closures, i.e., functions that
remember their environments, as a representation of specialized analysis. As we
show in the case study, compiling the analysis generates higer-order functions
on-the-fly with respect to the analyzed program, then the generated closure can
be applied immediately in the higher-order host language.

\citeauthor{Johnson:2013:OAA:2500365.2500604} adapt the idea of closure
generation to optimize small-step abstract interpreter in state-transition style
\cite{Johnson:2013:OAA:2500365.2500604}. The analyzed program is firstly
compiled to a intermediate representation called "abstract bytecode", which are
actually higher-order functions, and then be executed on a abstract abstract
machine for that IR.

\citet{damian1999partial} provides a formal treatment to abstract compilation
and Shiver's CFA, as well as proofs to establish correctness and certified
specialized analyzers \cite{damian1999partial}. \citeauthor{amtoft1999partial}
applyies partial evaluation for constraint-based control flow analysis
\cite{amtoft1999partial}. Split the analysis to be multiple stages is also
studied other than control-flow analysis, though the formulation may very
different. For example, \citeauthor{DBLP:conf/cgo/HardekopfL11} apply staging to
flow-sensitive pointer analysis \cite{DBLP:conf/cgo/HardekopfL11}. The first
stage is to analyze the program code to obtain a sparse representation, and then
the second stage conducts the flow-sensitive analysis.

\citeauthor{DBLP:conf/popl/SinghPV17} optimizes polyhedra abstract domain
through online decomposition \cite{DBLP:conf/popl/SinghPV17,
Singh:2017:PCD:3177123.3158143}. The idea is to decompose a large polyhedra into
several smaller one; one abstract transformer usually only depends a limit
number of variables, then we just need to compute the resulting polyhera on
those smaller polyhedra that contains these related variables. The decomposition
can be considered as a specialization of abstract domain with respect to the
program static structure.

\paragraph{Abstract Interpreters} Abstract interpretation was proposed as a
semantic-based approach to construct sound static analysis by approximation
\cite{DBLP:conf/popl/CousotC77}. As semantic artifacts, the Abstracting Abstract
Machines (AAM) \cite{DBLP:journals/jfp/HornM12, DBLP:conf/icfp/HornM10} approach
shows that abstract interpreters can be derived systematically from concrete
semantic artifacts. The big-step abstract interpreters we presented in this
paper are also inspired by the AAM framework, which are later adopted for
big-step abstract interpreters \cite{DBLP:journals/pacmpl/DaraisLNH17,
Wei:2018:RAA:3243631.3236800}. \cite{DBLP:conf/cc/CousotC02} also proposed an
abstract interpretation framework for modular analysis.
\citet{DBLP:conf/popl/CalcagnoDOY09} developed compositional shape analysis by
using bi-abduction. The big-step abstract interpreter we presented in this paper
is inspired by \cite{DBLP:journals/pacmpl/DaraisLNH17,
Wei:2018:RAA:3243631.3236800}. \citet{Keidel:2018:CSP:3243631.3236767}
demonstrate a similar implementation of definitional abstract interpreter using
arrows.

\paragraph{Meta-Programming} The Lightweight Modular Staging framework relies on
types as stage annotations, and the staging procedure is modular. Other notable
implementations of MSP exist in ML family, for examples, MetaML
\cite{DBLP:conf/pepm/TahaS97} and MetaOCaml \cite{DBLP:conf/gpce/CalcagnoTHL03,
DBLP:conf/flops/Kiselyov14}. Compared with the LMS approach in Scala,
MetaML/MetaOCaml use term-level annotations such as brackets, escape, and run.
Notwithstanding, we use LMS in this paper, the idea of staging an abstract
interpreter still applies with other MSP implementations. Partial evaluation as
an automatic technique is studied comprehensively
\cite{10.1007/3-540-61580-6_11, DBLP:books/daglib/0072559}. Futamura projections
reveals close relations between interpreters and compilers \cite{Futamura1999,
futamura1971partial}. \citet{DBLP:conf/gpce/Asai14} studies the compilation of
reflective language using MSP and MetaOCaml.
\citeauthor{Amin:2017:CTI:3177123.3158140} shows how to collapse a tower of
concrete interpreters by MSP and LMS framework.
