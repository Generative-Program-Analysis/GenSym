\section{From Abstract Interpreters to Staged Abstract Interpreters} \label{sai}

In the previous section, we have seen an unstaged abstract interpreter and a staged concrete interpreter, 
now we begin describing the implementation of their confluence -- a staged abstract interpreter. 
We present a principled approach to derive staged abstract interpreter
from its unstaged version. One guiding principle of our approach is the code of abstract semantics
and the code that optimizes should be separated. Thus it is also an advantage of doing staging 
for abstract interpreters: the designer of analysis has no need to rewrite the analysis, and 
the performance improvement comes almost for free, without any sacrifice of soundness or precision.
Unsurprisingly, the staged abstract interpreter we present in this section has the same abstract 
semantics with the unstaged version we presented in Section~\ref{unstaged_abs}.

\subsection{Staged Lattices} 
In Section~\ref{stagedpoly_lat}, we exploited the higher-kinded type @R@
to leave space for staging lattices, now we instantiate @R@ to @Rep@ and still use powerset as an 
example to present its staged version. 

\begin{lstlisting}
trait RepLattice[A] extends Lattice[A, Rep]
implicit def RepSetLattice[T:Typ]: RepLattice[Set[T]] = 
  new RepLattice[Set[T]] {
    lazy val bot: Rep[Set[T]] = Set[T]()
    lazy val top: Rep[Set[T]] = throw new NotImplementedError()
    def $\sqsubseteq$(l1: Rep[Set[T]], l2: Rep[Set[T]]): 
      Rep[Boolean] = l1 subsetOf l2
    def $\sqcup$(l1: Rep[Set[T]], l2: Rep[Set[T]]): 
      Rep[Set[T]] = l1 union l2
    def $\sqcap$(l1: Rep[Set[T]], l2: Rep[Set[T]]): 
      Rep[Set[T]] = l1 intersect l2
  }
\end{lstlisting}

The type parameter @T:Typ@ of @RepLattice@ requires the element of sets
is also can be staged, otherwise without knowing how to stage the elements in the set
we can not stage the set as well.
The methods defined operate on type @Rep[Set[T]]@, thus the underlying implementation
such as @union@ and @intersect@ will be mapped to a node in IR graph and emitted in 
the generated code. Again, other structures such as maps and tuples are also implemented
in a similar way.

\subsection{Staged Abstract Semantics} 
We have seen how to obtain a staged concrete semantics
based on types, now we take the same approach to obtain a staged abstract semantics.
\todo{what are static, what are dynamic?}
The basic operations largely kept same as the unstaged version, except the types are changed to @Rep@.
Besides, when we update the environment, the identifier @x@ is known statically, but the map of environment
has type @Rep[Map[Ident,Addr]]@, so we apply @lift@ to @x@ to make it as a next-stage value.

\begin{lstlisting}
trait RepAbsInterpOps extends Abstract with LMSOps {
  type R[+T] = Rep[T]
  val $\rho$0: Rep[Env] = Map[Ident, Addr]()
  val $\sigma$0: Rep[Store] = Map[Addr, Value]()
  def get($\rho$: Rep[Env], x: Ident): Rep[Addr] = $\rho$(x)
  def put($\rho$: Rep[Env], x: Ident, a: Rep[Addr]): 
    Rep[Env] = $\rho$ + (lift(x) -> a)
  def get($\sigma$: Rep[Store], a: Rep[Addr]): Rep[Value] = 
    $\sigma$.getOrElse(a, RepLattice[Value].bot)
  def put($\sigma$: Rep[Store], a: Rep[Addr], v: Rep[Value]): 
    Rep[Store] = $\sigma$ + (a -> RepLattice[Value].$\sqcup$(v, get($\sigma$, a)))
  def alloc($\sigma$: Rep[Store], x: Ident): Rep[Addr] = Addr(x)
  def num(i: Lit): Rep[Value] = Set(NumV())
  def branch0(cnd: Rep[Value], thn: => Ans, els: => Ans): Ans =
    thn $\sqcup$ els
  def prim_eval(op: Symbol, 
                v1: Rep[Value], v2: Rep[Value]): Rep[Value] = 
    Set(NumV())
  ...
}
\end{lstlisting}

Once more, the way we handle closures is as same as the staged concrete interpreter:
the recursive call to @ev@ with the body expression @e@ is compiled and specialized, 
the wrapper function @f@ and will be a field value of @CompiledClo@ and be generated
for the next stage. At the end, we return a singleton set.

\begin{lstlisting}
def close(ev: EvalFun)($\lambda$: Lam, $\rho$: Rep[Env]): Rep[Value] = {
  val Lam(x, e) = $\lambda$
  val f: Rep[(Value, Store)]=>Rep[(Value,Store)] = {
    case (args: Rep[Value], $\sigma$: Rep[Store]) =>
      val args = as._1; val $\sigma$ = as._2; val $\alpha$ = alloc($\sigma$, x)
      ev(e, put($\rho$, x, $\alpha$), put($\sigma$, $\alpha$, args))
    }
  Set[AbsValue](CompiledClo(fun(f)))
}
def apply_closure(ev: EvalFun)
  (f: Rep[Value], arg: Rep[Value], $\sigma$: Rep[Store]): Ans = {
    reflectEffect(ApplyClosure(f, arg, $\sigma$))
  }
\end{lstlisting}

When generating code for application, we can not directly apply the callee.
Instead, we emit code that calls a next-stage function @apply_closures_norep@ 
which non-deterministically applies multiple target closure with the argument
and latest store, and finally returns the joined value and a single store.

\begin{lstlisting}
case ApplyClosures(fs, arg, $\sigma$) =>
  emitValDef(sym, "apply_closures_norep(" + 
                  quote(fs) + "," + quote(arg) + 
                  "," + quote($\sigma$) + ")")
\end{lstlisting}

\subsection{Staged Fixpoint Iteration.} 
\todo{staged fixed point iteration with memoization}

\subsection{Specialized Data Structures}

Now we already obtained a working version of staged abstract interpter that is able to 
specialize an analysis. However, we treat the data structures such as @Map@s as black-boxes,
which means any operations on a @Map@ becomes code in the next stage.
But, as we identified before \todo{where}, the keys of environment are identifiers in the program,
which are completely known statically. This leaves us a chance to further specialize the 
data structures. Particularly, if we are specializing a monovariant analysis, the address space 
is equivalent to the identifiers, then the environment component can be entirely eliminated, 
and the store is a partially specialized map.
\todo{maps to arrays}

\subsection{Modular Analysis for Free}

Motivation: one of the challenges of modern static analysis is program usually depends on
large libraries programs\cite{toman_et_al:LIPIcs:2017:7121}. 
Can we analyze programs and libraries separately without losing precision? So that we can 
reduce part of the overhead of repeatedly analyzing libraries for different programs.
Similarly, some static analyzers compute summary for a function or a module, that can be reused
later (like Facebook Infer). But to my knowledge, they are mostly too conservative (context-insensitive) 
or unsound, which both lead to imprecision.

Application: for example, k-CFA (k > 0) is naturally a kind of whole program analysis,
because it is interprocedural and need the last k calling contexts to distinguish
different call sites.
But can we analyze programs (libraries) separately which generate the specialized 
analysis and leave the unavailable programs (for the moment) as dynamic parameters, 
and then install these contexts when we have the whole program.

Another perspective: programs are data for an abstract interpreter, so if we have $n$ programs, 
then maybe there can be $n$ stages. 
Probably we can analyze first $m$ programs, and generate a residual abstract interpreter
waiting for the rest $(n-m)$ programs.
These $(n-m)$ programs might be (abstract) arguments for the first $n$ programs, and
the abstract interpreter itself might be a partial abstract interpreter.

\subsection{Discussion}
Review a little bit what we have done?
what not to do when writing an abstract interpreter for staging?
what kind of abstract interpreter is friendly for staging/specialization?

Stage an abstract abstract machine yields another small-step abstract machine

\paragraph{Big-step vs Small-step.}

direct-style vs CPS

Operational vs denotational

General insights for staging other static analysis algorithm.

\paragraph{Soudness.}

\cite{10.1007/3-540-61580-6_11}

Jones-optimal specialization?
Futamura projection?
Lattice-theoretic Interpretation
