\newcommand{\TLang}{$L_\lambda$}

\section{Preliminaries} \label{prelim}

In this section, we first describe the abstract syntax of the language for our interpreter, 
then present the generic interpreter shared among the four different
semantics, after which, we instantiate the interpreter to the concrete one.
It is worth noting that we choose to use Scala and monad to demonstrate the
idea, but the approach is not restricted to our choice. One can use
imperative or direct style in other MSP languages (e.g., MetaOCaml
\cite{DBLP:conf/gpce/CalcagnoTHL03, DBLP:conf/flops/Kiselyov14} and Template
Haskell \cite{Sheard:2002:TMH:636517.636528} to construct such staged abstract
interpreters.

\subsection{Abstract Syntax} \label{bg_lang}

We consider a call-by-value $\lambda$-calculus in direct-style, extended
with numbers, arithmetic, recursions, and conditionals. Other effectful features
such as assignments can also be supported readily.
%In Section~\ref{cases_imp}, we will add more imperative features to the language.
Since we are mostly interested in analyzing the dynamic behaviors of the
program, we disguise any static semantics and type system. We also assume that
input programs are well-typed and all variables are distinct. The abstract
syntax is shown as follows:

\begin{lstlisting}
  abstract class Expr
  case class Lit(i: Int) extends Expr                         // numbers
  case class Var(x: String) extends Expr                      // variables
  case class Lam(x: String, e: Expr) extends Expr             // abstractions
  case class App(e1: Expr, e2: Expr) extends Expr             // applications
  case class If0(e1: Expr, e2: Expr, e3: Expr) extends Expr   // conditionals
  case class Rec(x: String, rhs: Expr, e: Expr) extends Expr  // recursions
  case class Aop(op: String, e1: Expr, e2: Expr) extends Expr // arithmetic
\end{lstlisting}

The abstract syntax we present in fact can be seen as a deep embedding of the
language -- we use data-types to represent programs. This design choice allows us
to easily use different interpretations over the AST; with the inheritance and
overriding mechanism in Scala, we may also add new language constructs and reuse
existing interpretations \todo{cite Bruno?}.

\iffalse
We will give the concrete semantics using a big-step definitional
interpreter. The interpreter is a recursive function that takes the program AST,
environment, and store, and returns the evaluated value and the accompanying
store. The environment is a mapping from identifiers to addresses, and the store
is a mapping from addresses to values. We use the store to model recursion and
mutation in concrete semantics; it is also useful for polyvariant analysis. This
environment-and-store-passing style big-step interpreter is standard and can
also be obtained by refunctionalizing \cite{DBLP:conf/ppdp/AgerBDM03,
Wei:2018:RAA:3243631.3236800} a small-step CESK machine
\cite{DBLP:conf/popl/FelleisenF87}.
\fi

\subsection{Monads in Scala} \label{monadscala}

A monad is a type constructor @M[_]: * -> *@ with two operations, often called
@return@ and @bind@. Informally, @return@ wraps a value into the monad @M@, and
@bind@ unwraps the monadic value and transforms it into a new monadic value.
Pragmatically in Scala, we define a monad type class using trait @Monad@ (Figure
\ref{fig:monad}), where it declares the @pure@ \footnote{We elect to use
\texttt{pure} as the name, since \texttt{return} is a keyword in Scala and
\texttt{unit} is a built-in function in LMS.} and @flatMap@ operation. The trait
itself takes the monad type @M[_]@ as argument, which is a higher-kinded type
that takes a type and returns a type. The method @pure@ promotes values of type
@A@ to values of type @M[A]@. The monadic @bind@ operation is usually called
@flatMap@ in Scala, which takes a monad-encapsulated value of type @M[A]@, a
function of @A => M[B]@ and returns values of type @M[B]@.

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.55\textwidth}
    \begin{lstlisting}
  trait Monad[M[_]] {                                  
    def pure[A](a: A): M[A]                            
    def flatMap[A,B](ma: M[A])(f: A => M[B]): M[B]     
  }                                                    
    \end{lstlisting}
    \caption{trait \texttt{Monad}} \label{fig:monad}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.4\textwidth}
    \begin{lstlisting}
trait MonadOps[M[_], A] {
  def map[B](f: A => B): M[B]
  def flatMap[B](f: A => M[B]): M[B]
}
    \end{lstlisting}
    \caption{trait \texttt{MonadOps}} \label{fig:monadops}
  \end{subfigure}
\end{figure}

Similar to Haskell's @do@-notation, Scala provides special syntactic support for
monadic operations through @for@-comprehension.
For example, an object of @List[A]@ is an instance of @List@ monad, where @A@ is the element type. 
Then to compute the Cartesian product of two lists of numbers, we can use Scala's
@for@-comprehension syntax.

\begin{lstlisting}
  val xs = List(1, 2); val ys = List(4, 5)
  for { x <- xs; y <- ys } yield (x, y) // List((1,4), (1,5), (2,4), (2,5))
\end{lstlisting}

The Scala compiler will translate the above @for@-comprehension expression into
an equivalent one using @flatMap@ and @map@ ~\cite{scala_spec}. The last binding
in the @for@-comprehension is translated into a @map@, where the expression of
@yield@ becomes the body expression of that @map@ application. The foregoing
bindings in the comprehension are all translated into calls of @flatMap@.

\begin{lstlisting}
  xs.flatMap { case x => ys.map { case y => (x, y) } }
\end{lstlisting}

Note that here the monadic object @List[_]@ encapsulates the data internally.
Therefore it only exposes the simplified version of @flatMap@, where the
monad @M[A]@ is not introduced as a function argument. The trait @MonadOps@
(Figure \ref{fig:monadops}) defines the simplified version of monadic
operations that are necessary for @for@-comprehension. 
The conversion between @Monad@ and @MonadOps@ can be done by using the implicit design pattern.
In the rest of the paper, we use Scala's @for@-comprehension syntax and monad
transformers such as @ReaderT@, @StateT@, and @ListT@ to write our interpreters.
The implementation of monads and monad transformers essentially borrows the
ground-truth from Haskell.

\subsection{Generic Interpreter} \label{generic_if}

Monad transformers are type constructors of kind @(* -> *) -> (* -> *)@, which
take a monad as argument and produces another monad. By using monad
transformers, we can combine multiple monads into a single one. Constructing
extensible interpreters using monad transformers was first proposed by
\citet{DBLP:conf/popl/LiangHJ95}, and later has been applied to abstract
interpreters \cite{Sergey:2013:MAI:2491956.2491979,
DBLP:journals/pacmpl/DaraisLNH17, Darais:2015:GTM:2814270.2814308}. In this section,
with the multi-stage programming and monad transformers in mind while leaving them
as abstract type members, we present the generic interface of a big-step
definitional interpreter.

\paragraph{Basic Types} We start with some basic type definitions used in the
interpreter. The identifiers in the program are represented by strings. The two
default components in the interpreter are environments @Env@ and stores @Store@,
i.e., mappings from identifiers to addresses and mappings from addresses to
values, respectively. The @Env@ models accessible variables, and @Store@ models
the persistent heap through the program runtime. But the @Addr@ and @Value@ are
just declared as abstract types.

\begin{lstlisting}
  trait Semantics {
    type Ident = String; type Addr; type Value
    type Env = Map[Ident, Addr]; type Store = Map[Addr, Value]
    type R[_] // Binding-time as a higher-kinded type
    ... // The definitions in the rest of this section are enclosed in trait Semantics.
  }
\end{lstlisting}

\paragraph{Binding-time Abstraction} As mentioned before, the binding-time is
declared as a higher-kinded type @R[_]@. If we simply instantiate @R@ as an identity
type (i.e., @type R[T] = T@), then the generic interpreter will execute the program.
In Section \ref{stagedinterp}, we will instantiate @R@ using LMS's built-in
next-stage type annotation @Rep@, which makes the interpreter act as a compiler.

\paragraph{Monadic Operations} We define the return type of the interpreter as
@Ans@, which is an arbitrary monad type @AnsM[_]@ wrapping the type @Value@. 
As mentioned in Section ~\ref{monadscala}, to use the @for@-comprehension
syntax, certain constraints have to be added on the type @AnsM@. Here, we use a
structural type @MonadOps@ to require @AnsM@ to at least implement @map@ and
@flatMap@. It is worth noting that @MonadOps@ takes another type parameter
@R[_]@ as binding-time; accordingly the outer @R@ defined in the trait is passed
to @MonadOps@. Inside of @MonadOps@, @R[_]@ wraps the data types @A@ and @B@ that are
encapsulated by the monad, but not the monad type @M@ itself. When acting as
compilers, we will also replace the monads to the ones that work on staged
values.

We also define several methods to obtain and modify the environment and store.
These methods return monadic values of type @AnsM[_]@, which encapsulate the 
environment or store, or simply a @Unit@ value for effects.
For example, @local_env@ takes a value @ans@ of type @Ans@ and an environment 
which will be installed when evaluating @ans@.

%\vspace{-1em}
\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{lstlisting}
  type MonadOps[R[_], M[_], A] = {
    def map[B](f: R[A] => R[B]): M[B]
    def flatMap[B](f: R[A] => M[B]): M[B]
  }
  
  type AnsM[T] <: MonadOps[R, AnsM, T]
  type Ans = AnsM[Value]
    \end{lstlisting}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.55\textwidth}
    \begin{lstlisting}
// Environment operations
def ask_env: AnsM[Env]
def local_env(ans: Ans)(ρ: R[Env]): Ans
// Store operations
def get_store: AnsM[Store]
def put_store(σ: R[Store]): AnsM[Unit]
def set_store(av: (R[Addr], R[Value])): AnsM[Unit]
    \end{lstlisting}
  \end{subfigure}
\end{figure}
%\vspace{-1em}

\paragraph{Primitive Operations} Next we define several primitive operations.
Two versions of @alloc@ are declared. The first one takes a store and an
identifier and produces a fresh address of non-monadic type @R[Addr]@. Since
the freshness of the address may depend on the store, which might be a
next-stage value as indicated by its type, the type of addresses is also wrapped
by @R[_]@. The other one would simply wrap the address with our monadic type
@AnsM[_]@.
\begin{lstlisting}
  def alloc(σ: R[Store], x: Ident): R[Addr];  def alloc(x: Ident): AnsM[Addr]
\end{lstlisting}

Other primitive operations provide basic functionality for the interpreter.
The method @num@ and @close@ deal with primitive values, which lift literal
terms (e.g., lambdas) to our value representation (e.g., closures).
The method @get@ simply retrieves the value mapped from the identifier @x@ in
the environment and store. Conditionals and arithmetic is handled by @br0@
and @arith@, respectively. The methods @ap_clo@ takes a function value and an
argument value and then does the application. Note that the @Env@, @Store@, and
@Value@ are all wrapped by @R[_]@ since they will be known as next-stage value
when acting as compilers.

%TODO: close/ap_clo takes an ev

\begin{lstlisting}
  def num(i: Int): Ans
  def get(σ: R[Store], ρ: R[Env], x: Ident): R[Value]
  def close(ev: Expr => Ans)(λ: Lam, ρ: R[Env]): R[Value]
  def br0(test: R[Value], thn: => Ans, els: => Ans): Ans
  def arith(op: Symbol, v1: R[Value], v2: R[Value]): R[Value]
  def ap_clo(ev: Expr => Ans)(rator: R[Value], rand: R[Value]): Ans
\end{lstlisting}

\paragraph{The Interpreter} Now we can define the semantics-agnostic interpreter
in monadic form, shown in Figure \ref{fig:shared_int}.
The essential idea is to traverse the abstract syntax tree while maintaining the
effects such as reader and state.
It is worth noting that the interpreter is written in open-recursive style -- it
can not refer to itself directly, instead, @eval@ takes an additional parameter
@ev@ of type @Expr => Ans@ to refer to itself. Accordingly, the method @close@
that lifts lambda terms to closures and @ap_clo@ that applies functions also
takes an extra @ev@.

%\vspace{-1em}
\begin{figure}[h!]
  \centering
  \begin{lstlisting}
          def eval(ev: Expr => Ans)(e: Expr): Ans = e match {
            case Lit(i) => num(i)                   case Let(x, rhs, e) => for {
            case Var(x) => for {                      v  <- ev(rhs)
              ρ <- ask_env                            ρ  <- ask_env
              σ <- get_store                          α  <- alloc(x)
            } yield get(σ, ρ, x)                      _  <- set_store(α → v)
            case Lam(x, e) => for {                   rt <- local_env(ev(e))(ρ + (x → α))
              ρ <- ask_env                          } yield rt
            } yield close(ev)(Lam(x, e), ρ)         case Aop(op, e1, e2) => for {
            case App(e1, e2) => for {                 v1 <- ev(e1)                                               
              v1 <- ev(e1)                            v2 <- ev(e2)
              v2 <- ev(e2)                          } yield arith(op, v1, v2)
              rt <- ap_clo(ev)(v1, v2)              case Rec(x, rhs, e) => for {
            } yield rt                                α  <- alloc(x)
            case If0(e1, e2, e3) => for {             ρ  <- ask_env
              cnd <- ev(e1)                           v  <- local_env(ev(rhs))(ρ + (x → α))
              rt  <- br0(cnd, ev(e2), ev(e3))         _  <- set_store(α → v)
            } yield rt                                rt <- local_env(ev(e))(ρ + (x → α))
                                                    } yield rt                    
          }
  \end{lstlisting}
\caption{The generic interpreter,
  shared by the unstaged/staged + concrete/abstract interpreter.}
\label{fig:shared_int}
\end{figure}
%\vspace{-1em}

Since the interpreter is written in an open-recursive style, we declare an abstract
combinator @fix@ used to close the recursion. For concrete-interpretation instantiation, it
works like the Y combinator; for abstract-interpretation instantiation, we will
instrument the interpreter by defining a memorized version of @fix@ to ensure
termination. Finally, a top-level wrapper @run@ is declared; the return type
@Result@ depends on what kind of monad we will be using, this is also an abstract type.

\begin{lstlisting}
  def fix(ev: (Expr => Ans) => (Expr => Ans)): Expr => Ans
  type Result; def run(e: Expr): Result
\end{lstlisting}

%==========================================================================

\section{A Concrete Interpreter} \label{unstaged_conc}

Now we can instantiate the interpreter as a standard environment-store
interpreter. Such interpreter also can be obtained by refunctionalization of
CESK machines \cite{Felleisen:1987:CAH:41625.41654, DBLP:conf/ppdp/AgerBDM03}.

\paragraph{Concrete Components}
The two types we need to concretize are @Addr@ and @Value@, afterward, the @Env@
and @Store@ is concretized automatically. To assure the freshness, we use @Int@
for the address space @Addr@. A value can be either a tagged number
\texttt{IntV}, or a closure \texttt{CloV} that contains a lambda term and an
environment. The final return value of the interpreter is a pair of values and
stores, where the @Value@ and @Store@ are obviously next-stage objects. We also
provide a standard fixed-point combinator to close the open-recursive function @ev@.

\begin{lstlisting}
  trait ConcreteComponents extends Semantics {
    type Addr = Int
    sealed trait Value
    case class IntV(i: Int) extends Value
    case class CloV(λ: Lam, e: Env) extends Value
    type Result = (R[Value], R[Store])
    def fix(ev: (Expr => Ans) => (Expr => Ans)): Expr => Ans = e => ev(fix(ev))(e)
  }
\end{lstlisting}
%\vspace{-1em}

\paragraph{Unstaged Monads}
The environment and store can be modeled by reader effect and state effect,
i.e., a Reader monad and a State monad. We combine them using monad transformers
@ReaderT@ and @StateT@.
In other words, we instantiate the @AnsM@ monad as a stack of @ReaderT@ and @StateT@
transformers\footnote{The question mark syntax is a kind projector
  \cite{kindprojector}, thus \texttt{StateT[IdM,Store,?]} is equivalent to \newline
  \texttt{(\{type M[T]=StateT[IdM,Store,T]\})\#M}}, where the @ReaderT@ is
parameterized by type @Env@, @StateT@ is parameterized by type @Store@, and the
inner-most monad @IdM@ is just an identity monad.

\begin{lstlisting}
  trait ConcreteSemantics extends ConcreteComponents {
    type R[T] = T
    type AnsM[T] = ReaderT[StateT[IdM, Store, ?], Env, T]
    ...
  }
\end{lstlisting}

Here we sketch the basic idea of unstaged @ReaderT@ and @StateT@. Readers may
refer to \cite{DBLP:conf/popl/LiangHJ95, Chiusano:2014:FPS:2688794} for more detail 
and implementation of monad transformers.
A @ReaderT@ monad transformer encapsulates the computation @R => M[A]@, where
@R@ is the reader type, @M[_]@ is a monad type. The @ReaderT@ monad returns the
transformed value of type @M[A]@. Similarly, a @StateT@ monad encapsulates the
computation @S => M[(A, S)]@, where @S@ is the state type, @M[_]@ is a monad
type. The @StateT@ monad returns the transformed value of type @M[(A, S)]@,
where the new state is accompanied.
Note that the binding-time type @R@ is an identity type, thus the monads are
operated on unstaged data. We can also see this from the signature of @flatMap@:
the function @f@ takes an unstaged value of type @A@ and produces a monadic
value.

\begin{lstlisting}
  case class ReaderT[M[_]: Monad, R, A](run: R => M[A]) {
    def flatMap[B](f: A => ReaderT[M, R, B]): ReaderT[M, R, B] = ... }
  case class StateT[M[_]: Monad, S, A](run: S => M[(A, S)]) {
    def flatMap[B](f: A => StateT[M, S, B]): StateT[M, S, B] = ... }
\end{lstlisting}

Then, the monadic operations that manipulate the environment and store are
simply constructing the proper monads and lifting it to the top-level of our
monad stack. To modify the store, for example, we may have a @StateT@ monad that
transforms the current store $\sigma$ to @σ + αv@, which results in
@StateT[IdM, Store, Unit]@, and then lift this @StateT@ value to @ReaderT@,
i.e., @AnsM[Unit]@.
\begin{lstlisting}
  def set_store(αv: (Addr, Value)): AnsM[Unit] = liftM(StateTMonad.mod(σ => σ + αv))
\end{lstlisting}

\paragraph{Primitive Operations}
Other primitive operations can be implemented straightforwardly, for example,
@alloc@ simply takes the size of the current store and produces the successor number.
We elide most of them but describe a little bit on how do we handle functions
and applications as they will be very different when staging and abstract
interpretation is involved. The method @close@ takes a lambda term and an
environment, then create a closure value @CloV@.

\begin{lstlisting}
  def close(ev: Expr => Ans)(λ: Lam, ρ: Env): Value = CloV(λ, ρ)
\end{lstlisting}

To apply a function, the method @ap_clo@ takes a function value and an argument
value, and extracts the lambda term and environment enclosed in the function value,
and evaluates the body expression of that lambda term under the new environment and store.

\begin{lstlisting}
  def ap_clo(ev: Expr => Ans)(rator: Value, rand: Value): Ans = rator match {
    case CloV(Lam(x, e), ρ: Env) => for {
      α <- alloc(x)
      _ <- set_store(α → rand)
      rt <- local_env(ev(e))(ρ + (x → α))
    } yield rt
  }
\end{lstlisting}

With other primitive operations implemented, we can implement the top-level
@run@ method, where $\rho_0$ and $\sigma_0$ are the initial empty environment and
store.

\begin{lstlisting}
  def run(e: Expr): Result = fix(eval)(e)(ρ$_0$)(σ$_0$)
\end{lstlisting}
