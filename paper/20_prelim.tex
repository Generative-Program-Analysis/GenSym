\newcommand{\TLang}{$L_\lambda$}

\section{Preliminaries} \label{prelim}

In this section, we first describe the abstract syntax of the language for our
interpreters. Then, we present the generic interpreter shared among the four
different semantics, after which we instantiate the interpreter to the concrete
one. It is worth noting that we choose to use Scala and a monadic style to
demonstrate this idea, though the approach is not restricted to this choice.
Indeed, one can use imperative or direct style in other MSP languages (e.g.,
MetaOCaml \cite{DBLP:conf/gpce/CalcagnoTHL03, DBLP:conf/flops/Kiselyov14} or
Template Haskell \cite{Sheard:2002:TMH:636517.636528}) to construct such staged
abstract interpreters.

\subsection{Abstract Syntax} \label{bg_lang}

We consider a call-by-value $\lambda$-calculus in direct-style, extended with
numbers, arithmetic, recursion, and conditionals. Other effects such as
assignments can also be supported readily. Since we are mostly interested in
analyzing dynamic behavior of programs, we elide the static semantics. We also
assume that input programs are well-typed and all variables are distinct. The
abstract syntax is as follows:
\begin{lstlisting}
  abstract class Expr
  case class Lit(i: Int) extends Expr                         // numbers
  case class Var(x: String) extends Expr                      // variables
  case class Lam(x: String, e: Expr) extends Expr             // abstractions
  case class App(e1: Expr, e2: Expr) extends Expr             // applications
  case class If0(e1: Expr, e2: Expr, e3: Expr) extends Expr   // conditionals
  case class Rec(x: String, rhs: Expr, e: Expr) extends Expr  // recursion
  case class Aop(op: String, e1: Expr, e2: Expr) extends Expr // arithmetic
\end{lstlisting}

The abstract syntax we present can be seen as a deep embedding of the language:
we use data-types to represent programs. This design choice allows us to use
different interpretations over the AST; with the inheritance and overriding
mechanisms in Scala, we may also add new language constructs and reuse existing
interpretations.

%\todo{cite Bruno?}.

\iffalse
We will give the concrete semantics using a big-step definitional
interpreter. The interpreter is a recursive function that takes the program AST,
environment, and store, and returns the evaluated value and the accompanying
store. The environment is a mapping from identifiers to addresses, and the store
is a mapping from addresses to values. We use the store to model recursion and
mutation in concrete semantics; it is also useful for polyvariant analysis. This
environment-and-store-passing style big-step interpreter is standard and can
also be obtained by refunctionalizing \cite{DBLP:conf/ppdp/AgerBDM03,
Wei:2018:RAA:3243631.3236800} a small-step CESK machine
\cite{DBLP:conf/popl/FelleisenF87}.
\fi

\subsection{Monads in Scala} \label{monadscala}

A monad is a type constructor @M[_]: * --> *@ with two operations, often called
@return@ and @bind@ \cite{Wadler:1992:EFP:143165.143169,
DBLP:journals/iandc/Moggi91}. Informally, @return@ wraps a value into a monad
@M@, and @bind@ unwraps a monadic value and transforms it into a new monadic value.
Pragmatically in Scala, we define the monad type class using trait @Monad@
(Figure \ref{fig:monad}), which declares the @pure@ \footnote{We elect to use
\texttt{pure} as the name, since \texttt{return} is a keyword in Scala and
\texttt{unit} is a built-in function in LMS.} and @flatMap@ operations. The
trait itself takes the monad type constructor @M[_]@ as an argument, which, as a
higher-kinded type, takes a type and returns a type. The method @pure@ promotes
values of type @A@ to values of type @M[A]@. The monadic @bind@ operation is
usually called @flatMap@ in Scala. It takes a monad-encapsulated value of type
@M[A]@, a function of @A => M[B]@, and returns values of type @M[B]@.

\begin{figure}[h!]
  \centering
  \vspace{-1em}
  \begin{subfigure}[b]{0.55\textwidth}
    \begin{lstlisting}
  trait Monad[M[_]] {
    def pure[A](a: A): M[A]
    def flatMap[A,B](ma: M[A])(f: A => M[B]): M[B]
  }
    \end{lstlisting}
    \vspace{-0.5em}
    \caption{trait \texttt{Monad}} \label{fig:monad}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.4\textwidth}
    \begin{lstlisting}
trait MonadOps[M[_], A] {
  def map[B](f: A => B): M[B]
  def flatMap[B](f: A => M[B]): M[B]
}
    \end{lstlisting}
    \vspace{-0.5em}
    \caption{trait \texttt{MonadOps}} \label{fig:monadops}
  \end{subfigure}
\end{figure}
\vspace{-1em}

Similar to Haskell's @do@-notation, Scala provides special syntactic support
for monadic operations through @for@-comprehension.  For example, an object of
@List[A]@ is an instance of the @List@ monad, with element type @A@.
To compute the Cartesian product of two lists of numbers, we can use Scala's
@for@-comprehension syntax:
\begin{lstlisting}
  val xs = List(1, 2); val ys = List(3, 4)
  for { x <- xs; y <- ys } yield (x, y)   // List((1,3), (1,4), (2,3), (2,4))
\end{lstlisting}

The Scala compiler translates the above @for@-comprehension expression into
an equivalent one using @flatMap@ and @map@. The last binding
in @for@-comprehensions is translated into a @map@, where the argument of
@yield@ becomes the body expression inside that @map@ operation. The
bindings before the last one are all translated into calls of @flatMap@:
\begin{lstlisting}
  xs.flatMap { case x => ys.map { case y => (x, y) } }
\end{lstlisting}

Note that here the monadic object @List[_]@ encapsulates the data internally.
Therefore, it only exposes the simplified version of @flatMap@, where the monadic
value of @M[A]@ is not introduced as a function argument. The trait @MonadOps@ (Figure
\ref{fig:monadops}) defines the simplified versions of monadic operations that
are necessary for @for@-comprehension. The conversion between @Monad@ and
@MonadOps@ can be achieved by using the implicit design pattern.
In the rest of the paper, we use Scala's @for@-comprehension syntax and a few
monads and monad transformers such as @ReaderT@, @StateT@, and @SetT@ to
write our interpreters.
Monad transformers are type constructors of kind @(* --> *) --> (* --> *)@, which
take a monad as an argument and produce another monad. By using monad
transformers, we can combine multiple monads into a single one.  The
implementation of monads and monad transformers follows the ones from Haskell.

\subsection{Generic Interpreter} \label{generic_if}

In this section, we present the generic interface in the style of a big-step
definitional interpreter. The key idea is to keep both the binding-time type and
returned monadic type abstract, so that they can be instantiated
differently. We also need to abstract the primitive operations on those types.
In later sections, we will instantiate the monadic type to perform concrete
interpretation \citet{DBLP:conf/popl/LiangHJ95} or abstract interpretation
\cite{Sergey:2013:MAI:2491956.2491979, DBLP:journals/pacmpl/DaraisLNH17}.

\paragraph{Basic Types} We start with some basic type definitions that are used
in the interpreter. The identifiers in the program are represented by strings.
To represent states, two required components for the interpreter are
environments, represented by type @Env@, and stores, represented by type
@Store@. An @Env@ maps identifiers to addresses, and a @Store@ maps addresses to
values. An environment captures bound variables in the scope of current control, and
a store models a persistent heap through the program run-time.  Currently,
the domains of addresses and values are still abstract; hence, they are
declared as abstract types.
\begin{lstlisting}
  trait Semantics {
    type Ident = String; type Addr; type Value
    type Env = Map[Ident, Addr]; type Store = Map[Addr, Value]
    type R[_] // Binding-time as a higher-kinded type
    ... // The definitions in the rest of this section are enclosed in trait Semantics.
  }
\end{lstlisting}

\paragraph{Binding-time Abstraction}
The binding-time type is declared as a higher-kinded type @R[_]@.
Now we can use @R@ to annotate other data-types in the interpreter;
it is also injected into the monadic type @MonadOps@.  If we instantiate
@R@ as an identity type (i.e., @type R[T] = T@), then the generic interpreter is a
standard definitional interpreter that will execute the program.  In Section
\ref{stagedinterp}, we instantiate @R@ using LMS's built-in next-stage
type annotation @Rep@, which makes the interpreter act as a compiler.

\paragraph{Monadic Operations} We define the return type of the interpreter
@Ans@ as a monadic type @AnsM[_]@ wrapping the type @Value@.
As mentioned in Section~\ref{monadscala}, in order to use the @for@-comprehension
syntax certain operations must be added on the type @AnsM@. Here, we use a
structural type @MonadOps@ to require that type @AnsM@ must (at least)
implement @map@ and @flatMap@. It is worth noting that @MonadOps@ takes another
type parameter @R[_]@ as the binding-time, i.e., @MonadOps[R, AnsM, T]@.
Inside @MonadOps@, @R[_]@ annotates the data types @A@ and @B@ that are
encapsulated by the monad, but not the monad type @M@ itself. When the generic
interpreter acts as a compiler, we will replace the monads with the ones that
work on staged data values.

We also declare several operations to manipulate environments and
stores. These methods return monadic values of type @AnsM[_]@, which
may be parameterized over the environment or store type, or merely a @Unit@
value for performing effects. For example, @local_env@ installs a new environment
@ρ@ when evaluating the monadic value @ans@; @set_store@ takes a pair of
addresses and (potentially staged) values, and updates the store accordingly.

%\vspace{-1em}
\begin{figure}[h!]
  \centering
\vspace{-1em}
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{lstlisting}
  type MonadOps[R[_], M[_], A] = {
    def map[B](f: R[A] => R[B]): M[B]
    def flatMap[B](f: R[A] => M[B]): M[B]
  }

  type AnsM[T] <: MonadOps[R, AnsM, T]
  type Ans = AnsM[Value]
    \end{lstlisting}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.55\textwidth}
    \begin{lstlisting}
// Environment operations
def ask_env: AnsM[Env]
def local_env(ans: Ans)(ρ: R[Env]): Ans
// Store operations
def get_store: AnsM[Store]
def put_store(σ: R[Store]): AnsM[Unit]
def set_store(av: (R[Addr], R[Value])): AnsM[Unit]
    \end{lstlisting}
  \end{subfigure}
\end{figure}
\vspace{-1em}

\paragraph{Primitive Operations} Next, we define a few primitive operations.
First, we declare two versions of @alloc@. The first takes a store and an
identifier and produces a fresh address of non-monadic type @R[Addr]@. Since
the freshness of the address may depend on the store, which might be a
next-stage value as indicated by its type, the type of addresses is
consequently wrapped by @R[_]@. The other @alloc@ is simply the monadic version
of the addresses, and can therefore be used in monadic computations.
An auxiliary method @get@ retrieves the value of an identifier @x@ through the
environment and store.
\begin{lstlisting}
  def alloc(σ: R[Store], x: Ident): R[Addr];  def alloc(x: Ident): AnsM[Addr]
  def get(σ: R[Store], ρ: R[Env], x: Ident): R[Value]
\end{lstlisting}

Other primitive operations in the interpreter handle the language constructs.  The
methods @num@ and @close@ deal with primitive values, which lift literal terms
(e.g., lambdas) to our value representation (e.g., closures).
Conditionals and arithmetic are handled by @br0@ and @arith@, respectively. The
method @ap_clo@ is used for applying functions, which takes a function value
and an argument value. Note that the @Env@, @Store@, and @Value@ are all
annotated by @R[_]@, as they are potentially next-stage values when the
interpreter acts as a compiler.
\begin{lstlisting}
  def num(i: Int): Ans
  def close(ev: Expr => Ans)(λ: Lam, ρ: R[Env]): R[Value]
  def br0(test: R[Value], thn: => Ans, els: => Ans): Ans
  def arith(op: Symbol, v1: R[Value], v2: R[Value]): R[Value]
  def ap_clo(ev: Expr => Ans)(fun: R[Value], arg: R[Value]): Ans
\end{lstlisting}

\begin{figure}[t]
  \centering
  \begin{lstlisting}
          def eval(ev: Expr => Ans)(e: Expr): Ans = e match {
            case Lit(i) => num(i)                   case Let(x, rhs, e) => for {
            case Var(x) => for {                      v  <- ev(rhs)
              ρ <- ask_env                            ρ  <- ask_env
              σ <- get_store                          α  <- alloc(x)
            } yield get(σ, ρ, x)                      _  <- set_store(α → v)
            case Lam(x, e) => for {                   rt <- local_env(ev(e))(ρ + (x → α))
              ρ <- ask_env                          } yield rt
            } yield close(ev)(Lam(x, e), ρ)         case Aop(op, e1, e2) => for {
            case App(e1, e2) => for {                 v1 <- ev(e1)
              v1 <- ev(e1)                            v2 <- ev(e2)
              v2 <- ev(e2)                          } yield arith(op, v1, v2)
              rt <- ap_clo(ev)(v1, v2)              case Rec(x, rhs, e) => for {
            } yield rt                                α  <- alloc(x)
            case If0(e1, e2, e3) => for {             ρ  <- ask_env
              cnd <- ev(e1)                           v  <- local_env(ev(rhs))(ρ + (x → α))
              rt  <- br0(cnd, ev(e2), ev(e3))         _  <- set_store(α → v)
            } yield rt                                rt <- local_env(ev(e))(ρ + (x → α))
                                                    } yield rt
          }
  \end{lstlisting}
\vspace{-0.5em}
\caption{The generic interpreter,
  shared by the unstaged/staged + concrete/abstract interpreter.}
\vspace{-1.5em}
\label{fig:shared_int}
\end{figure}

\paragraph{The Interpreter} We can now construct the semantics-agnostic interpreter
in monadic form, as shown in Figure \ref{fig:shared_int}. The basic idea
of generic interpretation is to traverse the abstract syntax tree
while maintaining the effects (such as environment and state updates).
Note that the interpreter is written in open-recursive style: it cannot
refer to itself directly. Instead, @eval@ takes an additional parameter @ev@ of
type @Expr => Ans@ that refers to itself. Consequently, the method @close@ that
lifts lambda terms to closures and method @ap_clo@ that applies functions also
takes an extra @ev@, because evaluations may happen inside them.
To close the open recursion, we use a fixed-point operator @fix@.
For concrete-interpretation instantiation, @fix@ works like the Y combinator;
for abstract-interpretation instantiation, it will instrument the interpreter
by memoizing @ev@'s inputs and outputs, which ensures the termination of
abstract interpretation.
Finally, there is a top-level wrapper @run@. The return type @Result@
depends on the kind of monads being used and is therefore also left abstract.
\begin{lstlisting}
  def fix(ev: (Expr => Ans) => (Expr => Ans)): Expr => Ans
  type Result; def run(e: Expr): Result
\end{lstlisting}

%==========================================================================

\section{A Concrete Interpreter} \label{unstaged_conc}

As the first step in our roadmap, we instantiate the generic interpreter for
concrete execution in this section. The result is a standard definitional
interpreter with environments and stores. It can also be obtained by
refunctionalizing a standard CESK machine \cite{Felleisen:1987:CAH:41625.41654,
DBLP:conf/ppdp/AgerBDM03}. We first present the concrete components, i.e., the
value domains, then show the monad stack for concrete interpretation, finally
sketch how the primitive operations are implemented.

\paragraph{Concrete Components}
The two types we need to concretize are addresses @Addr@ and values @Value@. The
types @Env@ and @Store@ are derived automatically. To ensure the freshness of
address allocations, we use type @Int@ and always return a number that is greater
than the size of the current store.
A value can be either a tagged number \texttt{IntV}, or a closure
\texttt{CloV} that contains a lambda term and an environment. The final
result of the interpreter is a pair of values and stores.
To distinguish from the monadic values of type @Ans@ produced by the
interpreter, later we use term \textit{grounded values} to denote such final values.
The two elements in the type @Result@ are annotated by the binding-time @R@,
because they can be next-stage objects.  We also define a standard fixed-point
combinator to close the open-recursive function @ev@.
\begin{lstlisting}
  trait ConcreteComponents extends Semantics {
    type Addr = Int;  sealed trait Value
    case class IntV(i: Int) extends Value
    case class CloV(λ: Lam, e: Env) extends Value
    type Result = (R[Value], R[Store])
    def fix(ev: (Expr => Ans) => (Expr => Ans)): Expr => Ans = e => ev(fix(ev))(e)
  }
\end{lstlisting}

\paragraph{Unstaged Monads}
For concrete interpretation, the monad needs to model reader and state effects,
which correspond to the environment and the store, respectively. We follow the
monad transformer approach \cite{DBLP:conf/popl/LiangHJ95},
and use the @ReaderT@ and @StateT@ monad transformers to
compose the monad stack. In other words, the type @AnsM@ is
instantiated by layering the @ReaderT@ and @StateT@ transformers\footnote{The
question mark syntax is a kind projector \cite{kindprojector}, such that
\texttt{StateT[IdM,Store,?]} is equivalent to \newline \texttt{(\{type
M[T]=StateT[IdM,Store,T]\})\#M}}, where the @ReaderT@ is parameterized by the
type @Env@, and the @StateT@ is parameterized by the type @Store@, and the
inner-most monad @IdM@ is merely an identity monad.
\begin{lstlisting}
  trait ConcreteSemantics extends ConcreteComponents {
    type R[T] = T
    type AnsM[T] = ReaderT[StateT[IdM, Store, ?], Env, T] // the monad stack
    ... }
\end{lstlisting}

Here, we sketch the basic idea of @ReaderT@ and @StateT@. Readers may
refer to \cite{DBLP:conf/popl/LiangHJ95, Chiusano:2014:FPS:2688794} for more detail.
A @ReaderT@ monad transformer encapsulates computation @R => M[A]@, where
@R@ is the environment type, and @M[_]@ is the inner monadic type.
Given a value of @R@, a @ReaderT@ monad produces a transformed value of type @M[A]@.
Similarly, a @StateT@ monad encapsulates computation @S => M[(A, S)]@, where
@S@ is the state type, and @M[_]@ is the inner monad type.
Given a value of @S@, a @StateT@ monad produces a transformed value of type @M[(A, S)]@,
where the new state (of type @S@) is accompanied with the result (of type @A@).
Note that for the moment, the binding-time type @R@ is an identity type; thus,
these monads operate on unstaged data. We can also see this from the
signature of @flatMap@: the argument function @f@ takes an unstaged value of type @A@ and
produces a monadic value. In the following code, we elide operations other than @flatMap@.
\begin{lstlisting}
  case class ReaderT[M[_]: Monad, R, A](run: R => M[A]) {
    def flatMap[B](f: A => ReaderT[M, R, B]): ReaderT[M, R, B] =
      ReaderT(r => Monad[M].flatMap(run(r))(a => f(a).run(r))); ... }
  case class StateT[M[_]: Monad, S, A](run: S => M[(A, S)]) {
    def flatMap[B](f: A => StateT[M, S, B]): StateT[M, S, B] =
      StateT(s => Monad[M].flatMap(run(s)) { case (a, s1) => f(a).run(s1) }); ... }
\end{lstlisting}

After defining the monad stack, the operations manipulating environments
and stores can be defined by constructing the proper monadic value and lifting it to the
top-level of our monad stack. To modify the store, for example, we construct a
@StateT@ value that updates the current store $\sigma$ to @σ + αv@, which
results in a @StateT[IdM, Store, Unit]@ value. Then, we lift this @StateT@
value to the top-level @ReaderT@ type, i.e., @AnsM[Unit]@.
\begin{lstlisting}
  def set_store(αv: (Addr, Value)): AnsM[Unit] = liftM(StateTMonad.mod(σ => σ + αv))
\end{lstlisting}

\paragraph{Primitive Operations}
Other primitive operations over the value domains can be implemented
straightforwardly. We elide most of them but describe a bit on how we handle
functions and applications. The reason is that lambda terms are data but are also
part of the control flow. The way we treat them is simple now, but
will become more involved when we stage the abstract interpreter.
The method @close@ denotes a lambda term to our representation of functions.
At the moment, @close@ takes a lambda term and an environment, and
produces the defunctionalized representation of closures.
The method @ap_clo@ performs function applications, which takes a function
value @fun@ and an argument @arg@. It first extracts the lambda term and environment
enclosed in @fun@, and allocates an addresses for the argument and updates the
environment and store accordingly.  Finally, body expression of the lambda term
is evaluated under the new environment and store.
\begin{lstlisting}
  def close(ev: Expr => Ans)(λ: Lam, ρ: Env): Value = CloV(λ, ρ)
  def ap_clo(ev: Expr => Ans)(fun: Value, arg: Value): Ans = fun match {
    case CloV(Lam(x, e), ρ: Env) => for {
      α <- alloc(x)
      _ <- set_store(α → arg)
      rt <- local_env(ev(e))(ρ + (x → α))
    } yield rt
  }
\end{lstlisting}


We define the top-level @run@ method as invoking the fixed-point operator with
the evaluator and input expression @e@, and running the monad stack with the
initial environment $\rho_0$ and store $\sigma_0$.
\begin{lstlisting}
  def run(e: Expr): Result = fix(eval)(e)(ρ$_0$)(σ$_0$)
\end{lstlisting}
