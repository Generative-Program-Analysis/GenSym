\section{Case Study} \label{cases_study}

In Section~\ref{sai}, we have shown staging an abstract interpreter is feasible and can be 
systematic after correctly identifying the binding-times, despite the fact that the abstract 
interpreter is intended to be imprecise and easy to implement. 
In this section, we conduct several case studies to show that it is also useful and widely
applicable to different analysis.

\subsection{Abstract Compilation a la Staging} \label{cs_ac}

\citeauthor{Boucher:1996:ACN:647473.727587} introduced abstract compilation (AC) as a new
implementation technique for abstract interpretation based static analysis \cite{Boucher:1996:ACN:647473.727587}.
The idea is inspired by partial evaluation and similar with the presented paper -- the program can be known 
statically therefore the overhead of interpretation can be eliminated. 
In AC, the compiled analysis can be represented by either text or closures (higher-order functions);
the closures can be executed immediately however the textual program need to be loaded firstly.

Specifically, \citeauthor{Boucher:1996:ACN:647473.727587} show how to compile a monovariant control-flow 
analysis \cite{Shivers:1991:SSC:115865.115884, Shivers:1988:CFA:53990.54007} 
for continuation-passing style (CPS) programs. Since the analyzed program is written in CPS, the analyzer 
is essentially a big-step control-environment abstract interpreter.
Closure generation compiles the analysis as a closure which takes an environment as argument.
And the overhead of traversing the abstract syntax tree of input program also has been eliminated.

In this section, we show that \citeauthor{Boucher:1996:ACN:647473.727587}'s abstract compilation can be 
understood and implemented as an instance of staging abstract interpreters.
We firstly revisit the original implementation of abstract compilation of 0-CFA,
and then reproduce their result by simply adding stage annotations.
The generated program of our approach improves approximately the same extent of speed,
but without changing a single line of the analyzer program (with the use of LMS).
However, closure generation requires more engineering effort, such as a whole-program 
conversion on the analyzer. Moreover, as shown in Section~\ref{staged_ds}, 
our approach is able to not only remove the interpretive overhead, but also specialize 
the data structures used in the analysis, for example, the environment that maps variables to sets of lambda.

\begin{figure*}
  \centering
  \begin{subfigure}[h]{0.49\textwidth}
    \centering
    \begin{lstlisting}
type CompAnalysis = Store => Store
def compProgram(prog: Expr): CompAnalysis = compCall(prog)
def compCall(call: Expr): CompAnalysis = call match {
  case Letrec(bds, body) =>
    val C1 = compCall(body); val C2 = compArgs(bds.map(_.value))
    ($\sigma$: Store) => C1(C2($\sigma$.update(bds.map(_.name), 
       bds.map(b => Set(b.value.asInstanceOf[Lam])))))
  case App(f, args) =>
    val C1 = compApp(f, args); val C2 = compArgs(args)
    ($\sigma$: Store) => C1(C2($\sigma$))
}
def compApp(f: Expr, args: List[Expr]): CompAnalysis = 
  f match {
    case Var(x) => ($\sigma$: Store) => 
      analysisAbsApp($\sigma$.lookup(x), args, $\sigma$)
    case Op(_) => compArgs(args)
    case Lam(vars, body) =>
      val C = compCall(body)
      ($\sigma$: Store) => 
        C($\sigma$.update(vars, args.map(primEval(_, $\sigma$))))
  }
def compArgs(args: List[Expr]): CompAnalysis = args match {
  case Nil => ($\sigma$: Store) => $\sigma$
  case (arg@Lam(vars, body))::rest =>
    val C1 = compCall(body); val C2 = compArgs(rest)
    ($\sigma$: Store) => C2(C1($\sigma$))
  case _::rest => compArgs(rest)
}
  \end{lstlisting}
  \end{subfigure}
\hfill
  \begin{subfigure}[h]{0.49\textwidth}
    \centering
    \begin{lstlisting}
def analyzeProgram(prog: Expr, $\sigma$: Rep[Store]): Rep[Store] = 
  analyzeCall(prog, $\sigma$)
def analyzeCall(call: Expr, $\sigma$: Rep[Store]): Rep[Store] = 
  call match {
    case App(f, args) => analyzeApp(f, args, analyzeArgs(args, $\sigma$))
    case Letrec(bds, body) =>
      val $\sigma$_* = $\sigma$.update(bds.map(_.name), 
        bds.map(b => Set(b.value.asInstanceOf[Lam])))
      val $\sigma$_** = analyzeArgs(bds.map(_.value), $\sigma$_*)
      analyzeCall(body, $\sigma$_**)
  }
def analyzeApp(f: Expr, args: List[Expr], $\sigma$: Rep[Store]): Rep[Store] = 
  f match {
    case Var(x) => analyzeAbsApp(args, $\sigma$(x), $\sigma$)
    case Op(_) => analyzeArgs(args, $\sigma$)
    case Lam(vars, body) =>
      val $\sigma$_* = $\sigma$.update(vars, args.map(primEval(_, $\sigma$)))
      analyzeCall(body, $\sigma$_*)
  }
def analyzeArgs(args: List[Expr], $\sigma$: Rep[Store]): Rep[Store] = 
  args match {
    case Nil => $\sigma$
    case Lam(vars, body)::rest => analyzeArgs(rest, analyzeCall(body, $\sigma$))
    case _::rest => analyzeArgs(rest, $\sigma$)
  }
  \end{lstlisting}

  \end{subfigure}
  \caption{Comparison of AC (left) and SAI (right). Only core code are shown.}
  \label{compare_ac_sai}
\end{figure*}

\subsubsection{Closure Generation}

The analysis presented by \citeauthor{Boucher:1996:ACN:647473.727587} is 0-CFA for a CPS language consisting
of lambda terms, applications, @letrec@ and primtive operators. The analyses for different syntactic 
structs are decomposed to different functions, such as @analyzeCall@ and @analyzeApp@. The idea of closure
generation is to rewrite these functions, where previously they may take both static arugments and dynamic arguments,
but after the rewrite only the static arguments is taken. In this case, the static arguments are syntactic terms;
the dynamic arguments are stores. After written in AC style, the functions like @compCall@ (compiled version of @analyzeCall@) 
returns a value of type
@CompAnalysis@, i.e., a closure that takes a store and returns a store. The result of multiple calls on such functions, for example,
@compCall@ and @compArgs@ can be composed. The generated closure only takes stores, because the input program
is specialized into the closure. The code is shown in Figure~\ref{compare_ac_sai} (left).

\subsubsection{Staged 0-CFA}

On the other side, our approach does exactly the same thing through staging: the syntactic terms are static, and 
stores are dynamic, therefore the generated code just looks-up and updates the store.
Figure~\ref{compare_ac_sai} (right) shows the code written with LMS. In fact, the only changes are
the type of @Store@ is replaced with @Rep[Store]@ indicating that the values of type @Store@  will be known
at the next stage. Indeed, a amount of additional engineering efforts are required to make this happen, 
including: the staged version @Map@ which is already included in LMS; implicit @lift@ function that transform a
current-stage constant value to next stage; next-stage representation of the syntactic terms, i.e., proper @toString@
functions of AST structs. We consider these efforts are relatively small, and does not interfere the actual analysis
we desire.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Control-flow Analysis} \label{cfa}

The target language we presented in Section~\ref{bg_lang} is essentially a higher-order functional language.
One fundamental analysis task for functional programs is the control-flow analysis, i,e., determining
which functions will possibly be applied at each call-site. 
The abstract interpreter we used in Section~\ref{unstaged_abs} and Section~\ref{sai} is a store-widened 
0-CFA-like abstraction, moreover it is also a pushdown control-flow analysis; 
in last section, we also reviewed AC with finite-state 0-CFA.
In this section, based on the existing staged abstract interpreter, we further
develop the staging techniques with control-flow analyses, including recoverying a more precise store model;
context-sensitive analsis, and using staging as a implementation stategy for mixed sensitivity.

\subsubsection{A More Precise Store Model}

The store-widened analysis we implemented in Section~\ref{sai} uses a single store to approximate
the runtime store. It can be efficently computed in polynomial time together with 0-CFA-like abstraction, 
but sometimes we may desire a 
more precise result that distinguish the final values and stores for different closure targets. 
To achieve this goal,
we need to tweak our abstract interpreter and type instantiation. The answer type @Ans@ is changed to
a set of @VS@s where a @VS@ is a pair of sets of abstract values (such as closures or abstract numbers)
and a store. 

\begin{lstlisting}
type VS = (Set[AbsValue], Store)
type Ans = R[Set[VS]]
\end{lstlisting}

Note that the type @Ans@ uses our stage polymorphic type @R@, meaning that under staging the type @Ans@
represents a next stage value. Then, our generic interpreter is also changed when handling function 
applications.

\begin{lstlisting}
case App(e1, e2) =>
  val e1ans = ev(e1, $\rho$, $\sigma$)
  val e1vs  = choices(e1ans)
  val e2ans = ev(e2, $\rho$, e1vs.$\sigma$)
  val e2vs  = choices(e2ans)
  apply_closure(ev)(e1vs.v, e2vs.v, e2vs.$\sigma$)
\end{lstlisting}

The idea is to handle the application is to explore all possible closures from @e1@ and meanwhile
use the latest store.
What @choices@ does is similar to McCarthy's @amb@ operator ~\cite{MCCARTHY196333}: it non-deterministically return an
element of type @VS@ from its argument, e.g., @e1ans@, to its right-hand side receiver, i.e., @e1vs@.
The function @choices@ internally uses delimited control operator @shift@ to capture the continuation,
which is the code block after its call site. 
This allows us to perform nesting depth-first evaluation for function application but still writing 
the program in direct-style \cite{Wei:2018:RAA:3243631.3236800}. 
Again, we can stage this part as we did for the naive abstract interpreter.

\subsubsection{Context-Sensitivity}

We add k-CFA-like context-sensitivity to the analysis by introducing an abstract time stamp, 
whose concrete instantiation is a finite list of expression that track $k$ recent calling context.
The definition of abstract addresses is changed to a tuple of identifiers and the time it get allocated,
meaning that this address points to some values under such calling context.
If $k$ is 0, we obtain a monovariant analysis as demonstrated before; if $k > 0$, a higher precision
analysis is obtained.

\begin{lstlisting}
type Time = List[Expr]
\end{lstlisting}

Every time when we call the @eval@ function, we refresh the time stamp by calling function @tick@,
which returns a new time stamp. Here we adopt a $k$-CFA-like allocation strategy, therefore
the @tick@ function can be implemented as appending the current expression being evaluated to the exiting
calling context, and then taking the first $k$ elements from the list.

\begin{lstlisting}
def tick(e: Expr, $\tau$: R[Time]): R[Time] = (e :: $\tau$).take(k)
def eval(ev: EvalFun)
  (e: Expr, $\rho$: R[Env], $\sigma$: R[Store], $\tau$: R[Time]): Ans = {
    val $\tau$_* = tick(e, $\tau$)
    e match {
      case Lit(i) => ...
      ...
    }
  }
\end{lstlisting}

Accordingly, the type of return value is accompanied with the time stamp. For recursive call of @ev@,
which would also return the latest time stamp, and that time stamp will be used for the afterward evaluation.

\begin{lstlisting}
type VST = (Value, Store, Time)
type Ans = R[Set[VST]]
\end{lstlisting}

Using other allocation strategies to achieve different sensitivities is possible \cite{DBLP:conf/icfp/Gilray0M16} 
and will be staged under our framework.
 
%\subsubsection{Mixed Sensitivity}

%using different $k$ for $k$-CFA

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Numerical Analysis in Imperative Languages} \label{cases_imp}

Now we consider in a first-order imperative language, we may care more about the data-flow because the control-flow
is relatively easy to obtain. In this section, we show the staging of other abstract domains, particularly an 
interval domain for numbers.
It has been shown that specializing abstract domains with respect to the structure of analyzed program significantly 
improves the performance: a recent example is online decomposition of polyhedra \cite{DBLP:conf/popl/SinghPV17, Singh:2017:PCD:3177123.3158143}.
In this section, we first show how to support imperative language features to the abstract interpreter, 
and present a similar idea for interval domain but show the specialization is feasible by systematically staging.

\subsubsection{Scaling to Imperative Languages}

To evaluates an assignment, we first evaluate its right-hand side, and then put the value to the slot where
the address of @v@ points to.
For simplicity, we elect to make the value of the assignment be the value of its right-hand side.

\begin{lstlisting}
case Assign(x, e) =>
  val (v, $\sigma$_*) = ev(e, $\rho$, $\sigma$)
  (v, put($\sigma$_*, get($\rho$, x), v))
\end{lstlisting}

without introducing new language value members.

\begin{lstlisting}
case While(t, e) =>
  val (tv, t$\sigma$) = ev(t, $\rho$, $\sigma$)
  if (notZero(tv)) 
\end{lstlisting}

\subsubsection{Staged Interval}

\begin{lstlisting}
case class Interval(lb: Rep[Double], ub: Rep[Double]) {
  def +(that: Interval): Interval = that match {
    case Interval(lb_, ub_) => Interval(lb + lb_, ub + ub_)
  }
  def -(that: Interval): Interval = that match {
    case Interval(lb_, ub_) => Interval(lb - lb_, ub_ - ub) 
  }
  ...
}
\end{lstlisting}

