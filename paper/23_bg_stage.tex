\section{From Interpreters to Staged Interpreters} \label{stagedinterp}

\subsection{Multi-Stage Programming in LMS}

Lightweight modular staging (LMS) \cite{DBLP:conf/gpce/RompfO10} is a
multi-stage programming framework implemented as a Scala library that enables
dynamic code generation in a type-safe manner. Different from the syntactic
approach in MetaOCaml \cite{DBLP:conf/flops/Kiselyov14,
DBLP:conf/gpce/CalcagnoTHL03} that uses quotations, LMS distinguishes
binding-time solely based on types. LMS provides a type constructor @Rep[T]@
where @T@ can be an arbitrary type, indicating an expression will be known at
next stage. All operations acting on a @Rep[T]@ expression will be residualized
in the generated code. However, we need to provide intermediate representation
and code generation support for type @T@ to LMS. Fortunately, the LMS framework
already provides such support for primitive types and commonly used data
structure such as arrays and maps; implementing such support for custom class is
also straightforward. Let's go back and see how LMS can be used to specialize
the power function we mentioned in Section 1.

\begin{lstlisting}
new DslDriver[Int, Int] {
  def power(b: Rep[Int], x: Int): Rep[Int] =
    if (x == 0) 1 else b * power(b, x-1)
  def snippet(x: Rep[Int]): Rep[Int] = power(x, 5)
}
\end{lstlisting}

In the code shown above, \texttt{power} takes two arguments where \texttt{b} is
declared as \texttt{Rep[Int]} type meaning that \texttt{b} is a representation
of \texttt{Int} but whose value will be available at the next stage. Meanwhile,
the result of the @power@ function will be available at the next stage as well,
thus the return value of \texttt{power} is also of type \texttt{Rep[Int]}. Then
we specialize @power@ in function @snippet@ by providing @x@ to @5@. The
generated code for \texttt{power5} is a function that takes only one argument
which corresponds to @b@, and the body of this function multiplies @b@ five
times.

\subsection{Staged Concrete Semantics}

In the staging part, we share the same concrete type instantiation, i.e., trait
\texttt{Concrete}, but we reimplement the staged version for the concrete
operations in trait @RepConcInterpOps@. Meanwhile, it is also extended from
@LMSOps@ which provides necessary support for the staged version of primitive
types and data structures. To stage the interpreter, we first identify the
syntactic input that is known statically, and the interpreter returns a pair of
values and store, which both becomes dynamic values. Thus the staged stores
propagate the binding-time to environments, because they share the same address
component.

\begin{lstlisting}
trait RepConcInterpOps extends Concrete with LMSOps {
  type R[+T] = Rep[T]
  val $\rho$0: Rep[Env] = Map[Ident,Addr]()
  val $\sigma$0: Rep[Store] = Map[Addr,Value]()
  def get($\rho$: Rep[Env], x: Ident): Rep[Addr] = $\rho$(x)
  def put($\rho$: Rep[Env], x: Ident, a: Rep[Addr]): Rep[Env] = 
    $\rho$ + (unit(x) -> a)
  def get($\sigma$: Rep[Store], a: Rep[Addr]): Rep[Value] = $\sigma$(a)
  def put($\sigma$: Rep[Store], a: Rep[Addr], v: Rep[Value]): Rep[Store] = 
    $\sigma$ + (a -> v)
  def alloc($\sigma$: Rep[Store], x: Ident): Rep[Addr] = $\sigma$.size + 1
  def num(i: Lit): Rep[Value] = lift(NumV(i))
  def branch0(cnd: Rep[Value], thn: => Ans, els: => Ans): Ans = {
    //FIXME: the cast is ugly, patten match?
    val i = cnd.asInstanceOf[Rep[NumV]].i
    if (i == 0) thn else els
  }
  def prim_eval(op: Symbol, 
    v1: Rep[Value], v2: Rep[Value]): Rep[Value] = op match {
      case '+ => v1.asInstanceOf[Rep[NumV]].i + 
                 v2.asInstanceOf[Rep[NumV]].i
      ...
    }
  ...
}
\end{lstlisting}

The first notable change is that the abstract type member @R@ is assigned to be
@Rep@, and accordingly the affected types such as @Env@ and @Store@ become
@Rep[Env]@ and @Rep[Store]@. For @num@, we use the @lift@ function which is a
built-in in LMS that lifts a current-stage value to next stage. The interesting
point is how we handle closures and function applications when staging is
involved. In the unstaged version, function @close@ is used to lift a literal
lambda term to a closure, which is a pair of the syntactic lambda term and the
enclosing environment. However, what we desire is a \textit{compiled} closure,
instead of a lifted @CloV@ value like what we did for @NumV@ --- in other words,
the syntactic term of the lambda expression should be eliminated and specialized
away. The specialization of the interpreter with respect to the body of the
lambda term proceeds under the assumptions that the argument and latest store
will be provided later.
%\note{to denotational style?, back to HO?}
We will see this is an important observation that enables us to specialize an
abstract interpreter in a modular way. At the end of function @close@, we create
a @CompiledClo@ object that contains a staged function, which all will be
emitted in the generated code.

\begin{lstlisting}
def close(ev: EvalFun)($\lambda$: Lam, $\rho$: Rep[Env]): Rep[Value] = {
  val Lam(x, e) = $\lambda$
  val f: Rep[(Value,Store)]=>Rep[(Value,Store)] = { 
    case (arg: Rep[Value],$\sigma$: Rep[Store]) =>
      val $\alpha$ = alloc($\sigma$, x)
      ev(e, put($\rho$, x, $\alpha$), put($\sigma$, $\alpha$, arg)) 
  }
  CompiledClo(fun(f))
}
\end{lstlisting}

Next, @apply_closure@ takes three arguments: the function value, argument value
and the latest store, which are all of @Rep@ type. This means basically there
is nothing we can do at the current stage --- so we create a new node
@ApplyClosure@ that contains these arguments in the intermediate representation
graph, and in the code generation phase we can emit the code that performs the
application. The additional @reflectEffect@ is a function in LMS that handles
side effects.

\begin{lstlisting}
case class ApplyClosure(f: Rep[Value], 
  arg: Rep[Value], $\sigma$: Rep[Store]) extends Def[(Value, Store)]
def apply_closure(ev: EvalFun)
  (f: Rep[Value], arg: Rep[Value], $\sigma$: Rep[Store]): Ans = {
    reflectEffect(ApplyClosure(f, arg, $\sigma$))
  }
\end{lstlisting}

\paragraph{Code Generation}

When generating code for the next stage, values like @CompiledClo@ and @NumV@
are kept as they are because they are intended exist in the next stage; however,
we need to treat @ApplyClosure@ a little differently.

\begin{lstlisting}
  case ApplyClosure(f, arg, $\sigma$) => 
    emitValDef(sym, quote(f) + 
                    ".asInstanceOf[CompiledClo].f(" + 
                    quote(arg) + "," + 
                    quote($\sigma$) + ")")
\end{lstlisting}

Concretely, as shown in the code above, when emitting code for @ApplyClosure@,
we just emit a function application where the function value is extracted from
the @CompiledClo@ object (we assume the input program is well-typed so that we
can safely cast it to @CompiledClo@). Argument and a store are the remaining rest
fields in @ApplyClosure@.
